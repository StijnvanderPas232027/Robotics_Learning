{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.187, 0.2195, 0.1195]\n",
      "[0.253, 0.2195, 0.1195]\n",
      "[0.253, 0.2195, 0.2895]\n",
      "[-0.187, 0.2195, 0.2894]\n",
      "[-0.1868, -0.1705, 0.2892]\n",
      "[0.253, -0.1705, 0.2891]\n",
      "[0.253, -0.1705, 0.1695]\n",
      "[-0.187, -0.1705, 0.1695]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sim_class import Simulation\n",
    "# Define the velocities for moving to each corner\n",
    "velocities = [\n",
    "    [-0.1, 0.1, 0.0],  # Move along +Y\n",
    "    [0.1, 0.0, 0.0],  # Move along +X\n",
    "    [0.0, 0.0, 0.1],  # Move along +Z\n",
    "    [-0.1, 0.0, 0.0],  # Move along -X\n",
    "    [0.0, -0.1, 0.0],  # Move along -Y\n",
    "    [0.1, 0.0, 0.0],  # Move along +X\n",
    "    [0.0, 0.0, -0.1],  # Move along -Z\n",
    "    [-0.1, 0.0, 0.0],  # Move along -X\n",
    "]\n",
    "\n",
    "# Initialize the simulation\n",
    "sim = Simulation(num_agents=1, render=True)\n",
    "\n",
    "for velocity in velocities:\n",
    "    actions = [[velocity[0], velocity[1], velocity[2], 0]]  # Define actions for the robot\n",
    "    \n",
    "    for _ in range(1300):  # Adjust range for movement duration\n",
    "        state = sim.run(actions, num_steps=1)  # Run the simulation and get the state\n",
    "        time.sleep(0.01)  # Delay for visualization\n",
    "\n",
    "    # Extract and print the pipette position\n",
    "    pipette_position = state.get('robotId_1', {}).get('pipette_position', None)\n",
    "    if pipette_position:\n",
    "        print(pipette_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "p.disconnect()  # Disconnect any active PyBullet connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from sim_class import Simulation\n",
    "import numpy as np\n",
    "import pybullet as p\n",
    "\n",
    "\n",
    "class OT2Env(gym.Env):\n",
    "    def __init__(self, render=False, max_steps=1000):\n",
    "        super(OT2Env, self).__init__()\n",
    "        self.render = render\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        # Create the simulation environment\n",
    "        self.sim = Simulation(num_agents=1)\n",
    "\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        self.action_space = spaces.Box(low=(-1, -1, -1) , high=(1, 1, 1), shape=(4,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low='-inf' , high='inf', shape=(6,), dtype=np.float32)\n",
    "\n",
    "        # keep track of the number of steps\n",
    "        self.steps = 0\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        # being able to set a seed is required for reproducibility\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # Reset the state of the environment to an initial state\n",
    "        # set a random goal position for the agent, consisting of x, y, and z coordinates within the working area (you determined these values in the previous datalab task)\n",
    "        self.goal_position = np.array([\n",
    "            np.random.uniform(-0.187, 0.253),\n",
    "            np.random.uniform(-0.1705, 0.2195),\n",
    "            np.random.uniform(0.1195, 0.2895)\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        # Call the environment reset function\n",
    "        observation = self.sim.reset(num_agents=1)\n",
    "        # now we need to process the observation and extract the relevant information, the pipette position, convert it to a numpy array, and append the goal position and make sure the array is of type np.float32\n",
    "        pipette_position = np.array(observation[f'robotId_{self.sim.robot_Ids[0]}']['pipette_position'], dtype=np.float32)\n",
    "        observation = np.concatenate([pipette_position, self.goal_position], axis=0)\n",
    "        # Reset the number of steps\n",
    "        self.steps = 0\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        # since we are only controlling the pipette position, we accept 3 values for the action and need to append 0 for the drop action\n",
    "        action = np.append(action, 0)\n",
    "\n",
    "        # Call the environment step function\n",
    "        observation = self.sim.run([action]) # Why do we need to pass the action as a list? Think about the simulation class.\n",
    "\n",
    "        # now we need to process the observation and extract the relevant information, the pipette position, convert it to a numpy array, and append the goal position and make sure the array is of type np.float32\n",
    "        pipette_position = np.array(observation[f'robotId_{self.sim.robot_Ids[0]}']['pipette_position'], dtype=np.float32)\n",
    "        observation = np.array(observation[f'robotId_{self.sim.robot_Ids[0]}']['pipette_position'], dtype=np.float32)\n",
    "\n",
    "        # Calculate the reward, this is something that you will need to experiment with to get the best results\n",
    "        reward = float(-np.linalg.norm(pipette_position - self.goal_position))\n",
    "        \n",
    "        # next we need to check if the if the task has been completed and i the episode should be terminated\n",
    "        # To do this we need to calculate the distance between the pipette position and the goal position and if it is below a certain threshold, we will consider the task complete. \n",
    "        # What is a reasonable threshold? Think about the size of the pipette tip and the size of the plants.\n",
    "        distance = np.linalg.norm(pipette_position - self.goal_position)\n",
    "        if distance - self.goal_position < 0.05:\n",
    "            terminated = True\n",
    "            # we can also give the agent a positive reward for completing the task\n",
    "        else:\n",
    "            terminated = False\n",
    "\n",
    "        # next we need to check if the episode should be truncated, we can check if the current number of steps is greater than the maximum number of steps\n",
    "        if self.steps > self.max_steps:\n",
    "            truncated = True\n",
    "        else:\n",
    "            truncated = False\n",
    "\n",
    "        info = {} # we don't need to return any additional information\n",
    "\n",
    "        # increment the number of steps\n",
    "        self.steps += 1\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        self.sim.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "p.disconnect()  # Disconnect any active PyBullet connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: {'robotId_2': {'joint_states': {'joint_0': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}, 'joint_1': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}, 'joint_2': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}}, 'robot_position': [0.0, 0.0, 0.03], 'pipette_position': [0.073, 0.0895, 0.1195]}}\n",
      "Episode: 1, Step: 1, Action: [ 0.33155861  0.87114066  0.85061955 -0.95268154], Reward: -0.29651448130607605\n",
      "Episode: 1, Step: 2, Action: [-0.5298414  -0.27832013 -0.6835679  -0.4130298 ], Reward: -0.29651448130607605\n",
      "Episode: 1, Step: 3, Action: [-0.819646    0.9616249  -0.6895472   0.61566633], Reward: -0.29604026675224304\n",
      "Episode: 1, Step: 4, Action: [0.34160957 0.5183211  0.20049039 0.49922356], Reward: -0.29551222920417786\n",
      "Episode: 1, Step: 5, Action: [ 0.8730142   0.18137029  0.67476255 -0.3295513 ], Reward: -0.2949245870113373\n",
      "Episode: 1, Step: 6, Action: [-0.48548496 -0.2520304   0.33814996  0.7135716 ], Reward: -0.29418447613716125\n",
      "Episode: 1, Step: 7, Action: [-0.63733715 -0.97977084  0.24330588  0.33993125], Reward: -0.2932837903499603\n",
      "Episode: 1, Step: 8, Action: [ 0.37898642  0.69027764  0.59313744 -0.19891256], Reward: -0.292246550321579\n",
      "Episode: 1, Step: 9, Action: [-0.15654129  0.83033407  0.3875744  -0.5704647 ], Reward: -0.29093363881111145\n",
      "Episode: 1, Step: 10, Action: [-0.04604724  0.33881292  0.46835393 -0.25426212], Reward: -0.289689838886261\n",
      "Episode: 1, Step: 11, Action: [ 0.9627348   0.98090065  0.58909816 -0.5902497 ], Reward: -0.286021888256073\n",
      "Episode: 1, Step: 12, Action: [ 0.38637087  0.86217034  0.4482885  -0.22354522], Reward: -0.28344058990478516\n",
      "Episode: 1, Step: 13, Action: [-0.53079915 -0.4588398  -0.45952013 -0.9693384 ], Reward: -0.2812575399875641\n",
      "Episode: 1, Step: 14, Action: [ 0.45191294  0.926523    0.88467354 -0.8557971 ], Reward: -0.2800537943840027\n",
      "Episode: 1, Step: 15, Action: [ 0.54290724  0.39833537  0.78148055 -0.34171322], Reward: -0.2796100974082947\n",
      "Episode: 1, Step: 16, Action: [ 0.44421282 -0.8379795  -0.5305507  -0.01437128], Reward: -0.28007882833480835\n",
      "Episode: 1, Step: 17, Action: [-0.9819322  -0.9613066  -0.14545669  0.19116312], Reward: -0.28022632002830505\n",
      "Episode: 1, Step: 18, Action: [ 0.50668865 -0.30400768  0.570977    0.40770763], Reward: -0.28080815076828003\n",
      "Episode: 1, Step: 19, Action: [0.23525375 0.9285447  0.4706014  0.9060559 ], Reward: -0.2811262309551239\n",
      "Episode: 1, Step: 20, Action: [-0.5389416 -0.7229511  0.6869988  0.6790011], Reward: -0.2806470990180969\n",
      "Episode: 1, Step: 21, Action: [ 0.8996866  -0.85776395 -0.26815403 -0.11357555], Reward: -0.2812100946903229\n",
      "Episode: 1, Step: 22, Action: [ 0.55196387  0.33747858 -0.38060698  0.25234285], Reward: -0.28257259726524353\n",
      "Episode: 1, Step: 23, Action: [ 0.5369251  -0.2260416   0.17363778 -0.8497325 ], Reward: -0.28428253531455994\n",
      "Episode: 1, Step: 24, Action: [ 0.57462287  0.48853746 -0.41278464 -0.92365605], Reward: -0.2867240905761719\n",
      "Episode: 1, Step: 25, Action: [-0.977924   -0.105281    0.02315566  0.7629635 ], Reward: -0.2884733974933624\n",
      "Episode: 1, Step: 26, Action: [-0.18353462  0.51635784 -0.49698552 -0.10139845], Reward: -0.290296345949173\n",
      "Episode: 1, Step: 27, Action: [-0.5781812   0.16663451  0.67323875  0.20037666], Reward: -0.2912690341472626\n",
      "Episode: 1, Step: 28, Action: [ 0.10005622  0.9524365  -0.74719477 -0.78121305], Reward: -0.29177555441856384\n",
      "Episode: 1, Step: 29, Action: [ 0.8854572   0.81393677 -0.91520214  0.14820753], Reward: -0.2926446795463562\n",
      "Episode: 1, Step: 30, Action: [0.33147588 0.879244   0.4332307  0.30025002], Reward: -0.29356062412261963\n",
      "Episode: 1, Step: 31, Action: [-0.8918407  -0.15719916  0.6209982   0.9170605 ], Reward: -0.29365667700767517\n",
      "Episode: 1, Step: 32, Action: [0.46430054 0.04754438 0.52258533 0.46679035], Reward: -0.2942224144935608\n",
      "Episode: 1, Step: 33, Action: [-0.12810706 -0.3776236   0.9115547   0.03109982], Reward: -0.29397961497306824\n",
      "Episode: 1, Step: 34, Action: [-0.68410766 -0.10907728 -0.8084808   0.7165611 ], Reward: -0.2938571274280548\n",
      "Episode: 1, Step: 35, Action: [ 0.49359608  0.82419837  0.0504889  -0.44850084], Reward: -0.29453906416893005\n",
      "Episode: 1, Step: 36, Action: [-0.24052724  0.9436354  -0.09576841  0.9606481 ], Reward: -0.2950400114059448\n",
      "Episode: 1, Step: 37, Action: [-0.29042643  0.3032416   0.28897536 -0.16170225], Reward: -0.2949385643005371\n",
      "Episode: 1, Step: 38, Action: [ 0.8790668  -0.4151866   0.16957399 -0.6375321 ], Reward: -0.2950933277606964\n",
      "Episode: 1, Step: 39, Action: [-0.67495716  0.9552642   0.48005882  0.5296159 ], Reward: -0.2945595979690552\n",
      "Episode: 1, Step: 40, Action: [ 0.3283003   0.92888427 -0.91363144  0.05227131], Reward: -0.29495877027511597\n",
      "Episode: 1, Step: 41, Action: [ 0.04433199  0.12229524 -0.9781357   0.8521184 ], Reward: -0.2954527735710144\n",
      "Episode: 1, Step: 42, Action: [0.4133621  0.66000146 0.23681034 0.20394593], Reward: -0.29605966806411743\n",
      "Episode: 1, Step: 43, Action: [ 0.43479776  0.42128712 -0.4483688  -0.31129372], Reward: -0.2975634038448334\n",
      "Episode: 1, Step: 44, Action: [ 0.5866506  -0.21122189 -0.17404869 -0.1382762 ], Reward: -0.29934045672416687\n",
      "Episode: 1, Step: 45, Action: [ 0.42367426  0.8327382   0.21508086 -0.6561153 ], Reward: -0.3009495735168457\n",
      "Episode: 1, Step: 46, Action: [-0.7600009   0.40106964 -0.97433126 -0.3170263 ], Reward: -0.30260178446769714\n",
      "Episode: 1, Step: 47, Action: [-0.80196077 -0.48749018  0.7918469   0.9087458 ], Reward: -0.3035368323326111\n",
      "Episode: 1, Step: 48, Action: [-0.9638876   0.32653922  0.6141671  -0.8500155 ], Reward: -0.30370160937309265\n",
      "Episode: 1, Step: 49, Action: [ 0.07115857 -0.03823356 -0.9774706   0.88132876], Reward: -0.30418673157691956\n",
      "Episode: 1, Step: 50, Action: [ 0.98270285 -0.8470389  -0.8498202   0.14082439], Reward: -0.30543312430381775\n",
      "Episode: 1, Step: 51, Action: [-0.09578273 -0.26296797  0.18204904  0.62151694], Reward: -0.3059574365615845\n",
      "Episode: 1, Step: 52, Action: [-0.25367936  0.8316754  -0.8001831   0.5135503 ], Reward: -0.3065580129623413\n",
      "Episode: 1, Step: 53, Action: [-0.31936923 -0.4468078  -0.78948504  0.58313775], Reward: -0.3070789873600006\n",
      "Episode: 1, Step: 54, Action: [-0.58534396  0.48057112  0.19005734 -0.06490599], Reward: -0.30685245990753174\n",
      "Episode: 1, Step: 55, Action: [ 0.41330355  0.5799265  -0.629488    0.40972185], Reward: -0.30630120635032654\n",
      "Episode: 1, Step: 56, Action: [-0.41009903  0.9804017   0.22107236 -0.8940649 ], Reward: -0.30503779649734497\n",
      "Episode: 1, Step: 57, Action: [-0.93888897 -0.6505339   0.35992348  0.5599295 ], Reward: -0.30307382345199585\n",
      "Episode: 1, Step: 58, Action: [ 0.52658105 -0.30679256 -0.17643556  0.23200566], Reward: -0.30208802223205566\n",
      "Episode: 1, Step: 59, Action: [ 0.09153792 -0.8842083   0.00118772 -0.9105315 ], Reward: -0.3015061020851135\n",
      "Episode: 1, Step: 60, Action: [-0.56658643  0.4700381  -0.6282711  -0.07822748], Reward: -0.3009403645992279\n",
      "Episode: 1, Step: 61, Action: [ 0.14159212  0.7789945  -0.8371664   0.5492137 ], Reward: -0.30135250091552734\n",
      "Episode: 1, Step: 62, Action: [ 0.59076625  0.02583189 -0.6493101  -0.19325045], Reward: -0.30108004808425903\n",
      "Episode: 1, Step: 63, Action: [ 0.18267865 -0.11908818 -0.03844536 -0.04528684], Reward: -0.30122509598731995\n",
      "Episode: 1, Step: 64, Action: [0.9725797 0.4738323 0.3925732 0.8493468], Reward: -0.3015686571598053\n",
      "Episode: 1, Step: 65, Action: [ 0.31104937 -0.5978709  -0.8143112  -0.07281806], Reward: -0.3027038872241974\n",
      "Episode: 1, Step: 66, Action: [-0.24630076  0.46906647 -0.16991732  0.74890465], Reward: -0.30361679196357727\n",
      "Episode: 1, Step: 67, Action: [-0.69046354 -0.99010277 -0.12704003  0.4780515 ], Reward: -0.30384138226509094\n",
      "Episode: 1, Step: 68, Action: [ 0.44892907 -0.72975904  0.4451187   0.7281494 ], Reward: -0.3041462004184723\n",
      "Episode: 1, Step: 69, Action: [-0.04106322  0.64079297 -0.09521237 -0.1911873 ], Reward: -0.3044770359992981\n",
      "Episode: 1, Step: 70, Action: [0.9812842  0.29484332 0.02228338 0.2231813 ], Reward: -0.30511680245399475\n",
      "Episode: 1, Step: 71, Action: [ 0.19320458 -0.18842015  0.3689415   0.67806613], Reward: -0.30550307035446167\n",
      "Episode: 1, Step: 72, Action: [ 0.10756526 -0.2903773  -0.08789825  0.25480297], Reward: -0.30601873993873596\n",
      "Episode: 1, Step: 73, Action: [ 4.2923429e-04  1.3712113e-01 -9.3412155e-01 -6.5536600e-01], Reward: -0.30651772022247314\n",
      "Episode: 1, Step: 74, Action: [-0.5059009   0.7378463   0.09654764 -0.48933116], Reward: -0.30606168508529663\n",
      "Episode: 1, Step: 75, Action: [-0.5028741  -0.23450907  0.17656033 -0.45604876], Reward: -0.30492398142814636\n",
      "Episode: 1, Step: 76, Action: [-0.78616875  0.97467697 -0.4910073  -0.1883169 ], Reward: -0.3039279878139496\n",
      "Episode: 1, Step: 77, Action: [ 0.18436636 -0.33476815 -0.8241555   0.6069953 ], Reward: -0.302975058555603\n",
      "Episode: 1, Step: 78, Action: [-0.72090197 -0.07476111 -0.96156806  0.23033974], Reward: -0.30174246430397034\n",
      "Episode: 1, Step: 79, Action: [ 0.57078683 -0.500433   -0.6912891  -0.3890895 ], Reward: -0.3008204698562622\n",
      "Episode: 1, Step: 80, Action: [ 0.66343814  0.32596216 -0.37986642  0.22494036], Reward: -0.3003312051296234\n",
      "Episode: 1, Step: 81, Action: [-0.51659775  0.30052444  0.67347664  0.6878304 ], Reward: -0.29919007420539856\n",
      "Episode: 1, Step: 82, Action: [ 0.30775794  0.7492775   0.46212944 -0.21391672], Reward: -0.2980712354183197\n",
      "Episode: 1, Step: 83, Action: [-0.06736457  0.8302688   0.55018294 -0.00264688], Reward: -0.29721590876579285\n",
      "Episode: 1, Step: 84, Action: [ 0.84490156 -0.15016855 -0.990085    0.46389532], Reward: -0.2970241606235504\n",
      "Episode: 1, Step: 85, Action: [-0.70616215  0.36120114 -0.84956264  0.00396123], Reward: -0.29702696204185486\n",
      "Episode: 1, Step: 86, Action: [ 0.03694561  0.1208344   0.97827965 -0.47643226], Reward: -0.2969769537448883\n",
      "Episode: 1, Step: 87, Action: [ 0.2582318  -0.46808445 -0.23840119 -0.05002508], Reward: -0.2977641820907593\n",
      "Episode: 1, Step: 88, Action: [ 0.25407687 -0.9989047   0.45249373 -0.20645481], Reward: -0.2986743748188019\n",
      "Episode: 1, Step: 89, Action: [-0.897238   -0.00701669  0.9518527  -0.7548331 ], Reward: -0.29883238673210144\n",
      "Episode: 1, Step: 90, Action: [-0.01089733 -0.9060755   0.76921237  0.7999121 ], Reward: -0.2981639802455902\n",
      "Episode: 1, Step: 91, Action: [-0.22264865 -0.8835508   0.21054368  0.5729164 ], Reward: -0.2975142300128937\n",
      "Episode: 1, Step: 92, Action: [-0.6309657   0.92321235 -0.65545756  0.13631855], Reward: -0.29684776067733765\n",
      "Episode: 1, Step: 93, Action: [ 0.06825309  0.28759122 -0.22803396 -0.2961764 ], Reward: -0.29685717821121216\n",
      "Episode: 1, Step: 94, Action: [0.9914554  0.31582618 0.9657117  0.6600394 ], Reward: -0.29707902669906616\n",
      "Episode: 1, Step: 95, Action: [ 0.43923044  0.39653596 -0.61837584 -0.14479648], Reward: -0.29814645648002625\n",
      "Episode: 1, Step: 96, Action: [-0.8574838  -0.01582681  0.13549905 -0.16400062], Reward: -0.2984083890914917\n",
      "Episode: 1, Step: 97, Action: [ 0.62834954 -0.6979393   0.5854784   0.08132209], Reward: -0.2987429201602936\n",
      "Episode: 1, Step: 98, Action: [ 0.39860693 -0.10871246  0.8656959  -0.627916  ], Reward: -0.29925715923309326\n",
      "Episode: 1, Step: 99, Action: [ 0.7362393  -0.697648   -0.91003054  0.95121944], Reward: -0.3005090057849884\n",
      "Episode: 1, Step: 100, Action: [-0.84309846  0.8608703  -0.26502076 -0.2789966 ], Reward: -0.3017481863498688\n",
      "Episode: 1, Step: 101, Action: [-0.0813191  -0.915674   -0.5174634  -0.36619535], Reward: -0.302965372800827\n",
      "Episode: 1, Step: 102, Action: [ 0.23469108  0.7740897   0.03067023 -0.07602843], Reward: -0.30427220463752747\n",
      "Episode: 1, Step: 103, Action: [ 0.3866497   0.34929177 -0.43746263 -0.89685905], Reward: -0.30628806352615356\n",
      "Episode: 1, Step: 104, Action: [-0.0285553  -0.36603898 -0.36501804  0.38378572], Reward: -0.30761414766311646\n",
      "Episode: 1, Step: 105, Action: [-0.96766436 -0.71619093 -0.5897406   0.24431837], Reward: -0.30897265672683716\n",
      "Episode: 1, Step: 106, Action: [0.43890327 0.75043756 0.7497698  0.73703754], Reward: -0.30975523591041565\n",
      "Episode: 1, Step: 107, Action: [-0.72052926 -0.73917246 -0.9071021   0.9645655 ], Reward: -0.3101729154586792\n",
      "Episode: 1, Step: 108, Action: [ 0.41376835 -0.2705677   0.09205467  0.6387547 ], Reward: -0.3109224736690521\n",
      "Episode: 1, Step: 109, Action: [0.8190583  0.88250685 0.01870687 0.5334769 ], Reward: -0.3122709095478058\n",
      "Episode: 1, Step: 110, Action: [ 0.5284171  -0.70957166  0.8329052   0.23643826], Reward: -0.313676118850708\n",
      "Episode: 1, Step: 111, Action: [-0.98072773  0.06804719 -0.06137326  0.8474574 ], Reward: -0.3150380849838257\n",
      "Episode: 1, Step: 112, Action: [-0.11966453  0.7988308  -0.04635648 -0.5571789 ], Reward: -0.3160468637943268\n",
      "Episode: 1, Step: 113, Action: [ 0.10362    -0.5997938   0.18686827  0.8075144 ], Reward: -0.3162640929222107\n",
      "Episode: 1, Step: 114, Action: [ 0.49840298 -0.398532   -0.40434566 -0.02380199], Reward: -0.3173348009586334\n",
      "Episode: 1, Step: 115, Action: [-0.33775675 -0.18165213 -0.11452343  0.07318241], Reward: -0.3179469108581543\n",
      "Episode: 1, Step: 116, Action: [ 0.1518215  -0.21108443  0.8199302  -0.19282955], Reward: -0.3183247745037079\n",
      "Episode: 1, Step: 117, Action: [ 0.09009448  0.7788286  -0.9185787  -0.5907774 ], Reward: -0.31895580887794495\n",
      "Episode: 1, Step: 118, Action: [ 0.5284373   0.83578986 -0.16171971 -0.31595668], Reward: -0.31995049118995667\n",
      "Episode: 1, Step: 119, Action: [ 0.7517678   0.3555751  -0.45710647  0.481264  ], Reward: -0.32116562128067017\n",
      "Episode: 1, Step: 120, Action: [ 0.8205089  0.9895225 -0.6154746 -0.7615628], Reward: -0.3229043781757355\n",
      "Episode: 1, Step: 121, Action: [ 0.06431356  0.13252428 -0.54586405  0.85759485], Reward: -0.32403168082237244\n",
      "Episode: 1, Step: 122, Action: [-0.59144914  0.5346865   0.2544212   0.5798607 ], Reward: -0.3246086537837982\n",
      "Episode: 1, Step: 123, Action: [0.22975804 0.13149703 0.40119806 0.8550483 ], Reward: -0.32494670152664185\n",
      "Episode: 1, Step: 124, Action: [-0.18052192 -0.95529246  0.6509184   0.4506379 ], Reward: -0.3246111273765564\n",
      "Episode: 1, Step: 125, Action: [-0.8067634   0.9942151   0.97627246  0.35787138], Reward: -0.3236408233642578\n",
      "Episode: 1, Step: 126, Action: [-0.82150257  0.13261053  0.41178715  0.05005014], Reward: -0.3226028382778168\n",
      "Episode: 1, Step: 127, Action: [-0.74792737  0.5662601   0.4025634  -0.9467708 ], Reward: -0.3213003873825073\n",
      "Episode: 1, Step: 128, Action: [-0.5647428  -0.46682483  0.5677756   0.7218635 ], Reward: -0.31942158937454224\n",
      "Episode: 1, Step: 129, Action: [ 0.41924044  0.7193182  -0.84900904  0.6704946 ], Reward: -0.31830814480781555\n",
      "Episode: 1, Step: 130, Action: [-0.00631241  0.6858538  -0.7313774   0.47773653], Reward: -0.3181109130382538\n",
      "Episode: 1, Step: 131, Action: [-0.70734894 -0.7550966   0.7283083   0.42942938], Reward: -0.3171217441558838\n",
      "Episode: 1, Step: 132, Action: [ 0.44903743 -0.5816545   0.10407107 -0.51417303], Reward: -0.3166379928588867\n",
      "Episode: 1, Step: 133, Action: [-0.0301896  -0.8548139  -0.07286648 -0.03474172], Reward: -0.3165242671966553\n",
      "Episode: 1, Step: 134, Action: [-0.9429511   0.24349374  0.755784    0.04773504], Reward: -0.31591784954071045\n",
      "Episode: 1, Step: 135, Action: [ 0.91128784 -0.28459582  0.57779247  0.26478255], Reward: -0.31528058648109436\n",
      "Episode: 1, Step: 136, Action: [ 0.4538808  -0.29418486 -0.691473   -0.5585152 ], Reward: -0.3155403137207031\n",
      "Episode: 1, Step: 137, Action: [-0.437962    0.18579611  0.13343944  0.29350257], Reward: -0.3151838779449463\n",
      "Episode: 1, Step: 138, Action: [-0.41218397  0.15125808 -0.06200649  0.7907121 ], Reward: -0.31482768058776855\n",
      "Episode: 1, Step: 139, Action: [ 0.7309885  -0.45135462  0.24409118  0.71133876], Reward: -0.3144441545009613\n",
      "Episode: 1, Step: 140, Action: [ 0.6325956  -0.91997737 -0.8702318   0.92119944], Reward: -0.3149508535861969\n",
      "Episode: 1, Step: 141, Action: [ 0.9025407   0.00831087  0.9438423  -0.41841605], Reward: -0.3156090974807739\n",
      "Episode: 1, Step: 142, Action: [ 0.01375306  0.7870603  -0.50511277 -0.7645419 ], Reward: -0.31620484590530396\n",
      "Episode: 1, Step: 143, Action: [-0.23003913  0.24334252  0.4581589   0.8362564 ], Reward: -0.31615927815437317\n",
      "Episode: 1, Step: 144, Action: [ 0.90818805 -0.29940736  0.09146164  0.2030313 ], Reward: -0.3163938820362091\n",
      "Episode: 1, Step: 145, Action: [-0.8866093  -0.63428676 -0.26586917  0.43301192], Reward: -0.3165382444858551\n",
      "Episode: 1, Step: 146, Action: [-0.92635596 -0.9962891  -0.20493434 -0.49113217], Reward: -0.31614235043525696\n",
      "Episode: 1, Step: 147, Action: [ 0.6320989  -0.62447387 -0.39876628  0.028044  ], Reward: -0.3164355754852295\n",
      "Episode: 1, Step: 148, Action: [ 0.79253626 -0.40860754 -0.4815207   0.446677  ], Reward: -0.31718698143959045\n",
      "Episode: 1, Step: 149, Action: [-0.60776323 -0.04104996 -0.68279475 -0.79887414], Reward: -0.3178791105747223\n",
      "Episode: 1, Step: 150, Action: [ 0.39426732 -0.30246064  0.4271029  -0.7508732 ], Reward: -0.3186335563659668\n",
      "Episode: 1, Step: 151, Action: [ 0.96876985 -0.9288201  -0.90954095  0.4931135 ], Reward: -0.32028642296791077\n",
      "Episode: 1, Step: 152, Action: [-0.7488845   0.09813566 -0.6802632  -0.8408135 ], Reward: -0.32143139839172363\n",
      "Episode: 1, Step: 153, Action: [-0.006786   -0.9973178  -0.56231993  0.5846908 ], Reward: -0.32209616899490356\n",
      "Episode: 1, Step: 154, Action: [ 0.27493525 -0.39112633  0.702142    0.46729177], Reward: -0.3228759765625\n",
      "Episode: 1, Step: 155, Action: [ 0.6472911 -0.5213154 -0.9477566 -0.6795412], Reward: -0.32362696528434753\n",
      "Episode: 1, Step: 156, Action: [-0.17148739  0.43643764 -0.3432347  -0.7407374 ], Reward: -0.3239337205886841\n",
      "Episode: 1, Step: 157, Action: [-0.21760865 -0.9048842  -0.16007185 -0.4333096 ], Reward: -0.32389572262763977\n",
      "Episode: 1, Step: 158, Action: [-0.01304655 -0.7248159   0.9407971  -0.77574706], Reward: -0.3234122693538666\n",
      "Episode: 1, Step: 159, Action: [-0.9848462  -0.3245366  -0.6171312  -0.11231746], Reward: -0.32303112745285034\n",
      "Episode: 1, Step: 160, Action: [-0.1992734   0.67807364 -0.786709    0.68120384], Reward: -0.3228073716163635\n",
      "Episode: 1, Step: 161, Action: [-0.48635367 -0.9237561   0.49369177 -0.7937307 ], Reward: -0.32153332233428955\n",
      "Episode: 1, Step: 162, Action: [-0.5468428   0.7618227   0.5967209  -0.69938123], Reward: -0.3195551633834839\n",
      "Episode: 1, Step: 163, Action: [-0.77180547  0.78827375 -0.6235879   0.33737135], Reward: -0.3175344169139862\n",
      "Episode: 1, Step: 164, Action: [-0.08804979 -0.36434308 -0.87241703  0.63341814], Reward: -0.31637871265411377\n",
      "Episode: 1, Step: 165, Action: [-0.333199    0.55836606 -0.741048   -0.35877442], Reward: -0.31498774886131287\n",
      "Episode: 1, Step: 166, Action: [0.18702355 0.2602282  0.07672521 0.32352704], Reward: -0.31405162811279297\n",
      "Episode: 1, Step: 167, Action: [-0.13287406 -0.9193179  -0.73684645  0.77990514], Reward: -0.3135761320590973\n",
      "Episode: 1, Step: 168, Action: [-0.68276805  0.7008675   0.72468466 -0.6004835 ], Reward: -0.31218260526657104\n",
      "Episode: 1, Step: 169, Action: [-0.11854705  0.03049547 -0.18060684  0.9914257 ], Reward: -0.31177669763565063\n",
      "Episode: 1, Step: 170, Action: [-0.13081145 -0.5903696   0.56428295 -0.38306502], Reward: -0.31095588207244873\n",
      "Episode: 1, Step: 171, Action: [-0.69343174 -0.8844279  -0.8248513  -0.03420381], Reward: -0.3102562427520752\n",
      "Episode: 1, Step: 172, Action: [-0.85435313 -0.4270599   0.21767992  0.8101494 ], Reward: -0.3088715970516205\n",
      "Episode: 1, Step: 173, Action: [ 0.25476736  0.01058746 -0.01316509  0.7934918 ], Reward: -0.3079786002635956\n",
      "Episode: 1, Step: 174, Action: [ 0.60924596 -0.10265839 -0.05149085  0.54417497], Reward: -0.30750322341918945\n",
      "Episode: 1, Step: 175, Action: [ 0.06701019  0.8381745  -0.18250152  0.7824302 ], Reward: -0.3077732026576996\n",
      "Episode: 1, Step: 176, Action: [ 0.34154662  0.9529117   0.9371311  -0.7541553 ], Reward: -0.307952344417572\n",
      "Episode: 1, Step: 177, Action: [-0.28295705  0.7989748   0.02415539 -0.11356474], Reward: -0.30776655673980713\n",
      "Episode: 1, Step: 178, Action: [-0.11726519 -0.8464228  -0.37600487 -0.9759161 ], Reward: -0.3077777028083801\n",
      "Episode: 1, Step: 179, Action: [-0.62981963  0.609359    0.76032615  0.06690345], Reward: -0.30672574043273926\n",
      "Episode: 1, Step: 180, Action: [-0.01879015  0.71925753 -0.12307786 -0.23257881], Reward: -0.3061278164386749\n",
      "Episode: 1, Step: 181, Action: [-0.7466775  -0.9278473   0.5724362   0.72760373], Reward: -0.3048681914806366\n",
      "Episode: 1, Step: 182, Action: [-0.90254694  0.84777373  0.15875046 -0.0608195 ], Reward: -0.3033049404621124\n",
      "Episode: 1, Step: 183, Action: [ 0.8222622   0.543495   -0.55093676  0.80761606], Reward: -0.3025366961956024\n",
      "Episode: 1, Step: 184, Action: [-0.7927543   0.8041543   0.68640006 -0.08734719], Reward: -0.3010960817337036\n",
      "Episode: 1, Step: 185, Action: [-0.8131285  -0.45651126  0.19510882 -0.40829   ], Reward: -0.29912975430488586\n",
      "Episode: 1, Step: 186, Action: [-0.8674433   0.04652259  0.7239306   0.55693454], Reward: -0.2962649464607239\n",
      "Episode: 1, Step: 187, Action: [ 0.79068804 -0.5122312  -0.24653871 -0.00699651], Reward: -0.2944505512714386\n",
      "Episode: 1, Step: 188, Action: [ 0.6314929   0.25697178  0.10079595 -0.24722229], Reward: -0.29298093914985657\n",
      "Episode: 1, Step: 189, Action: [ 0.37696612  0.55004907 -0.18675753  0.3738066 ], Reward: -0.2923548221588135\n",
      "Episode: 1, Step: 190, Action: [ 0.03777491 -0.13666162  0.96109784  0.85952806], Reward: -0.2919372320175171\n",
      "Episode: 1, Step: 191, Action: [ 0.21367346 -0.8223127   0.49004462 -0.22641698], Reward: -0.29147347807884216\n",
      "Episode: 1, Step: 192, Action: [ 0.22120473  0.25656924  0.88592273 -0.32495067], Reward: -0.2912539541721344\n",
      "Episode: 1, Step: 193, Action: [ 0.02266322 -0.664516   -0.54438484 -0.01074263], Reward: -0.29109323024749756\n",
      "Episode: 1, Step: 194, Action: [-0.25819197 -0.89247376 -0.6978757   0.9930568 ], Reward: -0.29088646173477173\n",
      "Episode: 1, Step: 195, Action: [0.22201796 0.63306075 0.09527689 0.87839454], Reward: -0.29086214303970337\n",
      "Episode: 1, Step: 196, Action: [-0.80324143  0.55010873  0.34142533  0.3945309 ], Reward: -0.2900855243206024\n",
      "Episode: 1, Step: 197, Action: [-0.06783279 -0.9550282  -0.5876791   0.49879903], Reward: -0.2897895276546478\n",
      "Episode: 1, Step: 198, Action: [ 0.20063266 -0.11028779 -0.617489    0.12879041], Reward: -0.29041528701782227\n",
      "Episode: 1, Step: 199, Action: [-0.7746604   0.36205724 -0.20503189 -0.6371873 ], Reward: -0.2904260754585266\n",
      "Episode: 1, Step: 200, Action: [-0.8779854   0.14523451  0.56028754 -0.02153772], Reward: -0.2897608280181885\n",
      "Episode: 1, Step: 201, Action: [ 0.5490824   0.8069515  -0.25640061  0.6157284 ], Reward: -0.2899131774902344\n",
      "Episode: 1, Step: 202, Action: [ 0.59938514  0.68156326  0.3276074  -0.6133761 ], Reward: -0.29022279381752014\n",
      "Episode: 1, Step: 203, Action: [ 0.67092437  0.98545915  0.44709492 -0.27616754], Reward: -0.2906103730201721\n",
      "Episode: 1, Step: 204, Action: [0.9742592  0.608385   0.21039209 0.28224632], Reward: -0.291536808013916\n",
      "Episode: 1, Step: 205, Action: [ 0.38210303 -0.5849901  -0.94255626  0.35533938], Reward: -0.29332104325294495\n",
      "Episode: 1, Step: 206, Action: [-0.4013058  0.2095121  0.5770869  0.5144116], Reward: -0.2942967116832733\n",
      "Episode: 1, Step: 207, Action: [ 0.88647074 -0.9693913  -0.05671424 -0.13220607], Reward: -0.29584652185440063\n",
      "Episode: 1, Step: 208, Action: [-0.15348707  0.3366773  -0.4845198  -0.18175973], Reward: -0.2975018322467804\n",
      "Episode: 1, Step: 209, Action: [-0.5525317  -0.60096854  0.22302039 -0.51103675], Reward: -0.2983381152153015\n",
      "Episode: 1, Step: 210, Action: [-0.88768506  0.7966505  -0.30476022 -0.91869986], Reward: -0.2990967631340027\n",
      "Episode: 1, Step: 211, Action: [0.48823336 0.55644476 0.9146689  0.01359423], Reward: -0.2999570369720459\n",
      "Episode: 1, Step: 212, Action: [-0.2639128   0.71703786 -0.61006325  0.86929935], Reward: -0.300957053899765\n",
      "Episode: 1, Step: 213, Action: [ 0.37427774  0.75686145 -0.4189868  -0.76229835], Reward: -0.3024957776069641\n",
      "Episode: 1, Step: 214, Action: [-0.23034862  0.47513014  0.651427    0.86508214], Reward: -0.3032701015472412\n",
      "Episode: 1, Step: 215, Action: [-0.8715885  -0.96759856  0.3161198   0.8317762 ], Reward: -0.3031696379184723\n",
      "Episode: 1, Step: 216, Action: [ 0.86525446 -0.5770863  -0.36765885 -0.4738875 ], Reward: -0.3035101592540741\n",
      "Episode: 1, Step: 217, Action: [-0.23129368  0.18038887 -0.18274143 -0.06537338], Reward: -0.30335789918899536\n",
      "Episode: 1, Step: 218, Action: [ 0.23317795 -0.93239504 -0.542792   -0.9571211 ], Reward: -0.30353641510009766\n",
      "Episode: 1, Step: 219, Action: [ 0.5210335   0.35489124 -0.48091233  0.9549313 ], Reward: -0.3042207956314087\n",
      "Episode: 1, Step: 220, Action: [-0.05388044  0.7892635   0.7103236  -0.75919145], Reward: -0.30426421761512756\n",
      "Episode: 1, Step: 221, Action: [ 0.21429719 -0.29367608 -0.29840323  0.25860536], Reward: -0.30507826805114746\n",
      "Episode: 1, Step: 222, Action: [-0.6272333  -0.5935486  -0.76401573  0.12307169], Reward: -0.3058655560016632\n",
      "Episode: 1, Step: 223, Action: [-0.7021244  -0.90341073  0.5276419   0.73859113], Reward: -0.30547282099723816\n",
      "Episode: 1, Step: 224, Action: [0.9045891  0.30314776 0.5908592  0.26798162], Reward: -0.30528557300567627\n",
      "Episode: 1, Step: 225, Action: [ 0.3530594  -0.19277677  0.20697796  0.02613636], Reward: -0.3054857552051544\n",
      "Episode: 1, Step: 226, Action: [-0.68478304  0.32740322 -0.8074761   0.9104598 ], Reward: -0.3058883547782898\n",
      "Episode: 1, Step: 227, Action: [0.5932197  0.33597952 0.14908856 0.8527371 ], Reward: -0.3064105808734894\n",
      "Episode: 1, Step: 228, Action: [0.7177378  0.54459757 0.08780482 0.32832924], Reward: -0.3075129985809326\n",
      "Episode: 1, Step: 229, Action: [-0.7080813  -0.7702512   0.7517946   0.18263029], Reward: -0.3077589273452759\n",
      "Episode: 1, Step: 230, Action: [ 0.48196763  0.2793902  -0.88596815 -0.620204  ], Reward: -0.30897510051727295\n",
      "Episode: 1, Step: 231, Action: [ 0.7751434   0.3742413  -0.65259135 -0.17443101], Reward: -0.311109721660614\n",
      "Episode: 1, Step: 232, Action: [ 0.24104425 -0.9806012  -0.21112339  0.9185317 ], Reward: -0.3125077188014984\n",
      "Episode: 1, Step: 233, Action: [ 0.3675059  -0.1698915   0.25806955  0.795154  ], Reward: -0.31404170393943787\n",
      "Episode: 1, Step: 234, Action: [ 0.31576386 -0.5102165  -0.9510205  -0.03274191], Reward: -0.31564861536026\n",
      "Episode: 1, Step: 235, Action: [-0.11699942 -0.02860508  0.32138398 -0.5275613 ], Reward: -0.31643176078796387\n",
      "Episode: 1, Step: 236, Action: [-0.9655773  -0.13241334  0.6470388  -0.9128669 ], Reward: -0.3163842558860779\n",
      "Episode: 1, Step: 237, Action: [-0.54448014  0.10395777 -0.94389975  0.29202953], Reward: -0.31635814905166626\n",
      "Episode: 1, Step: 238, Action: [-0.4872731  -0.97417545  0.6661139  -0.07161447], Reward: -0.3155944049358368\n",
      "Episode: 1, Step: 239, Action: [-0.76576763 -0.792689   -0.30262494 -0.7139941 ], Reward: -0.3146858215332031\n",
      "Episode: 1, Step: 240, Action: [ 0.5697458  -0.97726494  0.97163546  0.22696161], Reward: -0.3138308823108673\n",
      "Episode: 1, Step: 241, Action: [ 0.9560283   0.88115716  0.9734151  -0.3763533 ], Reward: -0.3131171464920044\n",
      "Episode: 1, Step: 242, Action: [-0.9434987   0.01979542  0.7589438  -0.73080236], Reward: -0.3118511140346527\n",
      "Episode: 1, Step: 243, Action: [ 0.65394217 -0.3109241   0.30814484  0.35028428], Reward: -0.31126266717910767\n",
      "Episode: 1, Step: 244, Action: [ 0.99593073 -0.4263509   0.30191138 -0.44227397], Reward: -0.31096938252449036\n",
      "Episode: 1, Step: 245, Action: [-0.3522581  -0.1232907  -0.34967792 -0.5589773 ], Reward: -0.310749888420105\n",
      "Episode: 1, Step: 246, Action: [ 0.570422    0.26178885 -0.01197972  0.9934589 ], Reward: -0.31105443835258484\n",
      "Episode: 1, Step: 247, Action: [ 0.62598014  0.6043944  -0.0031298  -0.97605306], Reward: -0.3119301199913025\n",
      "Episode: 1, Step: 248, Action: [-0.20945293  0.9923395   0.7897576  -0.58779633], Reward: -0.3120591640472412\n",
      "Episode: 1, Step: 249, Action: [ 0.947768   -0.5870441   0.00994804  0.45163858], Reward: -0.3128102421760559\n",
      "Episode: 1, Step: 250, Action: [ 0.96857387 -0.28447476 -0.05770229  0.09268653], Reward: -0.3140241205692291\n",
      "Episode: 1, Step: 251, Action: [0.42917222 0.5543937  0.01626165 0.8597195 ], Reward: -0.31568461656570435\n",
      "Episode: 1, Step: 252, Action: [-0.7667708   0.08298831 -0.5577812  -0.79160315], Reward: -0.3173680007457733\n",
      "Episode: 1, Step: 253, Action: [ 0.8291571  -0.9965092   0.5995007  -0.15728633], Reward: -0.31911206245422363\n",
      "Episode: 1, Step: 254, Action: [-0.64155644  0.93338495  0.7081879  -0.8448234 ], Reward: -0.3201712667942047\n",
      "Episode: 1, Step: 255, Action: [-0.8514972  -0.9557937   0.89831436  0.2903749 ], Reward: -0.3204694390296936\n",
      "Episode: 1, Step: 256, Action: [-0.7991644  -0.5564559  -0.5866068   0.87508607], Reward: -0.3206472396850586\n",
      "Episode: 1, Step: 257, Action: [ 0.8492448   0.4763877   0.33449498 -0.14862071], Reward: -0.3209846019744873\n",
      "Episode: 1, Step: 258, Action: [ 0.78845835 -0.99945176 -0.3828064   0.9238186 ], Reward: -0.32210803031921387\n",
      "Episode: 1, Step: 259, Action: [-0.1380653  -0.48138824 -0.13836904 -0.48485368], Reward: -0.32297149300575256\n",
      "Episode: 1, Step: 260, Action: [-0.8299213  -0.97480875  0.07710891  0.94878787], Reward: -0.32302674651145935\n",
      "Episode: 1, Step: 261, Action: [-0.32062238 -0.19089267 -0.9632765   0.72067475], Reward: -0.32307782769203186\n",
      "Episode: 1, Step: 262, Action: [ 0.82630527 -0.44426405 -0.79099417 -0.41395673], Reward: -0.3239407241344452\n",
      "Episode: 1, Step: 263, Action: [-0.00522508 -0.7671416  -0.23837678  0.84012896], Reward: -0.32408764958381653\n",
      "Episode: 1, Step: 264, Action: [ 0.93937206  0.5636693   0.42206484 -0.66539115], Reward: -0.32441088557243347\n",
      "Episode: 1, Step: 265, Action: [ 0.85706234 -0.76868993  0.34843433 -0.3238331 ], Reward: -0.3248523473739624\n",
      "Episode: 1, Step: 266, Action: [-0.5517126  -0.6963397   0.9814445   0.43733704], Reward: -0.3245883285999298\n",
      "Episode: 1, Step: 267, Action: [ 0.04528816  0.07556656 -0.2733335  -0.6261701 ], Reward: -0.32443809509277344\n",
      "Episode: 1, Step: 268, Action: [-0.8187798   0.6240947  -0.5228768  -0.54958135], Reward: -0.324458509683609\n",
      "Episode: 1, Step: 269, Action: [ 0.6835734  -0.16896898  0.731382    0.4213452 ], Reward: -0.32460033893585205\n",
      "Episode: 1, Step: 270, Action: [ 0.02694882 -0.10475412  0.01028528  0.9682958 ], Reward: -0.3246205449104309\n",
      "Episode: 1, Step: 271, Action: [-0.31593356  0.07333589  0.07439292 -0.09510999], Reward: -0.32414233684539795\n",
      "Episode: 1, Step: 272, Action: [-0.22370026  0.25045773 -0.66192853 -0.44485068], Reward: -0.3237232565879822\n",
      "Episode: 1, Step: 273, Action: [-0.4789317   0.48445818  0.44146878 -0.45268652], Reward: -0.3226814270019531\n",
      "Episode: 1, Step: 274, Action: [ 0.49532947  0.65634733  0.69971853 -0.50155574], Reward: -0.3217224180698395\n",
      "Episode: 1, Step: 275, Action: [-0.89448565  0.7072423   0.6589301   0.7987795 ], Reward: -0.32009264826774597\n",
      "Episode: 1, Step: 276, Action: [ 0.8952874   0.40576792 -0.06380076 -0.9586867 ], Reward: -0.3192884922027588\n",
      "Episode: 1, Step: 277, Action: [ 0.25397274  0.87651706  0.33510247 -0.8706987 ], Reward: -0.3187723457813263\n",
      "Episode: 1, Step: 278, Action: [ 0.5801907  -0.21888646 -0.9910885   0.7600183 ], Reward: -0.318996399641037\n",
      "Episode: 1, Step: 279, Action: [ 0.3229844  -0.49309415  0.939706   -0.7340592 ], Reward: -0.3192801773548126\n",
      "Episode: 1, Step: 280, Action: [ 0.609003    0.52678853  0.79591703 -0.03526936], Reward: -0.31988343596458435\n",
      "Episode: 1, Step: 281, Action: [-0.38727796 -0.20130606 -0.47234902 -0.88671356], Reward: -0.3202851116657257\n",
      "Episode: 1, Step: 282, Action: [-0.13325848  0.79200214  0.7787281   0.43069795], Reward: -0.32019728422164917\n",
      "Episode: 1, Step: 283, Action: [ 0.67009664  0.01360249 -0.56880546  0.00963702], Reward: -0.32069921493530273\n",
      "Episode: 1, Step: 284, Action: [-0.50641644 -0.23214827  0.10106194 -0.99129474], Reward: -0.32074135541915894\n",
      "Episode: 1, Step: 285, Action: [-0.9713546  -0.25887695  0.17290491 -0.7454445 ], Reward: -0.32027238607406616\n",
      "Episode: 1, Step: 286, Action: [-0.617771    0.006019    0.98439115 -0.9554621 ], Reward: -0.319040983915329\n",
      "Episode: 1, Step: 287, Action: [ 0.87617624  0.04311945  0.2715752  -0.0778382 ], Reward: -0.3184794783592224\n",
      "Episode: 1, Step: 288, Action: [-0.20911954  0.5107971  -0.27249888  0.9708271 ], Reward: -0.3178548216819763\n",
      "Episode: 1, Step: 289, Action: [ 0.8023349  -0.40332907  0.3445969   0.33558837], Reward: -0.3172810971736908\n",
      "Episode: 1, Step: 290, Action: [-0.7078374 -0.7961047 -0.8360857 -0.4803533], Reward: -0.31660330295562744\n",
      "Episode: 1, Step: 291, Action: [ 0.91476107 -0.31973994  0.73739594  0.6405048 ], Reward: -0.31609922647476196\n",
      "Episode: 1, Step: 292, Action: [-0.56515294  0.40721902 -0.07121391 -0.32739088], Reward: -0.31536898016929626\n",
      "Episode: 1, Step: 293, Action: [-0.5549146   0.59084654 -0.18839808  0.49947226], Reward: -0.31434401869773865\n",
      "Episode: 1, Step: 294, Action: [-0.42019328 -0.3493184   0.0195973  -0.8602611 ], Reward: -0.3126750588417053\n",
      "Episode: 1, Step: 295, Action: [0.86457527 0.23439404 0.65858954 0.2031765 ], Reward: -0.311155766248703\n",
      "Episode: 1, Step: 296, Action: [ 0.6491307   0.26134074  0.8844607  -0.01981697], Reward: -0.30993327498435974\n",
      "Episode: 1, Step: 297, Action: [ 0.99487954 -0.5538923   0.9161083   0.977832  ], Reward: -0.30890214443206787\n",
      "Episode: 1, Step: 298, Action: [-0.34130624  0.3597633   0.7378931  -0.48818624], Reward: -0.3074282705783844\n",
      "Episode: 1, Step: 299, Action: [ 0.8762235  -0.5234882  -0.76540923  0.00835756], Reward: -0.3066207766532898\n",
      "Episode: 1, Step: 300, Action: [ 0.20263667 -0.56506956 -0.13984922 -0.2734278 ], Reward: -0.3066633939743042\n",
      "Episode: 1, Step: 301, Action: [ 0.7365685  -0.7306362   0.93500113 -0.91022843], Reward: -0.3066667914390564\n",
      "Episode: 1, Step: 302, Action: [-0.6650472   0.213346    0.9279892  -0.28675318], Reward: -0.30616843700408936\n",
      "Episode: 1, Step: 303, Action: [ 0.05159974 -0.93918926  0.30557758  0.23922321], Reward: -0.30604785680770874\n",
      "Episode: 1, Step: 304, Action: [-0.6536731   0.29368916  0.37155885  0.790544  ], Reward: -0.30534687638282776\n",
      "Episode: 1, Step: 305, Action: [-0.5103485   0.77408606 -0.37840974 -0.9244497 ], Reward: -0.30464884638786316\n",
      "Episode: 1, Step: 306, Action: [-0.25289428  0.61636454  0.14114568  0.42870793], Reward: -0.3036322593688965\n",
      "Episode: 1, Step: 307, Action: [ 0.33884162  0.18344615  0.52934736 -0.70300126], Reward: -0.3028194308280945\n",
      "Episode: 1, Step: 308, Action: [ 0.715125   -0.724867   -0.664206    0.52285886], Reward: -0.30258551239967346\n",
      "Episode: 1, Step: 309, Action: [-0.6008007   0.40245342 -0.2197679   0.5308624 ], Reward: -0.30229219794273376\n",
      "Episode: 1, Step: 310, Action: [ 0.5291839  -0.7251403  -0.83452594 -0.02272573], Reward: -0.30273881554603577\n",
      "Episode: 1, Step: 311, Action: [-0.25329763 -0.8448317   0.16153724  0.10175462], Reward: -0.30239835381507874\n",
      "Episode: 1, Step: 312, Action: [-0.2618741   0.0278651   0.7710763  -0.02390695], Reward: -0.301421195268631\n",
      "Episode: 1, Step: 313, Action: [ 0.6430734   0.5519821   0.47727644 -0.51288325], Reward: -0.3008904457092285\n",
      "Episode: 1, Step: 314, Action: [ 0.48176533 -0.6534712  -0.7652731  -0.9846096 ], Reward: -0.30085137486457825\n",
      "Episode: 1, Step: 315, Action: [ 0.26373374  0.733217   -0.58546185 -0.4341095 ], Reward: -0.30170905590057373\n",
      "Episode: 1, Step: 316, Action: [-0.5405664   0.9133591  -0.19367947  0.8950041 ], Reward: -0.30201855301856995\n",
      "Episode: 1, Step: 317, Action: [ 0.36414284 -0.66714597  0.9465342   0.05216748], Reward: -0.3024037182331085\n",
      "Episode: 1, Step: 318, Action: [-0.7751005  -0.32488817  0.71159905  0.90622956], Reward: -0.30210357904434204\n",
      "Episode: 1, Step: 319, Action: [ 0.11815798  0.312131    0.24639189 -0.6353607 ], Reward: -0.30225151777267456\n",
      "Episode: 1, Step: 320, Action: [ 0.82875293  0.23219742 -0.25488153  0.83897996], Reward: -0.30319708585739136\n",
      "Episode: 1, Step: 321, Action: [-0.37251315  0.14773153 -0.8692053  -0.26147896], Reward: -0.3039563000202179\n",
      "Episode: 1, Step: 322, Action: [ 0.5066304  -0.42049834  0.52905196  0.9371858 ], Reward: -0.3049081563949585\n",
      "Episode: 1, Step: 323, Action: [-0.85140574  0.36564553 -0.7552396  -0.01936567], Reward: -0.3057522177696228\n",
      "Episode: 1, Step: 324, Action: [ 0.01824235  0.567936    0.10644406 -0.19372828], Reward: -0.3062785863876343\n",
      "Episode: 1, Step: 325, Action: [ 0.96281785 -0.8910276   0.01680324  0.47945723], Reward: -0.30684801936149597\n",
      "Episode: 1, Step: 326, Action: [ 0.611563    0.24839681 -0.37554345 -0.88681024], Reward: -0.3082868158817291\n",
      "Episode: 1, Step: 327, Action: [ 0.84706473  0.6816805  -0.94055814  0.75806767], Reward: -0.3106399476528168\n",
      "Episode: 1, Step: 328, Action: [ 0.27563572 -0.4454635  -0.59678704  0.73085463], Reward: -0.31252408027648926\n",
      "Episode: 1, Step: 329, Action: [ 0.49151114 -0.48953047  0.40904585  0.5801426 ], Reward: -0.31451159715652466\n",
      "Episode: 1, Step: 330, Action: [0.3544407  0.8806075  0.42722887 0.20836398], Reward: -0.316277414560318\n",
      "Episode: 1, Step: 331, Action: [-0.62784046  0.7255371  -0.93403447 -0.51787996], Reward: -0.31801173090934753\n",
      "Episode: 1, Step: 332, Action: [ 0.602764    0.5487478  -0.11905631 -0.32709235], Reward: -0.3200403153896332\n",
      "Episode: 1, Step: 333, Action: [ 0.6083237  -0.17319052 -0.17058526 -0.11070823], Reward: -0.3223116099834442\n",
      "Episode: 1, Step: 334, Action: [ 0.04435716 -0.6853346  -0.87881064 -0.45868495], Reward: -0.32446420192718506\n",
      "Episode: 1, Step: 335, Action: [-0.84894305  0.90570414  0.9519612  -0.1957348 ], Reward: -0.3260086178779602\n",
      "Episode: 1, Step: 336, Action: [ 0.13415958  0.1284652  -0.23465957  0.44149718], Reward: -0.32706186175346375\n",
      "Episode: 1, Step: 337, Action: [ 0.0463467 -0.9809444  0.2807937 -0.6566628], Reward: -0.3273249864578247\n",
      "Episode: 1, Step: 338, Action: [ 0.9156719 -0.7248603  0.1264233 -0.8450921], Reward: -0.3277282118797302\n",
      "Episode: 1, Step: 339, Action: [ 0.99143535  0.34379226  0.8702399  -0.7381177 ], Reward: -0.32843685150146484\n",
      "Episode: 1, Step: 340, Action: [-0.09476115 -0.7192337  -0.09457162 -0.36345303], Reward: -0.3290218710899353\n",
      "Episode: 1, Step: 341, Action: [ 0.43377304 -0.9583613   0.46310487  0.880687  ], Reward: -0.3296442925930023\n",
      "Episode: 1, Step: 342, Action: [-0.34325615 -0.902559    0.28701296  0.20842618], Reward: -0.329758882522583\n",
      "Episode: 1, Step: 343, Action: [0.3273504  0.54198956 0.8622014  0.03836778], Reward: -0.33010655641555786\n",
      "Episode: 1, Step: 344, Action: [-0.29451352  0.90793204  0.5221034   0.5200053 ], Reward: -0.33008795976638794\n",
      "Episode: 1, Step: 345, Action: [-0.8933171   0.69953245 -0.6194657  -0.4390345 ], Reward: -0.3301467299461365\n",
      "Episode: 1, Step: 346, Action: [ 0.6848314   0.03833143 -0.15314697 -0.7874225 ], Reward: -0.3309495449066162\n",
      "Episode: 1, Step: 347, Action: [-0.40317056 -0.44852734 -0.9489343   0.5557061 ], Reward: -0.33140772581100464\n",
      "Episode: 1, Step: 348, Action: [-0.07627013 -0.6985882   0.04827428  0.23790446], Reward: -0.33124712109565735\n",
      "Episode: 1, Step: 349, Action: [ 0.30513287  0.72850585 -0.84574974  0.6034729 ], Reward: -0.3319382667541504\n",
      "Episode: 1, Step: 350, Action: [ 0.78365016  0.03288798 -0.31087303 -0.08160492], Reward: -0.3328731656074524\n",
      "Episode: 1, Step: 351, Action: [-0.7391603   0.20913662 -0.4109503  -0.518103  ], Reward: -0.3336489200592041\n",
      "Episode: 1, Step: 352, Action: [-0.04714156  0.88157916 -0.2372626  -0.40711644], Reward: -0.3339509963989258\n",
      "Episode: 1, Step: 353, Action: [-0.6790836   0.05483979  0.50595933 -0.7061006 ], Reward: -0.33351245522499084\n",
      "Episode: 1, Step: 354, Action: [-0.23642974 -0.95391035  0.12614627  0.19028248], Reward: -0.33246752619743347\n",
      "Episode: 1, Step: 355, Action: [ 0.77940977 -0.97349054  0.48711234 -0.8257993 ], Reward: -0.33149096369743347\n",
      "Episode: 1, Step: 356, Action: [ 0.483181    0.25873935 -0.43807656  0.08267573], Reward: -0.33140596747398376\n",
      "Episode: 1, Step: 357, Action: [0.22815023 0.59474266 0.7193813  0.09395109], Reward: -0.33158794045448303\n",
      "Episode: 1, Step: 358, Action: [ 0.97921145 -0.8743228  -0.96507937 -0.43959993], Reward: -0.3324163258075714\n",
      "Episode: 1, Step: 359, Action: [ 0.8157401   0.17273654 -0.75158525  0.41321117], Reward: -0.3341807723045349\n",
      "Episode: 1, Step: 360, Action: [-0.6597584   0.5936465   0.09983946  0.57413006], Reward: -0.33539241552352905\n",
      "Episode: 1, Step: 361, Action: [-0.6603715   0.5319752  -0.3019427  -0.81789976], Reward: -0.3364640474319458\n",
      "Episode: 1, Step: 362, Action: [ 0.96705014  0.9112399   0.771333   -0.55647486], Reward: -0.3377547264099121\n",
      "Episode: 1, Step: 363, Action: [-0.90740806 -0.1375565  -0.17120072 -0.63507116], Reward: -0.3386898636817932\n",
      "Episode: 1, Step: 364, Action: [ 0.97573227  0.9579249  -0.8051001   0.18805136], Reward: -0.34062036871910095\n",
      "Episode: 1, Step: 365, Action: [-0.26767606  0.503816    0.5292099   0.795799  ], Reward: -0.34163355827331543\n",
      "Episode: 1, Step: 366, Action: [ 0.5909224  -0.14599703 -0.98613054 -0.19577728], Reward: -0.34348803758621216\n",
      "Episode: 1, Step: 367, Action: [-0.12524886 -0.783517    0.5206601   0.8776794 ], Reward: -0.3444885313510895\n",
      "Episode: 1, Step: 368, Action: [ 0.24468425  0.49935174 -0.7084214   0.10146727], Reward: -0.34638741612434387\n",
      "Episode: 1, Step: 369, Action: [ 0.75875866 -0.5142198  -0.8486004  -0.5746839 ], Reward: -0.3488527536392212\n",
      "Episode: 1, Step: 370, Action: [ 0.46698382 -0.2897618   0.2017646   0.39902097], Reward: -0.3506004214286804\n",
      "Episode: 1, Step: 371, Action: [-0.8202286   0.99060553  0.09709193  0.05034975], Reward: -0.35191017389297485\n",
      "Episode: 1, Step: 372, Action: [-0.928806   -0.6113833  -0.18594104  0.67523074], Reward: -0.3527121841907501\n",
      "Episode: 1, Step: 373, Action: [-0.95124906 -0.99159163  0.40466058 -0.9084166 ], Reward: -0.3527369797229767\n",
      "Episode: 1, Step: 374, Action: [ 0.32399306 -0.28904438  0.8366566   0.20737681], Reward: -0.3528439998626709\n",
      "Episode: 1, Step: 375, Action: [ 0.5185883  -0.09682389 -0.63162184 -0.21015328], Reward: -0.3537641763687134\n",
      "Episode: 1, Step: 376, Action: [0.36144254 0.22084254 0.00585845 0.414901  ], Reward: -0.35517579317092896\n",
      "Episode: 1, Step: 377, Action: [ 0.77870935 -0.46322185  0.22562587  0.581237  ], Reward: -0.3565976023674011\n",
      "Episode: 1, Step: 378, Action: [-0.79660195 -0.74311155 -0.236524    0.05559658], Reward: -0.3578890562057495\n",
      "Episode: 1, Step: 379, Action: [-0.96441984  0.76886106 -0.00945104 -0.8310385 ], Reward: -0.35882821679115295\n",
      "Episode: 1, Step: 380, Action: [ 0.9368558  -0.8193773   0.9648558   0.14328708], Reward: -0.35978081822395325\n",
      "Episode: 1, Step: 381, Action: [-0.6364363  0.9385362 -0.9642381 -0.6195276], Reward: -0.36074313521385193\n",
      "Episode: 1, Step: 382, Action: [ 0.20056507  0.31172276  0.31345642 -0.2298635 ], Reward: -0.36143866181373596\n",
      "Episode: 1, Step: 383, Action: [-0.03463184 -0.7361844  -0.5588356  -0.12561594], Reward: -0.3619241714477539\n",
      "Episode: 1, Step: 384, Action: [-0.22021759 -0.4181492  -0.89019966  0.4856767 ], Reward: -0.3622366786003113\n",
      "Episode: 1, Step: 385, Action: [-0.42948323 -0.30404246 -0.76251036 -0.96755475], Reward: -0.3623369634151459\n",
      "Episode: 1, Step: 386, Action: [-0.31716734  0.685185    0.49810156 -0.6757649 ], Reward: -0.3612014055252075\n",
      "Episode: 1, Step: 387, Action: [-0.3382888   0.7002135  -0.46845546 -0.01182696], Reward: -0.359824538230896\n",
      "Episode: 1, Step: 388, Action: [ 0.9862072  -0.11142483  0.6792288   0.64994556], Reward: -0.358578085899353\n",
      "Episode: 1, Step: 389, Action: [-0.5133294  -0.5332838  -0.37726596 -0.60482794], Reward: -0.35710689425468445\n",
      "Episode: 1, Step: 390, Action: [ 0.92608017 -0.150888   -0.37435457  0.93074626], Reward: -0.3565007746219635\n",
      "Episode: 1, Step: 391, Action: [ 0.4781624  -0.2728143   0.28469428 -0.98100406], Reward: -0.35572534799575806\n",
      "Episode: 1, Step: 392, Action: [-0.16198286 -0.13522899 -0.510133    0.32393754], Reward: -0.35501718521118164\n",
      "Episode: 1, Step: 393, Action: [-0.2652435   0.93698746 -0.6240394  -0.3570513 ], Reward: -0.353837251663208\n",
      "Episode: 1, Step: 394, Action: [ 0.40816006 -0.504539   -0.6238353   0.32459524], Reward: -0.35312944650650024\n",
      "Episode: 1, Step: 395, Action: [-0.5169342   0.11832502  0.0854224  -0.64321256], Reward: -0.3519824147224426\n",
      "Episode: 1, Step: 396, Action: [ 0.12308637 -0.31146437  0.9524537   0.05051085], Reward: -0.35091471672058105\n",
      "Episode: 1, Step: 397, Action: [-0.22798024  0.7602639  -0.7253012  -0.7173424 ], Reward: -0.34998074173927307\n",
      "Episode: 1, Step: 398, Action: [-0.95212686 -0.79159456 -0.849891    0.02100649], Reward: -0.34894946217536926\n",
      "Episode: 1, Step: 399, Action: [ 0.5335465   0.5327772  -0.95648515  0.26430854], Reward: -0.3480170667171478\n",
      "Episode: 1, Step: 400, Action: [-0.6651159  -0.46536547  0.16721486  0.14914416], Reward: -0.3463817238807678\n",
      "Episode: 1, Step: 401, Action: [ 0.38287404  0.63399684 -0.51528     0.65919966], Reward: -0.3457260727882385\n",
      "Episode: 1, Step: 402, Action: [ 0.5828685  -0.06578519 -0.01969765  0.61888194], Reward: -0.34523260593414307\n",
      "Episode: 1, Step: 403, Action: [ 0.43705156 -0.82239956  0.5805873   0.35057095], Reward: -0.3448025584220886\n",
      "Episode: 1, Step: 404, Action: [ 0.14169462 -0.00646475  0.06483072  0.6699367 ], Reward: -0.3450269401073456\n",
      "Episode: 1, Step: 405, Action: [-0.4353711   0.23318018 -0.20700948  0.53983176], Reward: -0.34535902738571167\n",
      "Episode: 1, Step: 406, Action: [-0.58403367 -0.43614307 -0.894574    0.83819246], Reward: -0.34551677107810974\n",
      "Episode: 1, Step: 407, Action: [-0.43774647 -0.67502034 -0.8990189  -0.9644344 ], Reward: -0.3443090617656708\n",
      "Episode: 1, Step: 408, Action: [-0.84097946  0.31311688  0.831955   -0.16900086], Reward: -0.34251269698143005\n",
      "Episode: 1, Step: 409, Action: [-0.08577272 -0.92387336  0.70703864 -0.6745325 ], Reward: -0.3408152759075165\n",
      "Episode: 1, Step: 410, Action: [-0.86310256 -0.31903887 -0.88522565  0.04081324], Reward: -0.3389608860015869\n",
      "Episode: 1, Step: 411, Action: [0.48971882 0.9428056  0.2080234  0.4408706 ], Reward: -0.33760586380958557\n",
      "Episode: 1, Step: 412, Action: [-0.8259301   0.13216642  0.90491045 -0.71728975], Reward: -0.33571815490722656\n",
      "Episode: 1, Step: 413, Action: [ 0.9274654  -0.55342615 -0.19545037 -0.5731213 ], Reward: -0.33457958698272705\n",
      "Episode: 1, Step: 414, Action: [-0.53941363 -0.2843135  -0.59243524  0.76745087], Reward: -0.333291232585907\n",
      "Episode: 1, Step: 415, Action: [-0.05855574 -0.24282652 -0.2300108   0.89533865], Reward: -0.33245012164115906\n",
      "Episode: 1, Step: 416, Action: [ 0.18148197 -0.62868685  0.34716693 -0.6708505 ], Reward: -0.3317030370235443\n",
      "Episode: 1, Step: 417, Action: [-0.76687896  0.6616614  -0.36784157 -0.45897976], Reward: -0.33109021186828613\n",
      "Episode: 1, Step: 418, Action: [-0.25243124  0.09080099 -0.79349923 -0.37027115], Reward: -0.3308439552783966\n",
      "Episode: 1, Step: 419, Action: [ 0.8822933  -0.34044144 -0.56200886 -0.42503387], Reward: -0.33085867762565613\n",
      "Episode: 1, Step: 420, Action: [-0.36992845  0.9892312   0.514036   -0.17808244], Reward: -0.3297475278377533\n",
      "Episode: 1, Step: 421, Action: [ 0.0472375   0.5000156   0.8735428  -0.46011177], Reward: -0.32878363132476807\n",
      "Episode: 1, Step: 422, Action: [0.42619678 0.68983185 0.6676311  0.2775607 ], Reward: -0.32807186245918274\n",
      "Episode: 1, Step: 423, Action: [ 0.14695723  0.90757704  0.35238957 -0.3477153 ], Reward: -0.3280843198299408\n",
      "Episode: 1, Step: 424, Action: [-0.7912043  -0.62626284  0.07624132 -0.71642023], Reward: -0.3280181288719177\n",
      "Episode: 1, Step: 425, Action: [ 0.19258139 -0.8653934  -0.27307147 -0.6345315 ], Reward: -0.32862791419029236\n",
      "Episode: 1, Step: 426, Action: [ 0.44691938 -0.4441102   0.10784274  0.19526295], Reward: -0.3292887508869171\n",
      "Episode: 1, Step: 427, Action: [-0.7858662  -0.8602316   0.44235006  0.42992857], Reward: -0.3291186988353729\n",
      "Episode: 1, Step: 428, Action: [ 0.5858647  0.7630815 -0.9421446  0.524769 ], Reward: -0.3299075961112976\n",
      "Episode: 1, Step: 429, Action: [ 0.82133335  0.7515184  -0.8833269   0.6737613 ], Reward: -0.3315943777561188\n",
      "Episode: 1, Step: 430, Action: [-0.21336234 -0.00593173  0.09133101  0.424233  ], Reward: -0.33254575729370117\n",
      "Episode: 1, Step: 431, Action: [0.08497131 0.03967115 0.56341267 0.36498576], Reward: -0.3327648341655731\n",
      "Episode: 1, Step: 432, Action: [-0.51504284 -0.4805881   0.62899095  0.3623677 ], Reward: -0.33226078748703003\n",
      "Episode: 1, Step: 433, Action: [ 0.22486421  0.5547045   0.6649997  -0.6695765 ], Reward: -0.3319902718067169\n",
      "Episode: 1, Step: 434, Action: [-0.06764217  0.28831497 -0.46929634 -0.7243253 ], Reward: -0.33177024126052856\n",
      "Episode: 1, Step: 435, Action: [ 0.7982642   0.89155686 -0.63186365 -0.8602267 ], Reward: -0.3323938548564911\n",
      "Episode: 1, Step: 436, Action: [-0.8521999 -0.992422  -0.8810803 -0.9572975], Reward: -0.3329719603061676\n",
      "Episode: 1, Step: 437, Action: [-0.5193305   0.71151507 -0.5075272  -0.68823326], Reward: -0.3333870470523834\n",
      "Episode: 1, Step: 438, Action: [ 0.25322694  0.37267372  0.86144483 -0.94911957], Reward: -0.3339103162288666\n",
      "Episode: 1, Step: 439, Action: [ 0.28516072  0.3571035  -0.24914561  0.71448517], Reward: -0.33481481671333313\n",
      "Episode: 1, Step: 440, Action: [-0.9787074   0.09008994  0.53124315 -0.98943555], Reward: -0.3348262310028076\n",
      "Episode: 1, Step: 441, Action: [ 0.3079248  -0.624635    0.47766465 -0.45064533], Reward: -0.3348929286003113\n",
      "Episode: 1, Step: 442, Action: [-0.69082105 -0.7374287  -0.33218244 -0.22730102], Reward: -0.3348252475261688\n",
      "Episode: 1, Step: 443, Action: [-0.95597094  0.7204179   0.54451644  0.10137017], Reward: -0.33409103751182556\n",
      "Episode: 1, Step: 444, Action: [ 0.05901518 -0.52201754  0.05235565  0.8700176 ], Reward: -0.3338971436023712\n",
      "Episode: 1, Step: 445, Action: [-0.18373744 -0.25679004 -0.37065777 -0.6951775 ], Reward: -0.3335224688053131\n",
      "Episode: 1, Step: 446, Action: [0.5695022  0.86689705 0.4289246  0.75632644], Reward: -0.33345550298690796\n",
      "Episode: 1, Step: 447, Action: [0.48866412 0.16886231 0.11307849 0.9110793 ], Reward: -0.3337440490722656\n",
      "Episode: 1, Step: 448, Action: [ 0.7540793   0.35572746  0.07788821 -0.7360296 ], Reward: -0.3345639705657959\n",
      "Episode: 1, Step: 449, Action: [-0.9014073  -0.2913963   0.22049828 -0.6180431 ], Reward: -0.3347308933734894\n",
      "Episode: 1, Step: 450, Action: [-0.08714692  0.14466588  0.37066406  0.15108605], Reward: -0.33425843715667725\n",
      "Episode: 1, Step: 451, Action: [ 0.5191966   0.61930186  0.5665523  -0.08750831], Reward: -0.33405429124832153\n",
      "Episode: 1, Step: 452, Action: [ 0.3139791   0.64195216  0.3297042  -0.00437396], Reward: -0.33472299575805664\n",
      "Episode: 1, Step: 453, Action: [-0.06234018 -0.7663397  -0.08993321  0.3785143 ], Reward: -0.3353111445903778\n",
      "Episode: 1, Step: 454, Action: [-0.7774844  -0.37569082  0.68134135 -0.9643134 ], Reward: -0.3350479304790497\n",
      "Episode: 1, Step: 455, Action: [-0.98190755 -0.4979872  -0.0325381   0.8598933 ], Reward: -0.3345378637313843\n",
      "Episode: 1, Step: 456, Action: [-0.29771054  0.71475995  0.26029125  0.3756032 ], Reward: -0.33349621295928955\n",
      "Episode: 1, Step: 457, Action: [0.16261093 0.12739043 0.02961094 0.39677334], Reward: -0.3330128788948059\n",
      "Episode: 1, Step: 458, Action: [-0.5238677  -0.15252955 -0.55846554  0.7038511 ], Reward: -0.33243322372436523\n",
      "Episode: 1, Step: 459, Action: [-0.84465414 -0.7489977  -0.3004165  -0.18948972], Reward: -0.3312676250934601\n",
      "Episode: 1, Step: 460, Action: [ 0.3452044  -0.85772973 -0.49863276  0.20052664], Reward: -0.3307245969772339\n",
      "Episode: 1, Step: 461, Action: [ 0.10794767 -0.7356972  -0.32091612  0.86570567], Reward: -0.33031296730041504\n",
      "Episode: 1, Step: 462, Action: [ 0.52412605 -0.36119685  0.7212355  -0.15164664], Reward: -0.3300435543060303\n",
      "Episode: 1, Step: 463, Action: [-0.40657777 -0.07163779 -0.46752682  0.5070103 ], Reward: -0.3298456072807312\n",
      "Episode: 1, Step: 464, Action: [ 0.20881109 -0.43925273  0.32130125 -0.89774525], Reward: -0.3296855390071869\n",
      "Episode: 1, Step: 465, Action: [ 0.9098203   0.12849961 -0.44374928  0.84192413], Reward: -0.3303876519203186\n",
      "Episode: 1, Step: 466, Action: [ 0.43013912 -0.64224344  0.6146662   0.92166775], Reward: -0.3308134377002716\n",
      "Episode: 1, Step: 467, Action: [-0.79150224 -0.9170542   0.06982631 -0.9158975 ], Reward: -0.330666184425354\n",
      "Episode: 1, Step: 468, Action: [ 0.04334232 -0.59010416 -0.98004407  0.5445152 ], Reward: -0.33035287261009216\n",
      "Episode: 1, Step: 469, Action: [ 0.31086096 -0.9145003  -0.7355205   0.7449639 ], Reward: -0.33035051822662354\n",
      "Episode: 1, Step: 470, Action: [-0.8630071  -0.66992974 -0.46888965  0.57605   ], Reward: -0.3300655782222748\n",
      "Episode: 1, Step: 471, Action: [-0.7756047   0.29056808  0.5123568   0.58362997], Reward: -0.3291022777557373\n",
      "Episode: 1, Step: 472, Action: [-0.3527787   0.50509816  0.8809886   0.1018029 ], Reward: -0.32756519317626953\n",
      "Episode: 1, Step: 473, Action: [0.65767574 0.41631106 0.4198071  0.89048326], Reward: -0.3265647292137146\n",
      "Episode: 1, Step: 474, Action: [-0.70856273  0.2117834  -0.4147386   0.12343953], Reward: -0.3256991505622864\n",
      "Episode: 1, Step: 475, Action: [ 0.67827946  0.7572813   0.47872466 -0.81564605], Reward: -0.3249843418598175\n",
      "Episode: 1, Step: 476, Action: [ 0.34195533  0.27119485 -0.00493777 -0.72340703], Reward: -0.32522523403167725\n",
      "Episode: 1, Step: 477, Action: [ 0.7197056  -0.2393236   0.44982806  0.8487321 ], Reward: -0.32545527815818787\n",
      "Episode: 1, Step: 478, Action: [0.41855064 0.76681745 0.74325275 0.9717915 ], Reward: -0.325964093208313\n",
      "Episode: 1, Step: 479, Action: [-0.36624205  0.12467957  0.3747862  -0.50467694], Reward: -0.3262556493282318\n",
      "Episode: 1, Step: 480, Action: [ 0.20403805 -0.5844191  -0.5489785   0.6449656 ], Reward: -0.3269253671169281\n",
      "Episode: 1, Step: 481, Action: [ 0.8244475   0.2244434  -0.13828212 -0.5212035 ], Reward: -0.32840093970298767\n",
      "Episode: 1, Step: 482, Action: [ 0.64578927  0.6864026   0.14086136 -0.316949  ], Reward: -0.33014732599258423\n",
      "Episode: 1, Step: 483, Action: [ 0.35297075  0.84817713  0.57911277 -0.4701579 ], Reward: -0.33143311738967896\n",
      "Episode: 1, Step: 484, Action: [ 0.99691105 -0.34942272 -0.5599021   0.6192686 ], Reward: -0.33337125182151794\n",
      "Episode: 1, Step: 485, Action: [-0.25292984 -0.14221895 -0.5539684  -0.38553703], Reward: -0.3352348804473877\n",
      "Episode: 1, Step: 486, Action: [-0.4184119   0.6988296  -0.9611461  -0.95261437], Reward: -0.3370940387248993\n",
      "Episode: 1, Step: 487, Action: [ 0.8770899   0.5325673   0.25243157 -0.46943182], Reward: -0.3391318917274475\n",
      "Episode: 1, Step: 488, Action: [-0.90873903 -0.794723    0.77139235  0.8371239 ], Reward: -0.3405207097530365\n",
      "Episode: 1, Step: 489, Action: [-0.15664595  0.37733787 -0.97082365 -0.948562  ], Reward: -0.3418434262275696\n",
      "Episode: 1, Step: 490, Action: [-0.43310326  0.1731592  -0.54121804  0.3000714 ], Reward: -0.3427952527999878\n",
      "Episode: 1, Step: 491, Action: [-0.9685214  -0.546075    0.39136863  0.4579637 ], Reward: -0.34287089109420776\n",
      "Episode: 1, Step: 492, Action: [ 0.31292427 -0.3541501  -0.10525841 -0.7707896 ], Reward: -0.3431013226509094\n",
      "Episode: 1, Step: 493, Action: [ 0.4483249   0.50832415 -0.6178338   0.9975712 ], Reward: -0.3442574441432953\n",
      "Episode: 1, Step: 494, Action: [-0.01199341 -0.93418217 -0.7511379   0.10250113], Reward: -0.3442405164241791\n",
      "Episode: 1, Step: 495, Action: [-0.17776692  0.5865546  -0.5341485  -0.99197865], Reward: -0.34388941526412964\n",
      "Episode: 1, Step: 496, Action: [0.5833934  0.07832798 0.59153295 0.8104474 ], Reward: -0.3436633050441742\n",
      "Episode: 1, Step: 497, Action: [ 0.5892134   0.6390014  -0.39647567  0.2690675 ], Reward: -0.34441131353378296\n",
      "Episode: 1, Step: 498, Action: [-0.32811108  0.66456836 -0.9802461   0.6453674 ], Reward: -0.34521475434303284\n",
      "Episode: 1, Step: 499, Action: [-0.9142254   0.47969708  0.4767468   0.13280882], Reward: -0.3451099693775177\n",
      "Episode: 1, Step: 500, Action: [-0.03786647 -0.95551324 -0.9126939   0.11998209], Reward: -0.34514039754867554\n",
      "Episode: 1, Step: 501, Action: [-0.753416    0.92531973  0.81039083  0.23628949], Reward: -0.3446051776409149\n",
      "Episode: 1, Step: 502, Action: [ 0.12919062 -0.93366635  0.7917572  -0.8562823 ], Reward: -0.34413793683052063\n",
      "Episode: 1, Step: 503, Action: [-0.45573243 -0.31845623 -0.13222156 -0.6547043 ], Reward: -0.3435184061527252\n",
      "Episode: 1, Step: 504, Action: [-0.9003113  -0.56006145  0.9327918  -0.07214769], Reward: -0.3420179784297943\n",
      "Episode: 1, Step: 505, Action: [-0.50284505 -0.43379503  0.5029869  -0.98808444], Reward: -0.3399609327316284\n",
      "Episode: 1, Step: 506, Action: [-0.15669085 -0.19693924  0.74091494 -0.86186093], Reward: -0.3379073441028595\n",
      "Episode: 1, Step: 507, Action: [-0.29172298  0.5341909   0.08820906 -0.63890123], Reward: -0.33621421456336975\n",
      "Episode: 1, Step: 508, Action: [-0.51571643 -0.06122206 -0.87784785  0.42752394], Reward: -0.3344665467739105\n",
      "Episode: 1, Step: 509, Action: [-0.9055948   0.40416652 -0.9238551  -0.6301827 ], Reward: -0.33281293511390686\n",
      "Episode: 1, Step: 510, Action: [-0.78137136  0.6243559  -0.09407432  0.94185877], Reward: -0.3306598961353302\n",
      "Episode: 1, Step: 511, Action: [ 0.14958984 -0.09114479  0.900923   -0.68965316], Reward: -0.328494668006897\n",
      "Episode: 1, Step: 512, Action: [0.5180483  0.1304553  0.94204193 0.8065715 ], Reward: -0.326698899269104\n",
      "Episode: 1, Step: 513, Action: [ 0.51451343  0.9160303  -0.535455    0.39853022], Reward: -0.3257591128349304\n",
      "Episode: 1, Step: 514, Action: [-0.8401376   0.1364917   0.53630024 -0.72913074], Reward: -0.3239641487598419\n",
      "Episode: 1, Step: 515, Action: [ 0.35167634  0.8380457  -0.69753927  0.12345004], Reward: -0.3231186866760254\n",
      "Episode: 1, Step: 516, Action: [-0.8919032  -0.68373966  0.14400764  0.3552209 ], Reward: -0.3214779198169708\n",
      "Episode: 1, Step: 517, Action: [ 0.05245261 -0.674226   -0.9771223   0.99580896], Reward: -0.32058238983154297\n",
      "Episode: 1, Step: 518, Action: [ 0.4249474   0.58533233 -0.04617803  0.01135262], Reward: -0.3201035261154175\n",
      "Episode: 1, Step: 519, Action: [0.3604359  0.8202505  0.6537093  0.98001456], Reward: -0.319875568151474\n",
      "Episode: 1, Step: 520, Action: [-0.19799076  0.617383   -0.84149706  0.82482195], Reward: -0.31968387961387634\n",
      "Episode: 1, Step: 521, Action: [ 0.31579575  0.40535748 -0.7794124   0.7928081 ], Reward: -0.3203383982181549\n",
      "Episode: 1, Step: 522, Action: [ 0.94914377 -0.83912355 -0.78531814 -0.5567518 ], Reward: -0.3217652440071106\n",
      "Episode: 1, Step: 523, Action: [ 0.7082473  -0.06464683  0.42587733  0.92117083], Reward: -0.32310786843299866\n",
      "Episode: 1, Step: 524, Action: [ 0.7326252  -0.5022601  -0.53906393  0.00908875], Reward: -0.3247967064380646\n",
      "Episode: 1, Step: 525, Action: [-0.3217073   0.7442862  -0.01360152 -0.68537754], Reward: -0.32590150833129883\n",
      "Episode: 1, Step: 526, Action: [-0.9865231  0.999942  -0.6457781  0.9553432], Reward: -0.32718318700790405\n",
      "Episode: 1, Step: 527, Action: [ 0.721563   0.5515235 -0.9238525  0.8139815], Reward: -0.3293943703174591\n",
      "Episode: 1, Step: 528, Action: [-0.0159204   0.7602943   0.5813666   0.88670975], Reward: -0.3300022482872009\n",
      "Episode: 1, Step: 529, Action: [ 0.88802993  0.26740813  0.09226425 -0.31254455], Reward: -0.3308621346950531\n",
      "Episode: 1, Step: 530, Action: [-0.18202466 -0.97062886 -0.1013943  -0.24853717], Reward: -0.3311155140399933\n",
      "Episode: 1, Step: 531, Action: [ 0.9261197   0.49589774 -0.944722   -0.44908482], Reward: -0.33211198449134827\n",
      "Episode: 1, Step: 532, Action: [-0.7258966   0.19763091 -0.7768772  -0.57082665], Reward: -0.33243900537490845\n",
      "Episode: 1, Step: 533, Action: [0.82603884 0.3808405  0.03320044 0.06349377], Reward: -0.3333614766597748\n",
      "Episode: 1, Step: 534, Action: [-0.915011   -0.23719834  0.506864   -0.8743956 ], Reward: -0.3334728479385376\n",
      "Episode: 1, Step: 535, Action: [ 0.41266364 -0.407903    0.04362326 -0.6268679 ], Reward: -0.33409422636032104\n",
      "Episode: 1, Step: 536, Action: [-0.769577   -0.6694633   0.03472034  0.39736158], Reward: -0.3342156410217285\n",
      "Episode: 1, Step: 537, Action: [ 0.6550733   0.18706356 -0.79634863 -0.44240728], Reward: -0.3352482318878174\n",
      "Episode: 1, Step: 538, Action: [ 0.6783121  -0.45185006 -0.4475958  -0.15359002], Reward: -0.33618423342704773\n",
      "Episode: 1, Step: 539, Action: [-0.38853127  0.84429026 -0.486886    0.5510892 ], Reward: -0.3368406593799591\n",
      "Episode: 1, Step: 540, Action: [-0.8546933   0.66648823  0.03694668  0.6839762 ], Reward: -0.3372712731361389\n",
      "Episode: 1, Step: 541, Action: [-0.57130545  0.49256405  0.3065984   0.16052006], Reward: -0.33711621165275574\n",
      "Episode: 1, Step: 542, Action: [-0.78799194 -0.12733859 -0.21464841 -0.06639837], Reward: -0.3367474377155304\n",
      "Episode: 1, Step: 543, Action: [ 0.99140984 -0.3336074   0.3568023  -0.6472844 ], Reward: -0.336227148771286\n",
      "Episode: 1, Step: 544, Action: [-0.87213343  0.79889935 -0.19741367 -0.9936264 ], Reward: -0.33578169345855713\n",
      "Episode: 1, Step: 545, Action: [-0.35948217 -0.2567318  -0.64092755  0.26558194], Reward: -0.3350910246372223\n",
      "Episode: 1, Step: 546, Action: [-0.3237835  -0.3192123  -0.11695558 -0.98973256], Reward: -0.3334754705429077\n",
      "Episode: 1, Step: 547, Action: [ 0.5447302   0.86816376 -0.80810374 -0.96344775], Reward: -0.33242538571357727\n",
      "Episode: 1, Step: 548, Action: [0.26582685 0.15981905 0.28163815 0.40561596], Reward: -0.33171364665031433\n",
      "Episode: 1, Step: 549, Action: [-0.81724054  0.5656489  -0.5210904  -0.83916306], Reward: -0.3311118185520172\n",
      "Episode: 1, Step: 550, Action: [ 0.80410224  0.655817   -0.65790826  0.26446754], Reward: -0.33158981800079346\n",
      "Episode: 1, Step: 551, Action: [0.5485251  0.08691959 0.86885107 0.23642355], Reward: -0.33167123794555664\n",
      "Episode: 1, Step: 552, Action: [ 0.7720465  -0.34211975 -0.56739    -0.74427927], Reward: -0.33202648162841797\n",
      "Episode: 1, Step: 553, Action: [ 0.9218119  -0.25920635  0.73128605  0.45500207], Reward: -0.33233675360679626\n",
      "Episode: 1, Step: 554, Action: [0.29805025 0.84225553 0.12722224 0.5992371 ], Reward: -0.3333504796028137\n",
      "Episode: 1, Step: 555, Action: [ 0.93974596  0.510804   -0.15676767 -0.281982  ], Reward: -0.3352205753326416\n",
      "Episode: 1, Step: 556, Action: [-0.90547985 -0.9505894  -0.401103    0.17930938], Reward: -0.33684173226356506\n",
      "Episode: 1, Step: 557, Action: [-0.736277   -0.0172861  -0.6190366  -0.38426086], Reward: -0.3374384045600891\n",
      "Episode: 1, Step: 558, Action: [-0.09042055  0.6352358  -0.02168057  0.30774003], Reward: -0.3377920687198639\n",
      "Episode: 1, Step: 559, Action: [0.5877355  0.65379596 0.7378765  0.87428045], Reward: -0.33810755610466003\n",
      "Episode: 1, Step: 560, Action: [-0.8218485  -0.95786524 -0.36792156 -0.7270601 ], Reward: -0.3382348418235779\n",
      "Episode: 1, Step: 561, Action: [ 0.728105    0.38069227 -0.64495265  0.9693467 ], Reward: -0.3394295573234558\n",
      "Episode: 1, Step: 562, Action: [ 0.553586   -0.56177986 -0.28564122  0.831157  ], Reward: -0.34021782875061035\n",
      "Episode: 1, Step: 563, Action: [-0.51784295 -0.6649711  -0.6430016  -0.7838776 ], Reward: -0.34056541323661804\n",
      "Episode: 1, Step: 564, Action: [ 0.26956347 -0.70965046  0.4137817   0.5384559 ], Reward: -0.3406839072704315\n",
      "Episode: 1, Step: 565, Action: [0.49237984 0.34548298 0.26061022 0.9279083 ], Reward: -0.3415283262729645\n",
      "Episode: 1, Step: 566, Action: [ 0.7374893  -0.18814276 -0.89347935  0.920097  ], Reward: -0.3432871997356415\n",
      "Episode: 1, Step: 567, Action: [-0.62138754  0.71784693  0.786319   -0.3494292 ], Reward: -0.3443340063095093\n",
      "Episode: 1, Step: 568, Action: [ 0.64560986  0.25362012 -0.6042095  -0.61304617], Reward: -0.34654346108436584\n",
      "Episode: 1, Step: 569, Action: [ 0.32206494 -0.20636362  0.67911094 -0.89618325], Reward: -0.3477427065372467\n",
      "Episode: 1, Step: 570, Action: [ 2.9118100e-01 -4.4760281e-01 -4.4720486e-04 -4.6657029e-01], Reward: -0.3487218916416168\n",
      "Episode: 1, Step: 571, Action: [-0.08287138  0.97474295  0.07300589  0.22868368], Reward: -0.3491956889629364\n",
      "Episode: 1, Step: 572, Action: [ 0.9222945  -0.01219339 -0.9822349   0.950567  ], Reward: -0.3505953848361969\n",
      "Episode: 1, Step: 573, Action: [-0.6787191  -0.26255426 -0.92092067 -0.95380616], Reward: -0.3518674075603485\n",
      "Episode: 1, Step: 574, Action: [-0.2394785  -0.1255184  -0.62181175 -0.51436836], Reward: -0.3519524931907654\n",
      "Episode: 1, Step: 575, Action: [-0.05869328 -0.33980575 -0.97585803 -0.26076794], Reward: -0.35142651200294495\n",
      "Episode: 1, Step: 576, Action: [-0.5727918   0.24815989 -0.26390174 -0.3868143 ], Reward: -0.350687712430954\n",
      "Episode: 1, Step: 577, Action: [-0.7923632   0.59822017 -0.18858835 -0.8929069 ], Reward: -0.3496474325656891\n",
      "Episode: 1, Step: 578, Action: [ 0.32586998  0.2622195  -0.84818006  0.2514167 ], Reward: -0.34921979904174805\n",
      "Episode: 1, Step: 579, Action: [ 0.05300758 -0.82935804 -0.36246163  0.9217403 ], Reward: -0.34900590777397156\n",
      "Episode: 1, Step: 580, Action: [ 0.5075289   0.80923474  0.7445477  -0.85250384], Reward: -0.34913259744644165\n",
      "Episode: 1, Step: 581, Action: [0.22374207 0.81502783 0.16499959 0.48542726], Reward: -0.34996840357780457\n",
      "Episode: 1, Step: 582, Action: [-0.05361056  0.84199506  0.24345355  0.8769643 ], Reward: -0.3503943085670471\n",
      "Episode: 1, Step: 583, Action: [-0.82166445  0.5873421  -0.180442   -0.8518488 ], Reward: -0.3508908450603485\n",
      "Episode: 1, Step: 584, Action: [-0.7963498  -0.09895743  0.09474466  0.5657767 ], Reward: -0.3507172465324402\n",
      "Episode: 1, Step: 585, Action: [-0.20784277 -0.3089599  -0.75192344 -0.96297485], Reward: -0.35046830773353577\n",
      "Episode: 1, Step: 586, Action: [-0.9160234   0.06168987  0.06575283  0.15386218], Reward: -0.34942176938056946\n",
      "Episode: 1, Step: 587, Action: [-0.7917805  -0.3133219  -0.2503066   0.92997926], Reward: -0.3481132388114929\n",
      "Episode: 1, Step: 588, Action: [-0.19925629  0.40031144  0.1414345   0.08936433], Reward: -0.3469613194465637\n",
      "Episode: 1, Step: 589, Action: [-0.38979742 -0.7145974   0.8961691   0.2630036 ], Reward: -0.3450908958911896\n",
      "Episode: 1, Step: 590, Action: [-0.71265     0.82206905 -0.5956045  -0.73878634], Reward: -0.34330445528030396\n",
      "Episode: 1, Step: 591, Action: [ 0.9622302   0.8101718  -0.29177108  0.9737452 ], Reward: -0.3423667848110199\n",
      "Episode: 1, Step: 592, Action: [-0.16133639  0.11543605 -0.49615735  0.0984873 ], Reward: -0.3412802219390869\n",
      "Episode: 1, Step: 593, Action: [-0.73524123  0.3711565   0.3044801  -0.34326932], Reward: -0.3395214378833771\n",
      "Episode: 1, Step: 594, Action: [-0.56084645  0.9586096  -0.57588375  0.810177  ], Reward: -0.33771541714668274\n",
      "Episode: 1, Step: 595, Action: [-0.67429256  0.73385245  0.9833864  -0.29485255], Reward: -0.3352382183074951\n",
      "Episode: 1, Step: 596, Action: [-0.14084364 -0.22509299 -0.2206127  -0.9507639 ], Reward: -0.3333866596221924\n",
      "Episode: 1, Step: 597, Action: [ 0.27469504 -0.17103803  0.3426233   0.56518644], Reward: -0.33164292573928833\n",
      "Episode: 1, Step: 598, Action: [-0.06955934  0.8989547  -0.8807535   0.07243297], Reward: -0.3308515250682831\n",
      "Episode: 1, Step: 599, Action: [-0.12353289  0.31834543 -0.24446486  0.3606129 ], Reward: -0.33030766248703003\n",
      "Episode: 1, Step: 600, Action: [ 0.3997058   0.8099779  -0.03519725  0.7964087 ], Reward: -0.33039554953575134\n",
      "Episode: 1, Step: 601, Action: [-0.9697717   0.95283    -0.41809607 -0.7232719 ], Reward: -0.3302490711212158\n",
      "Episode: 1, Step: 602, Action: [-0.62357455  0.2928861  -0.24130937 -0.08979256], Reward: -0.32908186316490173\n",
      "Episode: 1, Step: 603, Action: [-0.35207978 -0.07176317 -0.25783435 -0.15950733], Reward: -0.327646404504776\n",
      "Episode: 1, Step: 604, Action: [ 0.7364851   0.91497093 -0.7461112   0.11269788], Reward: -0.32665741443634033\n",
      "Episode: 1, Step: 605, Action: [ 0.5308057  0.6326945 -0.5568072  0.8103709], Reward: -0.32617929577827454\n",
      "Episode: 1, Step: 606, Action: [-0.07195497  0.5404576   0.9685094   0.15068352], Reward: -0.3255580961704254\n",
      "Episode: 1, Step: 607, Action: [ 0.4815021   0.61374587 -0.08881723 -0.9821463 ], Reward: -0.32574462890625\n",
      "Episode: 1, Step: 608, Action: [-0.17457733 -0.6532549   0.23588657  0.6442511 ], Reward: -0.32506927847862244\n",
      "Episode: 1, Step: 609, Action: [-0.6493886   0.4241252   0.74165505  0.9180124 ], Reward: -0.32389798760414124\n",
      "Episode: 1, Step: 610, Action: [ 0.80802214 -0.535453    0.03567244 -0.7822353 ], Reward: -0.3233511447906494\n",
      "Episode: 1, Step: 611, Action: [ 0.06051314 -0.61424255  0.68701154 -0.89064777], Reward: -0.3226998746395111\n",
      "Episode: 1, Step: 612, Action: [ 0.19866444  0.32039726 -0.6061493  -0.35569623], Reward: -0.32306334376335144\n",
      "Episode: 1, Step: 613, Action: [-0.8882263  -0.14744304  0.15031677  0.64571625], Reward: -0.32287755608558655\n",
      "Episode: 1, Step: 614, Action: [ 0.9595235   0.26077065  0.89971966 -0.14724354], Reward: -0.32292208075523376\n",
      "Episode: 1, Step: 615, Action: [ 0.08629095  0.55676776  0.68750757 -0.12737316], Reward: -0.32264038920402527\n",
      "Episode: 1, Step: 616, Action: [-0.33367592 -0.5127359  -0.8008014   0.8646256 ], Reward: -0.3221611976623535\n",
      "Episode: 1, Step: 617, Action: [-0.3405062  -0.623965   -0.68196136 -0.9105394 ], Reward: -0.32146862149238586\n",
      "Episode: 1, Step: 618, Action: [-0.31443182 -0.01316417  0.5806253   0.86896735], Reward: -0.32026368379592896\n",
      "Episode: 1, Step: 619, Action: [-0.4108864  -0.49362728 -0.08791823 -0.24784476], Reward: -0.3188139796257019\n",
      "Episode: 1, Step: 620, Action: [-0.42386138 -0.31293494 -0.18142243 -0.8565874 ], Reward: -0.31715908646583557\n",
      "Episode: 1, Step: 621, Action: [0.984797   0.4992773  0.6685536  0.74783504], Reward: -0.3157438039779663\n",
      "Episode: 1, Step: 622, Action: [ 0.2905713  -0.66966873 -0.9891601  -0.3239683 ], Reward: -0.3149435520172119\n",
      "Episode: 1, Step: 623, Action: [ 0.3026118  -0.38886204 -0.8263275   0.95693547], Reward: -0.3148403763771057\n",
      "Episode: 1, Step: 624, Action: [-0.8485735  -0.5036359   0.8628982  -0.74788254], Reward: -0.31396931409835815\n",
      "Episode: 1, Step: 625, Action: [-0.55258006 -0.0759315  -0.15669562  0.4456512 ], Reward: -0.3126027286052704\n",
      "Episode: 1, Step: 626, Action: [-0.41561574 -0.17533635 -0.37864488 -0.28452128], Reward: -0.3112258315086365\n",
      "Episode: 1, Step: 627, Action: [ 0.5670197  -0.57623285 -0.64909846  0.97428674], Reward: -0.31064316630363464\n",
      "Episode: 1, Step: 628, Action: [-0.7607527   0.73781836 -0.04405005  0.99012256], Reward: -0.30934005975723267\n",
      "Episode: 1, Step: 629, Action: [-0.2583719  -0.61839473  0.0045414  -0.6746606 ], Reward: -0.30775830149650574\n",
      "Episode: 1, Step: 630, Action: [-0.06233025 -0.32227716  0.03561913 -0.09261787], Reward: -0.3065117299556732\n",
      "Episode: 1, Step: 631, Action: [ 0.82366997  0.7476806   0.2451197  -0.6785763 ], Reward: -0.30568599700927734\n",
      "Episode: 1, Step: 632, Action: [-0.26156327  0.15086764 -0.5506432  -0.39792764], Reward: -0.3049826920032501\n",
      "Episode: 1, Step: 633, Action: [-0.916344    0.0778667   0.6523735   0.94609016], Reward: -0.3036806285381317\n",
      "Episode: 1, Step: 634, Action: [ 0.6005197 -0.5894426  0.6802893 -0.7571221], Reward: -0.30231961607933044\n",
      "Episode: 1, Step: 635, Action: [-0.84137315 -0.86412114  0.14227729 -0.8347402 ], Reward: -0.30073219537734985\n",
      "Episode: 1, Step: 636, Action: [ 0.6413256  -0.9434026   0.34217355 -0.7050123 ], Reward: -0.2991947829723358\n",
      "Episode: 1, Step: 637, Action: [-0.14359382  0.24917765  0.5963092   0.34566915], Reward: -0.29763656854629517\n",
      "Episode: 1, Step: 638, Action: [ 0.8116929   0.64719    -0.36456898  0.61225224], Reward: -0.2971363067626953\n",
      "Episode: 1, Step: 639, Action: [ 0.4429927   0.09359509  0.01426982 -0.39351612], Reward: -0.2974778711795807\n",
      "Episode: 1, Step: 640, Action: [-0.6956179  -0.10844021 -0.4661631   0.21739921], Reward: -0.2976190149784088\n",
      "Episode: 1, Step: 641, Action: [-0.8990239  -0.07850564  0.823853    0.3288576 ], Reward: -0.2970990538597107\n",
      "Episode: 1, Step: 642, Action: [-0.47895873 -0.9287175  -0.05494345 -0.62297964], Reward: -0.2960657775402069\n",
      "Episode: 1, Step: 643, Action: [-0.7703512  -0.52128977 -0.18173565  0.6834594 ], Reward: -0.2945942282676697\n",
      "Episode: 1, Step: 644, Action: [-0.4348811   0.04459441 -0.5402594   0.6192426 ], Reward: -0.29347118735313416\n",
      "Episode: 1, Step: 645, Action: [-0.06742202 -0.6019875  -0.43287826  0.02802821], Reward: -0.29250386357307434\n",
      "Episode: 1, Step: 646, Action: [ 0.41397706 -0.93528306  0.06263159 -0.54049605], Reward: -0.29150184988975525\n",
      "Episode: 1, Step: 647, Action: [-0.5327532  -0.7137178  -0.21050107  0.27105778], Reward: -0.29005345702171326\n",
      "Episode: 1, Step: 648, Action: [0.5669258 0.1275174 0.7474618 0.0512554], Reward: -0.2887534499168396\n",
      "Episode: 1, Step: 649, Action: [ 0.69584507  0.30813423 -0.39456627 -0.971666  ], Reward: -0.28795626759529114\n",
      "Episode: 1, Step: 650, Action: [-0.17975473  0.32714936 -0.4806162  -0.6406566 ], Reward: -0.28712838888168335\n",
      "Episode: 1, Step: 651, Action: [ 0.47233254 -0.520991   -0.22722627  0.68059146], Reward: -0.2864997386932373\n",
      "Episode: 1, Step: 652, Action: [-0.9685951  0.592595  -0.7059141 -0.3939205], Reward: -0.2856985330581665\n",
      "Episode: 1, Step: 653, Action: [0.500423   0.7265582  0.874755   0.33198756], Reward: -0.28497314453125\n",
      "Episode: 1, Step: 654, Action: [ 0.8290987  -0.792111   -0.28260124  0.5512639 ], Reward: -0.2850092649459839\n",
      "Episode: 1, Step: 655, Action: [ 0.89527506 -0.86009574 -0.06159047  0.67693436], Reward: -0.2854141294956207\n",
      "Episode: 1, Step: 656, Action: [ 0.13039592  0.8812805  -0.36723     0.02843273], Reward: -0.28628551959991455\n",
      "Episode: 1, Step: 657, Action: [ 0.15386474  0.74654377 -0.6321484   0.19725172], Reward: -0.2866586744785309\n",
      "Episode: 1, Step: 658, Action: [ 0.12016174  0.7094443  -0.32811776 -0.6324274 ], Reward: -0.2870962619781494\n",
      "Episode: 1, Step: 659, Action: [-0.9752123  -0.08757881  0.26987824 -0.00886104], Reward: -0.2867017388343811\n",
      "Episode: 1, Step: 660, Action: [ 0.6819315  -0.34602782  0.631473    0.4004484 ], Reward: -0.2862354516983032\n",
      "Episode: 1, Step: 661, Action: [ 0.56880647  0.1854269  -0.5546407   0.8509757 ], Reward: -0.2866925597190857\n",
      "Episode: 1, Step: 662, Action: [ 0.03270739  0.05433233  0.40876877 -0.697134  ], Reward: -0.28660261631011963\n",
      "Episode: 1, Step: 663, Action: [-0.16160773  0.72561926 -0.9981449   0.01977296], Reward: -0.2866881191730499\n",
      "Episode: 1, Step: 664, Action: [ 0.5498158  -0.9915416  -0.28865206 -0.5465098 ], Reward: -0.2875211536884308\n",
      "Episode: 1, Step: 665, Action: [-0.6540425  -0.12826644  0.4625474  -0.9413565 ], Reward: -0.28744375705718994\n",
      "Episode: 1, Step: 666, Action: [ 0.49294466 -0.61913323 -0.31921613  0.8476496 ], Reward: -0.2881745398044586\n",
      "Episode: 1, Step: 667, Action: [-0.08042534  0.3544635  -0.58074224  0.8414353 ], Reward: -0.28909173607826233\n",
      "Episode: 1, Step: 668, Action: [-0.4124336   0.77142495 -0.3571577  -0.02784045], Reward: -0.2892780005931854\n",
      "Episode: 1, Step: 669, Action: [ 0.10521788 -0.98101765 -0.6692609   0.5024702 ], Reward: -0.2891848385334015\n",
      "Episode: 1, Step: 670, Action: [-0.74499035  0.49629694  0.16347483  0.5833039 ], Reward: -0.2886006236076355\n",
      "Episode: 1, Step: 671, Action: [ 0.8328546  -0.15470184 -0.76844686 -0.80411214], Reward: -0.2887650728225708\n",
      "Episode: 1, Step: 672, Action: [ 0.37144652 -0.08159576  0.596832   -0.37748438], Reward: -0.28905412554740906\n",
      "Episode: 1, Step: 673, Action: [-0.22751614  0.22037652  0.2364245   0.92361426], Reward: -0.2888167202472687\n",
      "Episode: 1, Step: 674, Action: [ 0.31570265 -0.4727591   0.7347773   0.29144752], Reward: -0.2885129749774933\n",
      "Episode: 1, Step: 675, Action: [ 0.24073598 -0.7030395   0.6509253  -0.5082253 ], Reward: -0.28823643922805786\n",
      "Episode: 1, Step: 676, Action: [-0.6002305   0.6304522   0.43987158  0.37782878], Reward: -0.2879665493965149\n",
      "Episode: 1, Step: 677, Action: [-0.49273422 -0.7454636  -0.62731266 -0.48173663], Reward: -0.287725567817688\n",
      "Episode: 1, Step: 678, Action: [-0.05827188  0.17488691  0.7163001  -0.3939047 ], Reward: -0.28688615560531616\n",
      "Episode: 1, Step: 679, Action: [-0.4227066  -0.7427358   0.93898684  0.8763472 ], Reward: -0.28527748584747314\n",
      "Episode: 1, Step: 680, Action: [-0.95596504 -0.48087403  0.6982746  -0.31569463], Reward: -0.2830469608306885\n",
      "Episode: 1, Step: 681, Action: [ 0.7410357   0.35836032 -0.71451545 -0.72764164], Reward: -0.28172767162323\n",
      "Episode: 1, Step: 682, Action: [-0.8305342  -0.7933894   0.4226968  -0.13910304], Reward: -0.279802531003952\n",
      "Episode: 1, Step: 683, Action: [-0.3870099  -0.9315888  -0.19542803  0.5355502 ], Reward: -0.2778547406196594\n",
      "Episode: 1, Step: 684, Action: [-0.9394574   0.28776893  0.6395794  -0.10011793], Reward: -0.2751808166503906\n",
      "Episode: 1, Step: 685, Action: [ 0.7983191   0.55088836  0.7700434  -0.16190146], Reward: -0.2728274464607239\n",
      "Episode: 1, Step: 686, Action: [ 0.15040797 -0.6674044  -0.98137677  0.94561875], Reward: -0.2712443768978119\n",
      "Episode: 1, Step: 687, Action: [-0.003076    0.06976927 -0.33786654  0.0425467 ], Reward: -0.27051374316215515\n",
      "Episode: 1, Step: 688, Action: [ 0.5636633   0.45731777  0.7962525  -0.8138048 ], Reward: -0.26995912194252014\n",
      "Episode: 1, Step: 689, Action: [-0.35409552  0.7065808   0.5791286  -0.7281504 ], Reward: -0.26886025071144104\n",
      "Episode: 1, Step: 690, Action: [ 0.35294932  0.9271453  -0.9348641  -0.65517926], Reward: -0.2686561942100525\n",
      "Episode: 1, Step: 691, Action: [ 0.8907199   0.00609712  0.6548612  -0.34853467], Reward: -0.26850491762161255\n",
      "Episode: 1, Step: 692, Action: [-0.08690862 -0.4017498  -0.4202281   0.4592908 ], Reward: -0.2682265341281891\n",
      "Episode: 1, Step: 693, Action: [-0.23353264  0.993608    0.5727768  -0.6171284 ], Reward: -0.2673322558403015\n",
      "Episode: 1, Step: 694, Action: [-0.9583127   0.5683429   0.09082527  0.6173968 ], Reward: -0.26620498299598694\n",
      "Episode: 1, Step: 695, Action: [-0.13633072 -0.3917133   0.23825917  0.17051698], Reward: -0.2653796672821045\n",
      "Episode: 1, Step: 696, Action: [-0.23115817 -0.2981748   0.70706886 -0.74697673], Reward: -0.26381656527519226\n",
      "Episode: 1, Step: 697, Action: [-0.62661093 -0.30263773  0.62155706 -0.62596893], Reward: -0.26162585616111755\n",
      "Episode: 1, Step: 698, Action: [ 0.15336332  0.14163741 -0.37183407 -0.9212482 ], Reward: -0.2603023052215576\n",
      "Episode: 1, Step: 699, Action: [-0.5809966  -0.5197132   0.45031214  0.11301544], Reward: -0.2583227753639221\n",
      "Episode: 1, Step: 700, Action: [-0.4158614  -0.13434657 -0.3041916  -0.08850228], Reward: -0.2564542293548584\n",
      "Episode: 1, Step: 701, Action: [ 0.71341956 -0.21482249 -0.18817954  0.82680666], Reward: -0.25529778003692627\n",
      "Episode: 1, Step: 702, Action: [-0.409955    0.2789633  -0.41607007  0.5257193 ], Reward: -0.2541043162345886\n",
      "Episode: 1, Step: 703, Action: [-0.3490627  -0.04188473 -0.18998507  0.6404177 ], Reward: -0.25287652015686035\n",
      "Episode: 1, Step: 704, Action: [-0.32764438 -0.2708309  -0.7992842   0.46283627], Reward: -0.25214749574661255\n",
      "Episode: 1, Step: 705, Action: [ 0.2882335  -0.02205669 -0.07761765  0.08842273], Reward: -0.25149786472320557\n",
      "Episode: 1, Step: 706, Action: [ 0.97112167  0.09997635 -0.79303765  0.52717346], Reward: -0.2519329786300659\n",
      "Episode: 1, Step: 707, Action: [-0.37553343  0.85327214  0.4444597   0.3432584 ], Reward: -0.25165265798568726\n",
      "Episode: 1, Step: 708, Action: [-0.0097549   0.165232   -0.09958228  0.04919642], Reward: -0.2514771521091461\n",
      "Episode: 1, Step: 709, Action: [-0.22655375  0.02894189  0.02545539 -0.738825  ], Reward: -0.25063300132751465\n",
      "Episode: 1, Step: 710, Action: [ 0.38360676  0.8000497   0.5110312  -0.89439756], Reward: -0.2500056028366089\n",
      "Episode: 1, Step: 711, Action: [0.02909818 0.4202626  0.9835375  0.9725508 ], Reward: -0.24959495663642883\n",
      "Episode: 1, Step: 712, Action: [ 0.14739631  0.7752292  -0.47012785  0.05259483], Reward: -0.25014856457710266\n",
      "Episode: 1, Step: 713, Action: [ 0.72938234  0.26282212  0.7680561  -0.61611134], Reward: -0.25069284439086914\n",
      "Episode: 1, Step: 714, Action: [-0.04070929  0.1863673  -0.9071856   0.924555  ], Reward: -0.25118502974510193\n",
      "Episode: 1, Step: 715, Action: [ 0.83994    -0.34108427 -0.7244088  -0.6593398 ], Reward: -0.2523588240146637\n",
      "Episode: 1, Step: 716, Action: [-0.10931844 -0.26046094 -0.7957332   0.63161826], Reward: -0.25333720445632935\n",
      "Episode: 1, Step: 717, Action: [-0.90386045 -0.48500827 -0.12525748 -0.4986496 ], Reward: -0.2536717355251312\n",
      "Episode: 1, Step: 718, Action: [-0.24194849 -0.9647087   0.47679797 -0.85980606], Reward: -0.25304529070854187\n",
      "Episode: 1, Step: 719, Action: [ 0.5340886  -0.38489848 -0.9781078  -0.69855833], Reward: -0.2532860040664673\n",
      "Episode: 1, Step: 720, Action: [ 0.88401693 -0.5493852   0.15052094  0.29569244], Reward: -0.25365307927131653\n",
      "Episode: 1, Step: 721, Action: [-0.7222455  -0.16539977 -0.87646586  0.7301664 ], Reward: -0.25406038761138916\n",
      "Episode: 1, Step: 722, Action: [-0.6069878   0.4644661   0.62650204  0.6149019 ], Reward: -0.2537645697593689\n",
      "Episode: 1, Step: 723, Action: [-0.37744     0.4766614  -0.9300989  -0.84373134], Reward: -0.2536219358444214\n",
      "Episode: 1, Step: 724, Action: [-0.10610077  0.21121286 -0.823585    0.7657292 ], Reward: -0.2544674575328827\n",
      "Episode: 1, Step: 725, Action: [-0.87577945  0.81936455  0.6932127  -0.90138453], Reward: -0.25456923246383667\n",
      "Episode: 1, Step: 726, Action: [ 0.00278191 -0.4355116   0.9736286  -0.6049447 ], Reward: -0.2547023296356201\n",
      "Episode: 1, Step: 727, Action: [ 0.42989793 -0.31286463  0.97010785 -0.818533  ], Reward: -0.25481653213500977\n",
      "Episode: 1, Step: 728, Action: [-0.60418916  0.12476736  0.99725556 -0.4353551 ], Reward: -0.25431546568870544\n",
      "Episode: 1, Step: 729, Action: [0.62257695 0.1544547  0.6795245  0.96420103], Reward: -0.25388920307159424\n",
      "Episode: 1, Step: 730, Action: [-0.31230596  0.09533753 -0.13677388 -0.48551792], Reward: -0.2535770535469055\n",
      "Episode: 1, Step: 731, Action: [-0.71121526 -0.850335    0.5000505  -0.7894143 ], Reward: -0.25228017568588257\n",
      "Episode: 1, Step: 732, Action: [ 0.79119295  0.24242209 -0.48908073 -0.5246834 ], Reward: -0.25204089283943176\n",
      "Episode: 1, Step: 733, Action: [-0.4856078   0.48130286  0.20798714 -0.6789238 ], Reward: -0.2511269748210907\n",
      "Episode: 1, Step: 734, Action: [ 0.6708149   0.50173604 -0.00579348 -0.37167716], Reward: -0.2508935332298279\n",
      "Episode: 1, Step: 735, Action: [-0.92915124  0.7403162   0.30117667  0.67624325], Reward: -0.25007596611976624\n",
      "Episode: 1, Step: 736, Action: [-0.7550247  -0.49867135  0.6183243   0.32272676], Reward: -0.24845539033412933\n",
      "Episode: 1, Step: 737, Action: [ 0.30536598 -0.28696388 -0.37692994  0.92773926], Reward: -0.2475888580083847\n",
      "Episode: 1, Step: 738, Action: [-0.67377883 -0.34116554 -0.88887304 -0.27048573], Reward: -0.2466205507516861\n",
      "Episode: 1, Step: 739, Action: [-0.42757952 -0.43017188 -0.17574693 -0.27353176], Reward: -0.2451857030391693\n",
      "Episode: 1, Step: 740, Action: [ 0.82829225  0.44702095 -0.2523483   0.68578213], Reward: -0.2444680780172348\n",
      "Episode: 1, Step: 741, Action: [-0.28923705  0.70421433 -0.56835395  0.25701052], Reward: -0.244391530752182\n",
      "Episode: 1, Step: 742, Action: [-0.4789716  -0.5539554   0.92586195  0.88677055], Reward: -0.24345487356185913\n",
      "Episode: 1, Step: 743, Action: [ 0.20028453 -0.30188006 -0.97633684 -0.97297966], Reward: -0.24340195953845978\n",
      "Episode: 1, Step: 744, Action: [-0.6862558   0.75471103  0.54378736 -0.55774814], Reward: -0.24275635182857513\n",
      "Episode: 1, Step: 745, Action: [ 0.56673205  0.24958953 -0.8366587   0.34198096], Reward: -0.2430802285671234\n",
      "Episode: 1, Step: 746, Action: [-0.23321496 -0.44378904 -0.6838541   0.36705315], Reward: -0.24348746240139008\n",
      "Episode: 1, Step: 747, Action: [-0.20595375  0.10700946 -0.02227738 -0.41913033], Reward: -0.24360573291778564\n",
      "Episode: 1, Step: 748, Action: [ 0.27945945  0.15761605 -0.43342757 -0.22989613], Reward: -0.2441568523645401\n",
      "Episode: 1, Step: 749, Action: [-0.27567348  0.7592511  -0.69080234  0.01435312], Reward: -0.2435629516839981\n",
      "Episode: 1, Step: 750, Action: [ 0.8361166  -0.43351594 -0.98301345 -0.8083866 ], Reward: -0.24326731264591217\n",
      "Episode: 1, Step: 751, Action: [-0.14437746  0.75765383  0.32798618  0.02894266], Reward: -0.24251019954681396\n",
      "Episode: 1, Step: 752, Action: [-0.39445964  0.59669214  0.62212026  0.15236096], Reward: -0.24098165333271027\n",
      "Episode: 1, Step: 753, Action: [0.42804012 0.8141064  0.15236165 0.72411287], Reward: -0.24062922596931458\n",
      "Episode: 1, Step: 754, Action: [-0.13432911 -0.4891466  -0.35705033 -0.61667264], Reward: -0.24082516133785248\n",
      "Episode: 1, Step: 755, Action: [-0.23474076 -0.9391009  -0.5749811   0.25964054], Reward: -0.24101975560188293\n",
      "Episode: 1, Step: 756, Action: [-0.9414245  -0.14502384  0.5409231  -0.3364726 ], Reward: -0.24021753668785095\n",
      "Episode: 1, Step: 757, Action: [-0.2598218  -0.18482201  0.66547704  0.78661084], Reward: -0.2393345683813095\n",
      "Episode: 1, Step: 758, Action: [-0.28404343 -0.5885898   0.2386925   0.29199344], Reward: -0.23775941133499146\n",
      "Episode: 1, Step: 759, Action: [-0.15380149 -0.36229357  0.24920568 -0.9873426 ], Reward: -0.2363840937614441\n",
      "Episode: 1, Step: 760, Action: [-0.7282585  -0.7041711  -0.37658867 -0.8548213 ], Reward: -0.23518052697181702\n",
      "Episode: 1, Step: 761, Action: [ 0.84740704 -0.7364801  -0.94892305  0.9967602 ], Reward: -0.23464563488960266\n",
      "Episode: 1, Step: 762, Action: [-0.4269573   0.53328735  0.812743    0.30754384], Reward: -0.2336287945508957\n",
      "Episode: 1, Step: 763, Action: [ 0.05264353  0.7097545  -0.16078365  0.27455336], Reward: -0.23271743953227997\n",
      "Episode: 1, Step: 764, Action: [ 0.06072009  0.6745714  -0.16962707 -0.43153867], Reward: -0.23243558406829834\n",
      "Episode: 1, Step: 765, Action: [ 0.39743546 -0.14322124  0.30352834 -0.7865914 ], Reward: -0.23202364146709442\n",
      "Episode: 1, Step: 766, Action: [0.7025041 0.38844   0.5172823 0.4579011], Reward: -0.23169031739234924\n",
      "Episode: 1, Step: 767, Action: [-0.7914609  -0.92746365 -0.91259444  0.36242098], Reward: -0.23142455518245697\n",
      "Episode: 1, Step: 768, Action: [-0.25682563 -0.6115536   0.54909873 -0.52529836], Reward: -0.2302040308713913\n",
      "Episode: 1, Step: 769, Action: [ 0.570916   -0.15720399  0.6878873   0.5180349 ], Reward: -0.22916950285434723\n",
      "Episode: 1, Step: 770, Action: [-0.3002653   0.48349795 -0.8258457   0.53447664], Reward: -0.22845983505249023\n",
      "Episode: 1, Step: 771, Action: [-0.9879803   0.18159078  0.7958124  -0.9476788 ], Reward: -0.22686760127544403\n",
      "Episode: 1, Step: 772, Action: [ 0.5716292  -0.83529943 -0.31610394  0.20028497], Reward: -0.2263360470533371\n",
      "Episode: 1, Step: 773, Action: [ 0.7160141  -0.39838645  0.5934272   0.4413502 ], Reward: -0.22560392320156097\n",
      "Episode: 1, Step: 774, Action: [-0.34197152  0.9169729   0.86570305 -0.28435236], Reward: -0.2241852730512619\n",
      "Episode: 1, Step: 775, Action: [-0.8730551   0.12706968  0.7328858  -0.91712457], Reward: -0.22242417931556702\n",
      "Episode: 1, Step: 776, Action: [ 0.97399044  0.6946373  -0.92078036 -0.06498855], Reward: -0.22171702980995178\n",
      "Episode: 1, Step: 777, Action: [-0.5440999  -0.45214143 -0.77759475 -0.82738036], Reward: -0.2210080921649933\n",
      "Episode: 1, Step: 778, Action: [-0.86428523  0.88538796  0.64790106  0.951516  ], Reward: -0.21962538361549377\n",
      "Episode: 1, Step: 779, Action: [-0.15659578 -0.8401407   0.849806    0.43765804], Reward: -0.2182539999485016\n",
      "Episode: 1, Step: 780, Action: [-0.3868844   0.38321686 -0.87750465  0.5285324 ], Reward: -0.21700450778007507\n",
      "Episode: 1, Step: 781, Action: [ 0.25786716 -0.6638179   0.20825975 -0.90325165], Reward: -0.216202512383461\n",
      "Episode: 1, Step: 782, Action: [ 0.12569997 -0.12746297 -0.8001761  -0.29384047], Reward: -0.21605418622493744\n",
      "Episode: 1, Step: 783, Action: [-0.453869   -0.16449122 -0.25416538  0.94376314], Reward: -0.2156628668308258\n",
      "Episode: 1, Step: 784, Action: [ 0.5598208  -0.2960498  -0.68135446  0.20385504], Reward: -0.21597738564014435\n",
      "Episode: 1, Step: 785, Action: [-0.75755507 -0.47612715 -0.24535114  0.01660416], Reward: -0.21548013389110565\n",
      "Episode: 1, Step: 786, Action: [ 0.75850254 -0.96874475  0.13143337 -0.9092117 ], Reward: -0.21499338746070862\n",
      "Episode: 1, Step: 787, Action: [-0.01502992  0.30220821 -0.4528499   0.82255447], Reward: -0.21519948542118073\n",
      "Episode: 1, Step: 788, Action: [0.24987023 0.60825396 0.8412919  0.1067389 ], Reward: -0.21563510596752167\n",
      "Episode: 1, Step: 789, Action: [-0.60167426  0.9840683  -0.6392032  -0.7466037 ], Reward: -0.21628083288669586\n",
      "Episode: 1, Step: 790, Action: [0.92415226 0.7122505  0.3007938  0.4252826 ], Reward: -0.21711233258247375\n",
      "Episode: 1, Step: 791, Action: [ 0.38488087 -0.29524443 -0.52809715  0.12831362], Reward: -0.2186967134475708\n",
      "Episode: 1, Step: 792, Action: [ 0.9600145   0.6514387   0.5685098  -0.96573114], Reward: -0.2203373908996582\n",
      "Episode: 1, Step: 793, Action: [ 0.84810436  0.97173053 -0.46307942 -0.8175156 ], Reward: -0.2227451354265213\n",
      "Episode: 1, Step: 794, Action: [-0.4211061  -0.1289339  -0.15174906  0.44090804], Reward: -0.22439241409301758\n",
      "Episode: 1, Step: 795, Action: [-0.7277421   0.9617329   0.68889093 -0.09506319], Reward: -0.22517439723014832\n",
      "Episode: 1, Step: 796, Action: [-0.15640678 -0.23884694  0.8063002   0.37744924], Reward: -0.22512660920619965\n",
      "Episode: 1, Step: 797, Action: [-0.5092747  -0.8847985   0.5684999   0.35835707], Reward: -0.22412720322608948\n",
      "Episode: 1, Step: 798, Action: [ 0.11112253  0.21807665  0.55398846 -0.74389833], Reward: -0.22351638972759247\n",
      "Episode: 1, Step: 799, Action: [ 0.9620227  -0.55201983  0.58417207 -0.5340815 ], Reward: -0.22318781912326813\n",
      "Episode: 1, Step: 800, Action: [-0.37110588  0.46065387 -0.4922419  -0.9570712 ], Reward: -0.22309517860412598\n",
      "Episode: 1, Step: 801, Action: [ 0.6592423   0.6221578  -0.87183225  0.34918445], Reward: -0.22398622334003448\n",
      "Episode: 1, Step: 802, Action: [ 0.9627954  -0.8990419  -0.65325904 -0.6903245 ], Reward: -0.225729838013649\n",
      "Episode: 1, Step: 803, Action: [-0.34846082 -0.71667343 -0.5829836   0.31365663], Reward: -0.22738981246948242\n",
      "Episode: 1, Step: 804, Action: [ 0.49051532 -0.12909003  0.83268684  0.6874392 ], Reward: -0.2290583699941635\n",
      "Episode: 1, Step: 805, Action: [-0.80322295 -0.17843997  0.43362892  0.47393134], Reward: -0.22985920310020447\n",
      "Episode: 1, Step: 806, Action: [-0.08335984 -0.18888107 -0.87334603 -0.92626464], Reward: -0.23082248866558075\n",
      "Episode: 1, Step: 807, Action: [ 0.15820104 -0.32027173 -0.42890042  0.74005866], Reward: -0.2319868803024292\n",
      "Episode: 1, Step: 808, Action: [ 0.85614324  0.67320275  0.94713223 -0.43871716], Reward: -0.23318012058734894\n",
      "Episode: 1, Step: 809, Action: [-0.6242691   0.88136613  0.6364663   0.7118076 ], Reward: -0.2337331473827362\n",
      "Episode: 1, Step: 810, Action: [0.0592881  0.4211804  0.97407484 0.6120063 ], Reward: -0.23349981009960175\n",
      "Episode: 1, Step: 811, Action: [-0.9801586   0.43961138  0.07482053  0.6605728 ], Reward: -0.23333793878555298\n",
      "Episode: 1, Step: 812, Action: [-0.34880692 -0.10835353  0.9492286  -0.32021213], Reward: -0.23222243785858154\n",
      "Episode: 1, Step: 813, Action: [-0.09235412 -0.7527612  -0.9939517   0.7847324 ], Reward: -0.2319209724664688\n",
      "Episode: 1, Step: 814, Action: [ 0.6489156  -0.19703041 -0.01062972 -0.05893478], Reward: -0.23183473944664001\n",
      "Episode: 1, Step: 815, Action: [-0.7390707   0.51591206  0.701266   -0.798881  ], Reward: -0.2310747355222702\n",
      "Episode: 1, Step: 816, Action: [-0.05070874 -0.11221274 -0.4876777   0.60160553], Reward: -0.23099644482135773\n",
      "Episode: 1, Step: 817, Action: [-0.3693305  -0.22141618  0.4027797   0.7342751 ], Reward: -0.2300572693347931\n",
      "Episode: 1, Step: 818, Action: [0.8561011  0.067807   0.06695564 0.47541302], Reward: -0.22961914539337158\n",
      "Episode: 1, Step: 819, Action: [ 0.96425897  0.4204082  -0.36319003 -0.28808108], Reward: -0.2303299605846405\n",
      "Episode: 1, Step: 820, Action: [-0.42688    -0.18821675 -0.49058723 -0.5380009 ], Reward: -0.23096518218517303\n",
      "Episode: 1, Step: 821, Action: [-0.09519091 -0.09868988  0.7223603  -0.29758525], Reward: -0.23101334273815155\n",
      "Episode: 1, Step: 822, Action: [-0.5897183  -0.6024509   0.6172982  -0.69518554], Reward: -0.23010700941085815\n",
      "Episode: 1, Step: 823, Action: [ 0.40409803 -0.33317268  0.3616539   0.36687508], Reward: -0.22921158373355865\n",
      "Episode: 1, Step: 824, Action: [-0.76672846  0.78342414 -0.74093425  0.97217125], Reward: -0.2285580337047577\n",
      "Episode: 1, Step: 825, Action: [ 0.94543105 -0.6473689   0.2089021   0.9277126 ], Reward: -0.22780168056488037\n",
      "Episode: 1, Step: 826, Action: [ 0.30728763  0.05966321  0.9383617  -0.0698299 ], Reward: -0.22710442543029785\n",
      "Episode: 1, Step: 827, Action: [-0.7699737  -0.57162356 -0.7594075   0.77493954], Reward: -0.22662055492401123\n",
      "Episode: 1, Step: 828, Action: [ 0.17567457 -0.1721595  -0.85002863  0.23462573], Reward: -0.22699376940727234\n",
      "Episode: 1, Step: 829, Action: [ 0.6815393  -0.95923203  0.8873447  -0.7579741 ], Reward: -0.2273692935705185\n",
      "Episode: 1, Step: 830, Action: [ 0.01973279 -0.17172064  0.25442445 -0.46634194], Reward: -0.22707407176494598\n",
      "Episode: 1, Step: 831, Action: [-0.40071598  0.6545249  -0.3867117  -0.7005984 ], Reward: -0.22689604759216309\n",
      "Episode: 1, Step: 832, Action: [-0.2687458  -0.1256112  -0.6383298   0.00833861], Reward: -0.22694729268550873\n",
      "Episode: 1, Step: 833, Action: [ 0.13154857  0.31891248 -0.88560945  0.4395837 ], Reward: -0.22800466418266296\n",
      "Episode: 1, Step: 834, Action: [ 0.81062454  0.38603207  0.687201   -0.7444321 ], Reward: -0.22914882004261017\n",
      "Episode: 1, Step: 835, Action: [-0.9210014   0.5429823  -0.6833821   0.85397124], Reward: -0.2302025854587555\n",
      "Episode: 1, Step: 836, Action: [ 0.9376632   0.6423803   0.02257946 -0.88734126], Reward: -0.23038913309574127\n",
      "Episode: 1, Step: 837, Action: [0.3111851  0.6192125  0.03562319 0.09103736], Reward: -0.2311021238565445\n",
      "Episode: 1, Step: 838, Action: [ 0.26974836  0.59159577  0.46253765 -0.83362377], Reward: -0.23180441558361053\n",
      "Episode: 1, Step: 839, Action: [ 0.37423176 -0.00094089  0.54230535  0.11245228], Reward: -0.23235924541950226\n",
      "Episode: 1, Step: 840, Action: [-0.31215492  0.3283006   0.6234655   0.52967066], Reward: -0.23229250311851501\n",
      "Episode: 1, Step: 841, Action: [-0.00906289  0.15351808 -0.06943095  0.7766303 ], Reward: -0.23240171372890472\n",
      "Episode: 1, Step: 842, Action: [-0.2942907   0.0467688   0.37379694 -0.19944811], Reward: -0.23175139725208282\n",
      "Episode: 1, Step: 843, Action: [0.48662588 0.19235857 0.78934973 0.8663431 ], Reward: -0.23136919736862183\n",
      "Episode: 1, Step: 844, Action: [-0.9400177  -0.43534446 -0.7206742  -0.59775347], Reward: -0.2310142070055008\n",
      "Episode: 1, Step: 845, Action: [-0.448609   -0.39970106  0.4404482   0.3518952 ], Reward: -0.22986067831516266\n",
      "Episode: 1, Step: 846, Action: [-0.02563128 -0.4629281  -0.57543427 -0.28292772], Reward: -0.22944346070289612\n",
      "Episode: 1, Step: 847, Action: [-0.29377306 -0.44277412 -0.4296862   0.5171164 ], Reward: -0.22895465791225433\n",
      "Episode: 1, Step: 848, Action: [-0.5839246  -0.24276538  0.38584146  0.327882  ], Reward: -0.2278641164302826\n",
      "Episode: 1, Step: 849, Action: [-0.1115429  -0.32829523 -0.3357575   0.2508927 ], Reward: -0.22758693993091583\n",
      "Episode: 1, Step: 850, Action: [0.27987912 0.87693816 0.7481246  0.753203  ], Reward: -0.22741323709487915\n",
      "Episode: 1, Step: 851, Action: [-0.90511405  0.81739736 -0.4154088  -0.99836093], Reward: -0.22755981981754303\n",
      "Episode: 1, Step: 852, Action: [-0.5054295  -0.06227648 -0.44524342 -0.3356908 ], Reward: -0.22733783721923828\n",
      "Episode: 1, Step: 853, Action: [-0.02073395 -0.59693676  0.51703644 -0.4568791 ], Reward: -0.2271716594696045\n",
      "Episode: 1, Step: 854, Action: [-0.24637775  0.2703513   0.80962545  0.6276763 ], Reward: -0.2261209934949875\n",
      "Episode: 1, Step: 855, Action: [0.16191226 0.0689963  0.37576517 0.9113354 ], Reward: -0.22526919841766357\n",
      "Episode: 1, Step: 856, Action: [ 0.196857   -0.14488658 -0.6022388   0.23119548], Reward: -0.2252829521894455\n",
      "Episode: 1, Step: 857, Action: [ 0.6587272  0.7068119 -0.3180813 -0.7043447], Reward: -0.22615402936935425\n",
      "Episode: 1, Step: 858, Action: [ 0.7267841  -0.07402909 -0.6786836  -0.5212424 ], Reward: -0.22796937823295593\n",
      "Episode: 1, Step: 859, Action: [ 0.43201926 -0.01276283 -0.6455267   0.4253825 ], Reward: -0.2303152233362198\n",
      "Episode: 1, Step: 860, Action: [-0.80218    -0.2900384   0.05222556 -0.04149821], Reward: -0.23171602189540863\n",
      "Episode: 1, Step: 861, Action: [-0.6839973  -0.04873506 -0.28288168  0.718007  ], Reward: -0.2325923889875412\n",
      "Episode: 1, Step: 862, Action: [-0.5854796   0.33143046  0.10417987 -0.78198034], Reward: -0.23250822722911835\n",
      "Episode: 1, Step: 863, Action: [-0.68025285 -0.51748365  0.00700313 -0.9592197 ], Reward: -0.23186369240283966\n",
      "Episode: 1, Step: 864, Action: [ 0.2769574  -0.76967263  0.3695919   0.38817462], Reward: -0.23117370903491974\n",
      "Episode: 1, Step: 865, Action: [ 0.5212274   0.91437864 -0.9623891   0.03933427], Reward: -0.23155085742473602\n",
      "Episode: 1, Step: 866, Action: [-0.3608175  -0.04942218 -0.80831087  0.06531379], Reward: -0.2321275919675827\n",
      "Episode: 1, Step: 867, Action: [-0.9826591  -0.18538497 -0.60612303 -0.7238372 ], Reward: -0.2314552217721939\n",
      "Episode: 1, Step: 868, Action: [ 0.3866223  -0.08825891  0.19944869 -0.52020997], Reward: -0.23096400499343872\n",
      "Episode: 1, Step: 869, Action: [-0.60735375  0.7291166   0.44257763 -0.7385145 ], Reward: -0.22963573038578033\n",
      "Episode: 1, Step: 870, Action: [0.81959456 0.773237   0.9873893  0.8052654 ], Reward: -0.22841650247573853\n",
      "Episode: 1, Step: 871, Action: [-0.63569    -0.7686938   0.07259648 -0.3658281 ], Reward: -0.22724366188049316\n",
      "Episode: 1, Step: 872, Action: [-0.34186077  0.23099773  0.72128665  0.02577433], Reward: -0.22539076209068298\n",
      "Episode: 1, Step: 873, Action: [ 0.79603225 -0.23475452  0.15908492 -0.28224334], Reward: -0.2244051843881607\n",
      "Episode: 1, Step: 874, Action: [-0.8895097  -0.9453799  -0.44942197  0.67542416], Reward: -0.2236037254333496\n",
      "Episode: 1, Step: 875, Action: [-0.65494204 -0.7838473  -0.5566894   0.7274868 ], Reward: -0.222799614071846\n",
      "Episode: 1, Step: 876, Action: [-0.21733403  0.86105984  0.89752936 -0.7296857 ], Reward: -0.22209681570529938\n",
      "Episode: 1, Step: 877, Action: [ 0.9356892  -0.6214815   0.87995803 -0.658416  ], Reward: -0.22135545313358307\n",
      "Episode: 1, Step: 878, Action: [ 0.69041115  0.3399018   0.9444944  -0.9875737 ], Reward: -0.22056685388088226\n",
      "Episode: 1, Step: 879, Action: [-0.64855456 -0.7809805  -0.3510598   0.5197399 ], Reward: -0.21997447311878204\n",
      "Episode: 1, Step: 880, Action: [ 0.5782302  -0.88380414  0.6781945   0.40835398], Reward: -0.2192811518907547\n",
      "Episode: 1, Step: 881, Action: [-0.3821402   0.40498632 -0.53457654  0.28034472], Reward: -0.2187735140323639\n",
      "Episode: 1, Step: 882, Action: [ 0.98354495  0.46187454 -0.5181914   0.6555418 ], Reward: -0.21936407685279846\n",
      "Episode: 1, Step: 883, Action: [ 0.954838   -0.14329837 -0.09838839 -0.7776121 ], Reward: -0.21997365355491638\n",
      "Episode: 1, Step: 884, Action: [ 0.6377444   0.7960178   0.1340472  -0.83455914], Reward: -0.22049635648727417\n",
      "Episode: 1, Step: 885, Action: [-0.95468795 -0.16846657  0.5791008   0.68941945], Reward: -0.2201743721961975\n",
      "Episode: 1, Step: 886, Action: [ 0.675273   -0.5377316   0.50087255 -0.34592605], Reward: -0.21987278759479523\n",
      "Episode: 1, Step: 887, Action: [-0.15758151  0.8705967   0.8497626   0.71078706], Reward: -0.2188594788312912\n",
      "Episode: 1, Step: 888, Action: [ 0.38254508 -0.45221126  0.39746708  0.8973013 ], Reward: -0.2187754213809967\n",
      "Episode: 1, Step: 889, Action: [ 0.44488302  0.7479109  -0.26098618 -0.770533  ], Reward: -0.21974417567253113\n",
      "Episode: 1, Step: 890, Action: [0.12633397 0.7290727  0.5245578  0.7879817 ], Reward: -0.21990534663200378\n",
      "Episode: 1, Step: 891, Action: [ 0.06955881  0.03447697 -0.61472464 -0.69012535], Reward: -0.22015464305877686\n",
      "Episode: 1, Step: 892, Action: [ 0.33323362  0.01661016 -0.88008904 -0.3038525 ], Reward: -0.22136744856834412\n",
      "Episode: 1, Step: 893, Action: [-0.02024038 -0.89458495  0.83616364  0.18139875], Reward: -0.2218146026134491\n",
      "Episode: 1, Step: 894, Action: [-0.9209797  -0.3608268  -0.00348746 -0.13754493], Reward: -0.2216494381427765\n",
      "Episode: 1, Step: 895, Action: [ 0.17305446 -0.99228626  0.5241004  -0.15163703], Reward: -0.22141095995903015\n",
      "Episode: 1, Step: 896, Action: [0.21581519 0.5746742  0.8744432  0.7317873 ], Reward: -0.22132112085819244\n",
      "Episode: 1, Step: 897, Action: [-0.62480503 -0.07537156  0.6693179   0.66637   ], Reward: -0.2206144630908966\n",
      "Episode: 1, Step: 898, Action: [ 0.35206345 -0.75535405 -0.18179587 -0.20849562], Reward: -0.22073112428188324\n",
      "Episode: 1, Step: 899, Action: [-0.19357096 -0.95969886 -0.07098659  0.35096005], Reward: -0.22094768285751343\n",
      "Episode: 1, Step: 900, Action: [-0.84991467  0.38658226 -0.13638593  0.3988879 ], Reward: -0.2210364043712616\n",
      "Episode: 1, Step: 901, Action: [ 0.34570357  0.14364497  0.22391474 -0.79454494], Reward: -0.22114421427249908\n",
      "Episode: 1, Step: 902, Action: [-0.5284678  -0.28312466  0.7856087   0.732605  ], Reward: -0.22049137949943542\n",
      "Episode: 1, Step: 903, Action: [ 0.6855458 -0.4727727 -0.7397642 -0.7293281], Reward: -0.22072142362594604\n",
      "Episode: 1, Step: 904, Action: [-0.33612576  0.55332816  0.5664925   0.99346036], Reward: -0.2202373892068863\n",
      "Episode: 1, Step: 905, Action: [-0.7191774  -0.7788693   0.13408531 -0.73725575], Reward: -0.21952351927757263\n",
      "Episode: 1, Step: 906, Action: [ 0.38843548  0.6557578  -0.11419576 -0.30230656], Reward: -0.219598650932312\n",
      "Episode: 1, Step: 907, Action: [ 0.00681273  0.669868    0.6925555  -0.03886011], Reward: -0.21941204369068146\n",
      "Episode: 1, Step: 908, Action: [ 0.7744522   0.81455386 -0.68707764  0.06124635], Reward: -0.2201700210571289\n",
      "Episode: 1, Step: 909, Action: [-0.703838   -0.03717531 -0.82882136 -0.4406702 ], Reward: -0.2209831178188324\n",
      "Episode: 1, Step: 910, Action: [-0.3074474  -0.82641196  0.23341759  0.1116504 ], Reward: -0.22102265059947968\n",
      "Episode: 1, Step: 911, Action: [ 0.6613039  -0.8768236  -0.4597613  -0.98465395], Reward: -0.22174791991710663\n",
      "Episode: 1, Step: 912, Action: [-0.5169062  -0.99553233  0.23527294  0.96932787], Reward: -0.2217777669429779\n",
      "Episode: 1, Step: 913, Action: [-0.8310662  -0.00736888 -0.36434075 -0.9359394 ], Reward: -0.22155870497226715\n",
      "Episode: 1, Step: 914, Action: [-0.482641   -0.6423624   0.24882668  0.80019873], Reward: -0.22064276039600372\n",
      "Episode: 1, Step: 915, Action: [ 0.1873169   0.90766454  0.73923445 -0.6170371 ], Reward: -0.21969272196292877\n",
      "Episode: 1, Step: 916, Action: [-0.93787473 -0.46246624 -0.10858562 -0.754903  ], Reward: -0.21863551437854767\n",
      "Episode: 1, Step: 917, Action: [-0.6692579  -0.8081918  -0.90593714  0.8156884 ], Reward: -0.2178407460451126\n",
      "Episode: 1, Step: 918, Action: [ 0.12953155 -0.91451424  0.39090744 -0.81151265], Reward: -0.21716512739658356\n",
      "Episode: 1, Step: 919, Action: [-0.5628834  -0.33015966  0.27932918 -0.9614862 ], Reward: -0.21561124920845032\n",
      "Episode: 1, Step: 920, Action: [ 0.11203931 -0.09673279 -0.6525484  -0.5585267 ], Reward: -0.2150108516216278\n",
      "Episode: 1, Step: 921, Action: [-0.7135226  -0.8006168  -0.10656807 -0.88728553], Reward: -0.21377237141132355\n",
      "Episode: 1, Step: 922, Action: [-0.4508207  -0.4630547   0.2042944   0.41238973], Reward: -0.21214289963245392\n",
      "Episode: 1, Step: 923, Action: [-0.6593172  -0.90553737 -0.80500615 -0.37410823], Reward: -0.2106306105852127\n",
      "Episode: 1, Step: 924, Action: [ 0.4835279   0.83818024  0.7887531  -0.6816584 ], Reward: -0.20908677577972412\n",
      "Episode: 1, Step: 925, Action: [ 0.36650807  0.60892797  0.5190708  -0.15555368], Reward: -0.20754112303256989\n",
      "Episode: 1, Step: 926, Action: [-0.23760113  0.8165524  -0.71172404 -0.38953242], Reward: -0.2068537175655365\n",
      "Episode: 1, Step: 927, Action: [ 0.6981374   0.79784954  0.12973145 -0.11393022], Reward: -0.20617274940013885\n",
      "Episode: 1, Step: 928, Action: [ 0.10213461 -0.8899354  -0.34409124  0.37621468], Reward: -0.20655414462089539\n",
      "Episode: 1, Step: 929, Action: [ 0.3233768  -0.9478672  -0.8941449  -0.24622937], Reward: -0.20805707573890686\n",
      "Episode: 1, Step: 930, Action: [ 0.9945458   0.09933037  0.3130862  -0.94859475], Reward: -0.20938031375408173\n",
      "Episode: 1, Step: 931, Action: [ 0.4837756  -0.97623074  0.1607355  -0.50296146], Reward: -0.21078382432460785\n",
      "Episode: 1, Step: 932, Action: [-0.49117324 -0.25287804 -0.7352704  -0.5970994 ], Reward: -0.21241474151611328\n",
      "Episode: 1, Step: 933, Action: [-0.43274242 -0.6016801  -0.9888914   0.01979954], Reward: -0.21431870758533478\n",
      "Episode: 1, Step: 934, Action: [ 0.71301746  0.7596224   0.33471575 -0.30352178], Reward: -0.2160416841506958\n",
      "Episode: 1, Step: 935, Action: [-0.02303177  0.14405857  0.30070755  0.12282585], Reward: -0.21685093641281128\n",
      "Episode: 1, Step: 936, Action: [0.4632328  0.35008633 0.24995606 0.11313432], Reward: -0.217478409409523\n",
      "Episode: 1, Step: 937, Action: [ 0.11054794  0.6218327   0.5205518  -0.27835196], Reward: -0.2172943502664566\n",
      "Episode: 1, Step: 938, Action: [-0.95512486 -0.89161044  0.9937245  -0.5490907 ], Reward: -0.216370090842247\n",
      "Episode: 1, Step: 939, Action: [-0.8932885  -0.22522461  0.21621926  0.2773911 ], Reward: -0.2155909687280655\n",
      "Episode: 1, Step: 940, Action: [ 0.97061014  0.8860894  -0.19885974 -0.7683191 ], Reward: -0.21577365696430206\n",
      "Episode: 1, Step: 941, Action: [ 0.43549472  0.3568217  -0.9893775  -0.00674216], Reward: -0.21688899397850037\n",
      "Episode: 1, Step: 942, Action: [-0.7183469   0.38050792  0.8570291  -0.9592037 ], Reward: -0.21706105768680573\n",
      "Episode: 1, Step: 943, Action: [-0.25351843  0.74293584 -0.6643372  -0.87421995], Reward: -0.21738384664058685\n",
      "Episode: 1, Step: 944, Action: [-0.26861924  0.45681235 -0.4239143  -0.37984684], Reward: -0.2170799970626831\n",
      "Episode: 1, Step: 945, Action: [ 0.10850714  0.7267198   0.92647654 -0.7897497 ], Reward: -0.2167852520942688\n",
      "Episode: 1, Step: 946, Action: [ 0.9115427  -0.23630026  0.412605    0.26104763], Reward: -0.21648702025413513\n",
      "Episode: 1, Step: 947, Action: [-0.02839861  0.99826545 -0.82928604  0.0789456 ], Reward: -0.216637521982193\n",
      "Episode: 1, Step: 948, Action: [ 0.58653516 -0.98033226  0.74417794  0.54139227], Reward: -0.216587096452713\n",
      "Episode: 1, Step: 949, Action: [-0.8781072   0.17674276  0.42777288 -0.25980622], Reward: -0.21582607924938202\n",
      "Episode: 1, Step: 950, Action: [ 0.7922788  -0.68509054 -0.68465996 -0.91208977], Reward: -0.216104656457901\n",
      "Episode: 1, Step: 951, Action: [-0.2953445 -0.7302135  0.1898551 -0.4781151], Reward: -0.21560828387737274\n",
      "Episode: 1, Step: 952, Action: [-0.5108098  -0.71474236  0.6670774   0.42915773], Reward: -0.21429280936717987\n",
      "Episode: 1, Step: 953, Action: [-0.817118   -0.20681596  0.41655946 -0.8499088 ], Reward: -0.21269682049751282\n",
      "Episode: 1, Step: 954, Action: [ 0.24639645 -0.07817956  0.30495995  0.86242324], Reward: -0.21158596873283386\n",
      "Episode: 1, Step: 955, Action: [-0.96482855  0.7180553   0.5072562   0.5268636 ], Reward: -0.20970045030117035\n",
      "Episode: 1, Step: 956, Action: [ 0.3071185   0.41062582 -0.5975237   0.3134881 ], Reward: -0.2087169885635376\n",
      "Episode: 1, Step: 957, Action: [-0.04828008 -0.58960307 -0.6104608  -0.69466054], Reward: -0.20874464511871338\n",
      "Episode: 1, Step: 958, Action: [0.10655672 0.89385563 0.59309286 0.62338847], Reward: -0.20870529115200043\n",
      "Episode: 1, Step: 959, Action: [-1.5959366e-04 -1.9804460e-03  9.2637116e-01  4.9566123e-01], Reward: -0.20802722871303558\n",
      "Episode: 1, Step: 960, Action: [ 0.72002554 -0.20262721  0.94409996  0.80752414], Reward: -0.20731571316719055\n",
      "Episode: 1, Step: 961, Action: [ 0.8469102  -0.39499047  0.94949025  0.20297606], Reward: -0.20683260262012482\n",
      "Episode: 1, Step: 962, Action: [ 0.8815322   0.05458186 -0.5016631   0.83689916], Reward: -0.20717744529247284\n",
      "Episode: 1, Step: 963, Action: [0.23231576 0.21318352 0.38084114 0.4673026 ], Reward: -0.20737256109714508\n",
      "Episode: 1, Step: 964, Action: [-0.08585725  0.6345211  -0.20621286 -0.5027486 ], Reward: -0.20761875808238983\n",
      "Episode: 1, Step: 965, Action: [-0.29166704  0.7446877  -0.41367128  0.80565965], Reward: -0.2080027014017105\n",
      "Episode: 1, Step: 966, Action: [ 0.8201109  -0.7367215   0.23112524 -0.9739755 ], Reward: -0.20842410624027252\n",
      "Episode: 1, Step: 967, Action: [-0.35236737  0.9166657   0.80129445  0.45709094], Reward: -0.20793740451335907\n",
      "Episode: 1, Step: 968, Action: [ 0.7343598  -0.90186304  0.44553444 -0.39905447], Reward: -0.20758529007434845\n",
      "Episode: 1, Step: 969, Action: [ 0.24134272 -0.4430764  -0.8967109  -0.9939534 ], Reward: -0.20822900533676147\n",
      "Episode: 1, Step: 970, Action: [-0.6340415  -0.6467303  -0.39611357 -0.02938743], Reward: -0.209039568901062\n",
      "Episode: 1, Step: 971, Action: [ 0.4799745 -0.842863  -0.9704302  0.2847954], Reward: -0.21083085238933563\n",
      "Episode: 1, Step: 972, Action: [ 0.53150815  0.17929819 -0.8834613   0.4410121 ], Reward: -0.21355026960372925\n",
      "Episode: 1, Step: 973, Action: [-0.76584965  0.9527568   0.9952197   0.6517062 ], Reward: -0.2154504656791687\n",
      "Episode: 1, Step: 974, Action: [ 0.57011575 -0.3244244  -0.19080047  0.7277631 ], Reward: -0.21738818287849426\n",
      "Episode: 1, Step: 975, Action: [-0.6542887  -0.31350943  0.1677187   0.29039526], Reward: -0.21857711672782898\n",
      "Episode: 1, Step: 976, Action: [-0.97139025 -0.58182806  0.95043194  0.81349546], Reward: -0.21893349289894104\n",
      "Episode: 1, Step: 977, Action: [-0.20498104 -0.32812455 -0.4304169  -0.33893242], Reward: -0.2194109559059143\n",
      "Episode: 1, Step: 978, Action: [-0.8226207   0.5434629   0.99474376  0.44182125], Reward: -0.2190888226032257\n",
      "Episode: 1, Step: 979, Action: [0.00830677 0.18668936 0.83346367 0.02062717], Reward: -0.21867787837982178\n",
      "Episode: 1, Step: 980, Action: [ 0.62353206  0.04685808 -0.5360806  -0.8471513 ], Reward: -0.21919208765029907\n",
      "Episode: 1, Step: 981, Action: [ 0.9750764   0.55231434 -0.40650743  0.62085366], Reward: -0.22066624462604523\n",
      "Episode: 1, Step: 982, Action: [ 0.27848163 -0.13968366  0.16501716  0.6144024 ], Reward: -0.2218925505876541\n",
      "Episode: 1, Step: 983, Action: [-0.13507223 -0.2591127   0.04574348  0.14501888], Reward: -0.2224624902009964\n",
      "Episode: 1, Step: 984, Action: [ 0.91362303  0.5022456  -0.26629558 -0.55776644], Reward: -0.22399479150772095\n",
      "Episode: 1, Step: 985, Action: [-0.8516413  0.9838418 -0.9193456 -0.9065247], Reward: -0.22560487687587738\n",
      "Episode: 1, Step: 986, Action: [-0.2863535  -0.28462917 -0.7345667   0.4759914 ], Reward: -0.22723731398582458\n",
      "Episode: 1, Step: 987, Action: [ 0.34634492  0.50043863  0.29093605 -0.45652992], Reward: -0.22875060141086578\n",
      "Episode: 1, Step: 988, Action: [-0.18117738  0.2933298   0.3569435  -0.5619171 ], Reward: -0.2293243259191513\n",
      "Episode: 1, Step: 989, Action: [-0.15844955  0.4889741  -0.08854715  0.75048655], Reward: -0.2291945070028305\n",
      "Episode: 1, Step: 990, Action: [-0.0047521   0.23411302  0.11886876 -0.4976211 ], Reward: -0.2288789004087448\n",
      "Episode: 1, Step: 991, Action: [ 0.7021583   0.29451945 -0.58313787 -0.41286623], Reward: -0.2295248955488205\n",
      "Episode: 1, Step: 992, Action: [ 0.09711323  0.08490273 -0.17938444  0.63795596], Reward: -0.22978965938091278\n",
      "Episode: 1, Step: 993, Action: [-0.63582116 -0.20132817 -0.46509218 -0.41558892], Reward: -0.22973747551441193\n",
      "Episode: 1, Step: 994, Action: [ 0.27809525  0.40943897 -0.63436735 -0.4581768 ], Reward: -0.2300569862127304\n",
      "Episode: 1, Step: 995, Action: [ 0.7589876  -0.32287753  0.903204    0.697573  ], Reward: -0.2302495688199997\n",
      "Episode: 1, Step: 996, Action: [0.3764242  0.40761498 0.85387194 0.95973825], Reward: -0.23051466047763824\n",
      "Episode: 1, Step: 997, Action: [-0.20837255 -0.1330977   0.95159155 -0.25354892], Reward: -0.22998887300491333\n",
      "Episode: 1, Step: 998, Action: [ 0.11348718 -0.9924893  -0.27605215  0.7478969 ], Reward: -0.22976745665073395\n",
      "Episode: 1, Step: 999, Action: [ 0.86209524  0.82896566 -0.9063373   0.09422646], Reward: -0.23044544458389282\n",
      "Episode: 1, Step: 1000, Action: [ 0.85217327  0.99956924  0.8712963  -0.8214552 ], Reward: -0.23112472891807556\n",
      "Episode: 1, Step: 1001, Action: [-0.89687675 -0.49139595  0.9325267   0.83126694], Reward: -0.23098203539848328\n",
      "Episode finished after 1001 steps. Info: {}\n",
      "Observation: {'robotId_1': {'joint_states': {'joint_0': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}, 'joint_1': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}, 'joint_2': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}}, 'robot_position': [0.0, 0.0, 0.03], 'pipette_position': [0.073, 0.0895, 0.1195]}}\n",
      "Episode: 2, Step: 1, Action: [-0.55230093 -0.91070473  0.29964167 -0.24446689], Reward: -0.07894182205200195\n",
      "Episode: 2, Step: 2, Action: [ 0.33746123  0.8896822  -0.15249489  0.9455315 ], Reward: -0.07894182205200195\n",
      "Episode: 2, Step: 3, Action: [ 0.9733119   0.08839652 -0.15366563  0.821831  ], Reward: -0.07832808047533035\n",
      "Episode: 2, Step: 4, Action: [ 0.4681489   0.00648436  0.63340956 -0.0540828 ], Reward: -0.0775948092341423\n",
      "Episode: 2, Step: 5, Action: [ 0.9394308   0.68078554 -0.81648505  0.71706074], Reward: -0.07627829909324646\n",
      "Episode: 2, Step: 6, Action: [ 0.0150542   0.7420585  -0.49306682 -0.87819684], Reward: -0.07480809837579727\n",
      "Episode: 2, Step: 7, Action: [-0.34870514 -0.8177504   0.5940619   0.33398563], Reward: -0.07384876161813736\n",
      "Episode: 2, Step: 8, Action: [-0.909584    0.502832   -0.6312446  -0.48462647], Reward: -0.07300417870283127\n",
      "Episode: 2, Step: 9, Action: [ 0.15880951 -0.13402921 -0.00324618 -0.04163642], Reward: -0.07229921221733093\n",
      "Episode: 2, Step: 10, Action: [-0.1652859  -0.10002925 -0.6029023  -0.7763961 ], Reward: -0.07229921221733093\n",
      "Episode: 2, Step: 11, Action: [-0.6263605   0.30049258 -0.30458876 -0.19076784], Reward: -0.07209067046642303\n",
      "Episode: 2, Step: 12, Action: [ 0.48117444 -0.50575525  0.4630535   0.70899934], Reward: -0.07192295044660568\n",
      "Episode: 2, Step: 13, Action: [-0.8022127  0.8057824 -0.8665465  0.6841167], Reward: -0.07178383320569992\n",
      "Episode: 2, Step: 14, Action: [-0.77140665  0.19279061 -0.94199514 -0.33806345], Reward: -0.07176166027784348\n",
      "Episode: 2, Step: 15, Action: [ 0.0289221   0.14996834 -0.14028552  0.05201326], Reward: -0.07164372503757477\n",
      "Episode: 2, Step: 16, Action: [-0.5905066  -0.765707   -0.18196826 -0.92685276], Reward: -0.07216265797615051\n",
      "Episode: 2, Step: 17, Action: [ 0.8471938   0.9836485  -0.70625865 -0.13119693], Reward: -0.07206092774868011\n",
      "Episode: 2, Step: 18, Action: [ 0.49931678  0.55612093  0.903042   -0.01113705], Reward: -0.07102572917938232\n",
      "Episode: 2, Step: 19, Action: [-0.5882431  -0.4129302   0.14758456  0.03899487], Reward: -0.07077357918024063\n",
      "Episode: 2, Step: 20, Action: [-0.4356258   0.8614865  -0.17382891 -0.32502925], Reward: -0.07055788487195969\n",
      "Episode: 2, Step: 21, Action: [-0.44736338 -0.2448779   0.2698578   0.8101618 ], Reward: -0.07098609954118729\n",
      "Episode: 2, Step: 22, Action: [ 0.7647109  -0.6206877   0.85305023 -0.13295425], Reward: -0.0713169053196907\n",
      "Episode: 2, Step: 23, Action: [-0.82688445 -0.8992768   0.28099048  0.3811363 ], Reward: -0.07255548238754272\n",
      "Episode: 2, Step: 24, Action: [ 0.10503697  0.03715242 -0.83917093  0.440968  ], Reward: -0.07315206527709961\n",
      "Episode: 2, Step: 25, Action: [ 0.81542426  0.8453146  -0.9350804   0.73564315], Reward: -0.07312750816345215\n",
      "Episode: 2, Step: 26, Action: [ 0.8541716  -0.16329983  0.29770094  0.76972365], Reward: -0.07296779751777649\n",
      "Episode: 2, Step: 27, Action: [ 0.3929529   0.9346809   0.9840672  -0.71573806], Reward: -0.07193420827388763\n",
      "Episode: 2, Step: 28, Action: [ 0.7976839  -0.42030197 -0.28140303  0.7311688 ], Reward: -0.071639284491539\n",
      "Episode: 2, Step: 29, Action: [-0.8480824   0.9783868  -0.17938015 -0.73830175], Reward: -0.07167395204305649\n",
      "Episode: 2, Step: 30, Action: [-0.81963825 -0.791766   -0.05973201 -0.6081571 ], Reward: -0.07246578484773636\n",
      "Episode: 2, Step: 31, Action: [-0.13296394  0.33760065  0.9968448  -0.73799914], Reward: -0.07357227802276611\n",
      "Episode: 2, Step: 32, Action: [-0.20454574 -0.43156877  0.3461652   0.01776226], Reward: -0.07501797378063202\n",
      "Episode: 2, Step: 33, Action: [-0.33781117 -0.8700058   0.45651567 -0.10989806], Reward: -0.07689307630062103\n",
      "Episode: 2, Step: 34, Action: [-0.82280964 -0.02974781  0.04246022  0.9757148 ], Reward: -0.07874027639627457\n",
      "Episode: 2, Step: 35, Action: [-0.24307188 -0.30568323 -0.10887938 -0.9149522 ], Reward: -0.08048701286315918\n",
      "Episode: 2, Step: 36, Action: [ 0.3882946  -0.983662   -0.87394696 -0.9061134 ], Reward: -0.0821685642004013\n",
      "Episode: 2, Step: 37, Action: [-0.5881151  -0.55928457  0.45470244  0.95512724], Reward: -0.08482644706964493\n",
      "Episode: 2, Step: 38, Action: [ 0.76819754  0.90010357 -0.7446688   0.46264672], Reward: -0.08629585802555084\n",
      "Episode: 2, Step: 39, Action: [-0.6668806   0.08952938  0.4853208   0.8464814 ], Reward: -0.0882001593708992\n",
      "Episode: 2, Step: 40, Action: [-0.09778231 -0.31490725  0.88246244 -0.19909254], Reward: -0.09051786363124847\n",
      "Episode: 2, Step: 41, Action: [-0.6953419  -0.515532    0.12206288 -0.16415237], Reward: -0.09293203055858612\n",
      "Episode: 2, Step: 42, Action: [0.752914   0.9392014  0.56193674 0.24760953], Reward: -0.09511207789182663\n",
      "Episode: 2, Step: 43, Action: [ 0.42565227 -0.9979653   0.10165024  0.54751396], Reward: -0.09679284691810608\n",
      "Episode: 2, Step: 44, Action: [ 0.24900998  0.16588548 -0.9105082   0.76137555], Reward: -0.09731525927782059\n",
      "Episode: 2, Step: 45, Action: [ 0.45749032 -0.45971367  0.57060647  0.15620744], Reward: -0.09822525084018707\n",
      "Episode: 2, Step: 46, Action: [ 0.5105594  -0.30624205  0.12307993 -0.8938563 ], Reward: -0.09865181893110275\n",
      "Episode: 2, Step: 47, Action: [-0.50521684  0.56265694 -0.7953967  -0.9155244 ], Reward: -0.09838078171014786\n",
      "Episode: 2, Step: 48, Action: [0.62630355 0.6697712  0.20820236 0.6563832 ], Reward: -0.09794355928897858\n",
      "Episode: 2, Step: 49, Action: [-0.72904795  0.13225676  0.0946637   0.87313867], Reward: -0.09748644381761551\n",
      "Episode: 2, Step: 50, Action: [0.04178452 0.71763766 0.26715848 0.46258155], Reward: -0.09721916913986206\n",
      "Episode: 2, Step: 51, Action: [ 0.64311415 -0.85251886 -0.33496287 -0.7982538 ], Reward: -0.09649409353733063\n",
      "Episode: 2, Step: 52, Action: [-0.11292238  0.9372196   0.2346503   0.34283218], Reward: -0.09609654545783997\n",
      "Episode: 2, Step: 53, Action: [ 0.84260494  0.7262535   0.8576105  -0.9551015 ], Reward: -0.09551685303449631\n",
      "Episode: 2, Step: 54, Action: [-0.9245106   0.7651649  -0.44182825 -0.23497975], Reward: -0.09434916079044342\n",
      "Episode: 2, Step: 55, Action: [0.2383011  0.95608443 0.71901715 0.04792236], Reward: -0.09303414821624756\n",
      "Episode: 2, Step: 56, Action: [0.43942016 0.6151478  0.4214325  0.6895422 ], Reward: -0.09172917157411575\n",
      "Episode: 2, Step: 57, Action: [-0.20712069 -0.91252553  0.6081646   0.80394936], Reward: -0.0915556475520134\n",
      "Episode: 2, Step: 58, Action: [ 0.9393831   0.42820916 -0.30059427  0.38667622], Reward: -0.09060654789209366\n",
      "Episode: 2, Step: 59, Action: [-0.08132788  0.959712    0.24656306  0.37105152], Reward: -0.08959940075874329\n",
      "Episode: 2, Step: 60, Action: [-0.15147936 -0.30259672  0.9895389  -0.7505401 ], Reward: -0.08975400030612946\n",
      "Episode: 2, Step: 61, Action: [ 0.2447861 -0.6028679 -0.5286499  0.6428878], Reward: -0.08915719389915466\n",
      "Episode: 2, Step: 62, Action: [ 0.75053203 -0.936837   -0.07863667 -0.81376904], Reward: -0.08795004338026047\n",
      "Episode: 2, Step: 63, Action: [ 0.5546987   0.55756706 -0.52224416  0.37777272], Reward: -0.08538901060819626\n",
      "Episode: 2, Step: 64, Action: [ 0.6960157   0.9667876  -0.26085043  0.20215558], Reward: -0.08260376751422882\n",
      "Episode: 2, Step: 65, Action: [ 0.8076286   0.05776545  0.52950114 -0.13295034], Reward: -0.08044002950191498\n",
      "Episode: 2, Step: 66, Action: [ 0.14729252 -0.1649199   0.5423174  -0.36664256], Reward: -0.07943598181009293\n",
      "Episode: 2, Step: 67, Action: [-0.8773181  -0.89379066 -0.64345735 -0.99826765], Reward: -0.07818283885717392\n",
      "Episode: 2, Step: 68, Action: [ 0.30469698 -0.06362387  0.13847153  0.6543795 ], Reward: -0.07786890864372253\n",
      "Episode: 2, Step: 69, Action: [ 0.51597095  0.14105749 -0.12414667 -0.989855  ], Reward: -0.07643713802099228\n",
      "Episode: 2, Step: 70, Action: [-0.39041126  0.17087246 -0.1407539  -0.9961445 ], Reward: -0.07497525215148926\n",
      "Episode: 2, Step: 71, Action: [-0.23415951  0.17388572  0.5483868   0.2736506 ], Reward: -0.07447942346334457\n",
      "Episode: 2, Step: 72, Action: [ 0.61373043 -0.4571213  -0.24252373  0.264225  ], Reward: -0.07311584055423737\n",
      "Episode: 2, Step: 73, Action: [ 0.8089362   0.56304777 -0.00126185  0.66883475], Reward: -0.07176139950752258\n",
      "Episode: 2, Step: 74, Action: [-0.11676375 -0.5399109   0.46307418 -0.502704  ], Reward: -0.07181437313556671\n",
      "Episode: 2, Step: 75, Action: [ 0.07088825 -0.91129714  0.26579332  0.02394019], Reward: -0.07231228798627853\n",
      "Episode: 2, Step: 76, Action: [-0.4216246 -0.1538461 -0.92904   -0.544544 ], Reward: -0.07236341387033463\n",
      "Episode: 2, Step: 77, Action: [ 0.31162727 -0.7964883   0.04100529  0.11141506], Reward: -0.0727289468050003\n",
      "Episode: 2, Step: 78, Action: [-0.19699973 -0.41126102  0.20405735 -0.2694438 ], Reward: -0.0739973783493042\n",
      "Episode: 2, Step: 79, Action: [ 0.19351348  0.64052063 -0.33444217  0.04830278], Reward: -0.07398521900177002\n",
      "Episode: 2, Step: 80, Action: [-0.6194609  -0.16792345  0.78432226  0.7098291 ], Reward: -0.07459049671888351\n",
      "Episode: 2, Step: 81, Action: [ 0.5094143  -0.5082254   0.06571615 -0.7575278 ], Reward: -0.0751212015748024\n",
      "Episode: 2, Step: 82, Action: [-0.85465306 -0.8058595  -0.9215058   0.8706384 ], Reward: -0.07519105821847916\n",
      "Episode: 2, Step: 83, Action: [ 0.33530834  0.01686402  0.48473984 -0.17239714], Reward: -0.07555381208658218\n",
      "Episode: 2, Step: 84, Action: [ 0.20193191  0.17689404 -0.29440117 -0.98291945], Reward: -0.07482173293828964\n",
      "Episode: 2, Step: 85, Action: [ 0.33982033  0.8515164   0.9632478  -0.16469197], Reward: -0.07423888891935349\n",
      "Episode: 2, Step: 86, Action: [ 0.28905857 -0.1012974   0.7179976  -0.4956073 ], Reward: -0.0744536742568016\n",
      "Episode: 2, Step: 87, Action: [-0.34005067 -0.8811298   0.04731852 -0.05572071], Reward: -0.07492807507514954\n",
      "Episode: 2, Step: 88, Action: [ 0.19324298 -0.405208    0.31291482  0.4463841 ], Reward: -0.07649822533130646\n",
      "Episode: 2, Step: 89, Action: [-0.4343308  -0.6323378  -0.97474    -0.84991014], Reward: -0.07761231064796448\n",
      "Episode: 2, Step: 90, Action: [ 0.34181535 -0.7852824  -0.40221128  0.03902647], Reward: -0.07814809679985046\n",
      "Episode: 2, Step: 91, Action: [-0.40328792  0.8582107   0.58935857  0.01781331], Reward: -0.07914675027132034\n",
      "Episode: 2, Step: 92, Action: [ 0.5738861   0.5080999   0.15082973 -0.3206311 ], Reward: -0.08028748631477356\n",
      "Episode: 2, Step: 93, Action: [-0.87341666  0.7430988   0.9710029  -0.6377103 ], Reward: -0.08181492984294891\n",
      "Episode: 2, Step: 94, Action: [-0.22398026  0.28318906  0.86607283 -0.11235439], Reward: -0.0836988314986229\n",
      "Episode: 2, Step: 95, Action: [ 0.7986107   0.7896833  -0.69588804  0.00342209], Reward: -0.08418813347816467\n",
      "Episode: 2, Step: 96, Action: [-0.6767271  -0.85472727  0.9924553  -0.70159286], Reward: -0.08593745529651642\n",
      "Episode: 2, Step: 97, Action: [ 0.7764853   0.32858828  0.3767307  -0.11239567], Reward: -0.08679615706205368\n",
      "Episode: 2, Step: 98, Action: [ 0.11042985 -0.27880484 -0.5643883   0.06662794], Reward: -0.0871461033821106\n",
      "Episode: 2, Step: 99, Action: [-0.49498114  0.7452695  -0.51389927  0.08995529], Reward: -0.08625087141990662\n",
      "Episode: 2, Step: 100, Action: [-0.60906845 -0.371285   -0.23965107 -0.9626275 ], Reward: -0.08603852987289429\n",
      "Episode: 2, Step: 101, Action: [ 0.69851804 -0.5732985   0.9569919  -0.8300289 ], Reward: -0.0866594910621643\n",
      "Episode: 2, Step: 102, Action: [-0.4700253  -0.55121714  0.6155102  -0.6951747 ], Reward: -0.0885043665766716\n",
      "Episode: 2, Step: 103, Action: [ 0.33811766  0.48398557 -0.14665993 -0.57524765], Reward: -0.08886808902025223\n",
      "Episode: 2, Step: 104, Action: [0.98771054 0.08971503 0.50247645 0.5038628 ], Reward: -0.0894906222820282\n",
      "Episode: 2, Step: 105, Action: [-0.50740194 -0.71752334 -0.9711237  -0.05474811], Reward: -0.0896666944026947\n",
      "Episode: 2, Step: 106, Action: [ 0.6936148  -0.7358132  -0.6673416   0.11199021], Reward: -0.08934642374515533\n",
      "Episode: 2, Step: 107, Action: [ 0.47430664 -0.6134887   0.5617421  -0.09220114], Reward: -0.09006355702877045\n",
      "Episode: 2, Step: 108, Action: [ 0.69212013 -0.67539155  0.29795128  0.14455713], Reward: -0.09160061180591583\n",
      "Episode: 2, Step: 109, Action: [-0.67612725  0.7208454   0.36975852  0.8010604 ], Reward: -0.09357383102178574\n",
      "Episode: 2, Step: 110, Action: [ 0.2799317  -0.85279787  0.53946936  0.6918443 ], Reward: -0.09646199643611908\n",
      "Episode: 2, Step: 111, Action: [ 0.08948182 -0.66119814  0.05170336  0.328405  ], Reward: -0.09880855679512024\n",
      "Episode: 2, Step: 112, Action: [ 0.89986986  0.2809856   0.17346968 -0.4596046 ], Reward: -0.10078037530183792\n",
      "Episode: 2, Step: 113, Action: [-0.8909165   0.08994462 -0.89505506 -0.855731  ], Reward: -0.10160025209188461\n",
      "Episode: 2, Step: 114, Action: [-0.49880958  0.7915705   0.33341652  0.5687721 ], Reward: -0.10267126560211182\n",
      "Episode: 2, Step: 115, Action: [-0.83573604  0.508551   -0.532624    0.65953374], Reward: -0.10253264009952545\n",
      "Episode: 2, Step: 116, Action: [ 0.88375324  0.10389216  0.44390994 -0.27565506], Reward: -0.10256041586399078\n",
      "Episode: 2, Step: 117, Action: [-0.50193965  0.7277739  -0.42891288 -0.50798976], Reward: -0.1013680174946785\n",
      "Episode: 2, Step: 118, Action: [ 0.7367963 -0.4953632 -0.5048084  0.7203659], Reward: -0.10015933960676193\n",
      "Episode: 2, Step: 119, Action: [ 0.1362674  -0.7764745   0.85816956  0.675879  ], Reward: -0.09985045343637466\n",
      "Episode: 2, Step: 120, Action: [-0.95195997  0.6743118   0.3955013  -0.962633  ], Reward: -0.09978265315294266\n",
      "Episode: 2, Step: 121, Action: [ 0.42753613 -0.55270314  0.05980307 -0.9083284 ], Reward: -0.10022378712892532\n",
      "Episode: 2, Step: 122, Action: [-0.01448408  0.94170445  0.1592377   0.88727885], Reward: -0.10050445050001144\n",
      "Episode: 2, Step: 123, Action: [0.7970392 0.7385005 0.1423157 0.3536761], Reward: -0.10025671869516373\n",
      "Episode: 2, Step: 124, Action: [ 0.48624808  0.07687832 -0.15056932  0.31290576], Reward: -0.09950249642133713\n",
      "Episode: 2, Step: 125, Action: [ 0.81129515  0.15405443 -0.44251043 -0.27865985], Reward: -0.09786072373390198\n",
      "Episode: 2, Step: 126, Action: [0.6193168  0.3713781  0.78038627 0.05482468], Reward: -0.09618963301181793\n",
      "Episode: 2, Step: 127, Action: [ 0.1896201  0.7527984 -0.4170436 -0.9816903], Reward: -0.09364618360996246\n",
      "Episode: 2, Step: 128, Action: [ 0.8421688   0.09913249 -0.65447557 -0.9181874 ], Reward: -0.09102991223335266\n",
      "Episode: 2, Step: 129, Action: [0.5992812  0.12764141 0.22212979 0.6277553 ], Reward: -0.08954692631959915\n",
      "Episode: 2, Step: 130, Action: [-0.9762837  -0.02442489 -0.729332   -0.94181955], Reward: -0.08789464831352234\n",
      "Episode: 2, Step: 131, Action: [ 0.9176745  -0.83966124 -0.9317533  -0.7833352 ], Reward: -0.08659437298774719\n",
      "Episode: 2, Step: 132, Action: [-0.59283465  0.7937285   0.38651142  0.4874358 ], Reward: -0.08527332544326782\n",
      "Episode: 2, Step: 133, Action: [ 0.25627476 -0.21517582  0.9660645  -0.99198747], Reward: -0.08503708988428116\n",
      "Episode: 2, Step: 134, Action: [ 0.02586219 -0.8487468  -0.26971287 -0.3745894 ], Reward: -0.08555924147367477\n",
      "Episode: 2, Step: 135, Action: [-0.2422704  -0.46414235  0.72489905  0.6044111 ], Reward: -0.0871572345495224\n",
      "Episode: 2, Step: 136, Action: [ 0.9688417 -0.6822576  0.8907483 -0.7627212], Reward: -0.08959189057350159\n",
      "Episode: 2, Step: 137, Action: [ 0.89090866 -0.912039    0.41089743 -0.8523776 ], Reward: -0.09295501559972763\n",
      "Episode: 2, Step: 138, Action: [ 0.24651967 -0.81394255  0.4873143  -0.77208465], Reward: -0.0967627689242363\n",
      "Episode: 2, Step: 139, Action: [ 0.6142108  -0.73731077 -0.34684303 -0.4940532 ], Reward: -0.10007978230714798\n",
      "Episode: 2, Step: 140, Action: [-0.15245007  0.09635613  0.7718007  -0.33972308], Reward: -0.10314273834228516\n",
      "Episode: 2, Step: 141, Action: [-0.70651674 -0.12978166  0.82397133  0.5758162 ], Reward: -0.10606373846530914\n",
      "Episode: 2, Step: 142, Action: [-0.47064856  0.3381365   0.81069714 -0.65676856], Reward: -0.10873998701572418\n",
      "Episode: 2, Step: 143, Action: [-0.58656865  0.23732997 -0.44654155 -0.40044186], Reward: -0.11027654260396957\n",
      "Episode: 2, Step: 144, Action: [-0.77111155 -0.5108907  -0.1125262   0.45593664], Reward: -0.11178212612867355\n",
      "Episode: 2, Step: 145, Action: [ 0.5338598  -0.52582407 -0.14183906 -0.67631936], Reward: -0.1132250651717186\n",
      "Episode: 2, Step: 146, Action: [-0.29044685  0.7568186   0.83837235 -0.91118455], Reward: -0.11457233875989914\n",
      "Episode: 2, Step: 147, Action: [ 0.24496213  0.9163594  -0.16064818 -0.61836845], Reward: -0.11506088823080063\n",
      "Episode: 2, Step: 148, Action: [-0.34699547 -0.48073804  0.6239449  -0.4564877 ], Reward: -0.11637959629297256\n",
      "Episode: 2, Step: 149, Action: [ 0.89824396  0.93439037 -0.01918944  0.12166861], Reward: -0.11702965945005417\n",
      "Episode: 2, Step: 150, Action: [-0.8232255   0.27410764 -0.6668669   0.30893812], Reward: -0.11667047441005707\n",
      "Episode: 2, Step: 151, Action: [ 0.5398021  -0.22369352  0.37284696  0.7549756 ], Reward: -0.11722022294998169\n",
      "Episode: 2, Step: 152, Action: [-0.558926   -0.24998449 -0.28162462 -0.70772725], Reward: -0.11770045757293701\n",
      "Episode: 2, Step: 153, Action: [0.18837447 0.14554045 0.9999171  0.7286652 ], Reward: -0.11806567013263702\n",
      "Episode: 2, Step: 154, Action: [-0.41682956  0.96643966  0.06423414  0.92436975], Reward: -0.11804022639989853\n",
      "Episode: 2, Step: 155, Action: [ 0.6657467   0.15044768  0.85294676 -0.572931  ], Reward: -0.11784617602825165\n",
      "Episode: 2, Step: 156, Action: [ 0.79713076 -0.54629666 -0.28320265 -0.72450864], Reward: -0.11781225353479385\n",
      "Episode: 2, Step: 157, Action: [ 0.44533935 -0.3704052  -0.17838848  0.5279055 ], Reward: -0.11802724003791809\n",
      "Episode: 2, Step: 158, Action: [ 0.11863621  0.8803099  -0.97428155 -0.9391569 ], Reward: -0.11716941744089127\n",
      "Episode: 2, Step: 159, Action: [-0.9714365  -0.696401    0.36617047  0.1178595 ], Reward: -0.11723648011684418\n",
      "Episode: 2, Step: 160, Action: [-0.0190313  -0.40933415 -0.16654006 -0.80157316], Reward: -0.1179465502500534\n",
      "Episode: 2, Step: 161, Action: [-0.11798329  0.13624424  0.9185118  -0.9679922 ], Reward: -0.11845352500677109\n",
      "Episode: 2, Step: 162, Action: [ 0.3513911   0.25825825  0.85201263 -0.63169646], Reward: -0.1188846230506897\n",
      "Episode: 2, Step: 163, Action: [-0.4090292   0.28330928  0.23169406 -0.00664704], Reward: -0.11857516318559647\n",
      "Episode: 2, Step: 164, Action: [ 0.08912402 -0.80359197  0.18508917 -0.11915051], Reward: -0.11887050420045853\n",
      "Episode: 2, Step: 165, Action: [-0.78667426  0.604079    0.58899474 -0.723108  ], Reward: -0.11886129528284073\n",
      "Episode: 2, Step: 166, Action: [-0.14522947  0.9908299   0.40084964  0.9266367 ], Reward: -0.1184123232960701\n",
      "Episode: 2, Step: 167, Action: [ 0.8117514  -0.6478632  -0.4293102   0.48434335], Reward: -0.11798489838838577\n",
      "Episode: 2, Step: 168, Action: [ 0.5782746   0.23265569  0.42169026 -0.4119772 ], Reward: -0.11776944249868393\n",
      "Episode: 2, Step: 169, Action: [ 0.6631413  -0.7706594  -0.7570377  -0.39260474], Reward: -0.11735767126083374\n",
      "Episode: 2, Step: 170, Action: [-0.18858613  0.91110116  0.24371983  0.4357033 ], Reward: -0.11699601262807846\n",
      "Episode: 2, Step: 171, Action: [-0.34368375 -0.5362054  -0.71232325  0.6899624 ], Reward: -0.116451196372509\n",
      "Episode: 2, Step: 172, Action: [ 0.52075285 -0.4858459  -0.25097722  0.4844133 ], Reward: -0.11613179743289948\n",
      "Episode: 2, Step: 173, Action: [-0.16025268  0.28002852  0.6278803  -0.65694153], Reward: -0.11571677774190903\n",
      "Episode: 2, Step: 174, Action: [ 0.94701964  0.31824905 -0.26380822  0.8049232 ], Reward: -0.11436241120100021\n",
      "Episode: 2, Step: 175, Action: [-0.26049814  0.09187441  0.98174715 -0.94915265], Reward: -0.1139526292681694\n",
      "Episode: 2, Step: 176, Action: [ 0.51789796  0.5732716  -0.20223373  0.36641046], Reward: -0.11277639865875244\n",
      "Episode: 2, Step: 177, Action: [ 0.8845611  -0.39269188  0.05826641  0.9478343 ], Reward: -0.11241963505744934\n",
      "Episode: 2, Step: 178, Action: [ 0.11173508 -0.642634   -0.41147423 -0.00298932], Reward: -0.1121266558766365\n",
      "Episode: 2, Step: 179, Action: [ 0.8563428   0.0484674  -0.7172635  -0.15749012], Reward: -0.11100220680236816\n",
      "Episode: 2, Step: 180, Action: [ 0.9519857  -0.36255622 -0.20137379  0.51615846], Reward: -0.110817551612854\n",
      "Episode: 2, Step: 181, Action: [0.539681   0.84707355 0.4350146  0.4295266 ], Reward: -0.11060280352830887\n",
      "Episode: 2, Step: 182, Action: [-0.971382   -0.22145626  0.9540912  -0.10950049], Reward: -0.11127499490976334\n",
      "Episode: 2, Step: 183, Action: [ 0.9676812  -0.44544303 -0.8699988  -0.70247173], Reward: -0.11201444268226624\n",
      "Episode: 2, Step: 184, Action: [ 0.25907263 -0.7758015   0.35442877 -0.33259824], Reward: -0.11359596997499466\n",
      "Episode: 2, Step: 185, Action: [-0.5103701   0.27259216  0.60558784 -0.30938435], Reward: -0.11492599546909332\n",
      "Episode: 2, Step: 186, Action: [-0.78260034 -0.87043965  0.72049826  0.76431984], Reward: -0.11712276935577393\n",
      "Episode: 2, Step: 187, Action: [-0.34488264 -0.48888987 -0.7372342  -0.08092342], Reward: -0.11917470395565033\n",
      "Episode: 2, Step: 188, Action: [ 0.64911467 -0.20310959 -0.5923278   0.14822675], Reward: -0.12038564682006836\n",
      "Episode: 2, Step: 189, Action: [-0.9316413   0.04790093 -0.3600985  -0.453271  ], Reward: -0.12067046016454697\n",
      "Episode: 2, Step: 190, Action: [-0.65742075 -0.90663815  0.2978841   0.5452102 ], Reward: -0.12169141322374344\n",
      "Episode: 2, Step: 191, Action: [-0.48404524  0.22854675 -0.3396059   0.25440755], Reward: -0.12200970947742462\n",
      "Episode: 2, Step: 192, Action: [-0.63287425 -0.5040225  -0.78183293 -0.17595796], Reward: -0.12225427478551865\n",
      "Episode: 2, Step: 193, Action: [-0.6071507   0.90795666  0.59000427  0.71381176], Reward: -0.1223316639661789\n",
      "Episode: 2, Step: 194, Action: [-0.7686846  -0.04173252  0.7495866   0.24699698], Reward: -0.12222820520401001\n",
      "Episode: 2, Step: 195, Action: [ 0.21592079  0.05878864 -0.29150873  0.6949093 ], Reward: -0.12152887880802155\n",
      "Episode: 2, Step: 196, Action: [ 0.14372794 -0.62616926  0.54109687  0.24492233], Reward: -0.12164951860904694\n",
      "Episode: 2, Step: 197, Action: [0.9874814  0.03739788 0.04270792 0.6930654 ], Reward: -0.12151973694562912\n",
      "Episode: 2, Step: 198, Action: [ 0.7535595  -0.07258937  0.2722835  -0.08067367], Reward: -0.12211809307336807\n",
      "Episode: 2, Step: 199, Action: [-0.7073369   0.07321738  0.23843575 -0.49972793], Reward: -0.12207459658384323\n",
      "Episode: 2, Step: 200, Action: [ 0.75035673  0.22260372 -0.75321543 -0.09973188], Reward: -0.12117201834917068\n",
      "Episode: 2, Step: 201, Action: [ 0.17585413 -0.8207558  -0.5257967   0.9753671 ], Reward: -0.12051451206207275\n",
      "Episode: 2, Step: 202, Action: [ 0.17471048 -0.32274547  0.18426497 -0.6683013 ], Reward: -0.1206585094332695\n",
      "Episode: 2, Step: 203, Action: [ 0.3670207   0.34996685 -0.6016202   0.6635401 ], Reward: -0.11987762153148651\n",
      "Episode: 2, Step: 204, Action: [ 0.9471265   0.8690201  -0.83392215 -0.18156722], Reward: -0.11928556859493256\n",
      "Episode: 2, Step: 205, Action: [ 0.7448328  -0.18940641 -0.79106736 -0.07318377], Reward: -0.11920054256916046\n",
      "Episode: 2, Step: 206, Action: [-0.33671427  0.878739    0.5610414  -0.49145985], Reward: -0.11890222132205963\n",
      "Episode: 2, Step: 207, Action: [-0.9489651   0.55784756  0.43255812 -0.4171239 ], Reward: -0.1182841807603836\n",
      "Episode: 2, Step: 208, Action: [ 0.2146152   0.76915526  0.83355725 -0.5876719 ], Reward: -0.11734145879745483\n",
      "Episode: 2, Step: 209, Action: [0.2576571  0.07874724 0.26808822 0.8409399 ], Reward: -0.1167588010430336\n",
      "Episode: 2, Step: 210, Action: [ 0.4083158  -0.7555844   0.38955754  0.29574552], Reward: -0.11667902767658234\n",
      "Episode: 2, Step: 211, Action: [-0.58372957  0.31769824  0.9529614  -0.15552808], Reward: -0.1165904700756073\n",
      "Episode: 2, Step: 212, Action: [ 0.27037245  0.42625108 -0.5008294   0.93214345], Reward: -0.11562070995569229\n",
      "Episode: 2, Step: 213, Action: [-0.52096426  0.22565848 -0.41908085 -0.7653166 ], Reward: -0.11461126804351807\n",
      "Episode: 2, Step: 214, Action: [-0.32625258  0.9224264  -0.6618589  -0.50336325], Reward: -0.11260101944208145\n",
      "Episode: 2, Step: 215, Action: [-0.6004945  -0.8100455  -0.90498245 -0.3941603 ], Reward: -0.11038046330213547\n",
      "Episode: 2, Step: 216, Action: [ 0.31100208 -0.6898784  -0.75846624 -0.8361008 ], Reward: -0.10871463268995285\n",
      "Episode: 2, Step: 217, Action: [-0.3522898   0.03546184 -0.18254517  0.42762977], Reward: -0.1077474057674408\n",
      "Episode: 2, Step: 218, Action: [ 0.7425834   0.48243064  0.18734947 -0.5791425 ], Reward: -0.10674239695072174\n",
      "Episode: 2, Step: 219, Action: [-0.71942747 -0.32750764  0.3179607   0.16392243], Reward: -0.10651654005050659\n",
      "Episode: 2, Step: 220, Action: [-0.7729691  -0.43841916  0.4056183   0.05543006], Reward: -0.10698987543582916\n",
      "Episode: 2, Step: 221, Action: [-0.19709305  0.40664858  0.73773676  0.928216  ], Reward: -0.1071837842464447\n",
      "Episode: 2, Step: 222, Action: [-0.22058018 -0.6591962  -0.02320784  0.4447624 ], Reward: -0.10751146823167801\n",
      "Episode: 2, Step: 223, Action: [-0.29236642 -0.26603884  0.6044537   0.31206477], Reward: -0.1087067723274231\n",
      "Episode: 2, Step: 224, Action: [-0.7910039   0.3252883   0.02892656  0.02789522], Reward: -0.10888123512268066\n",
      "Episode: 2, Step: 225, Action: [-0.08422932  0.1360064  -0.37590137 -0.838097  ], Reward: -0.10825992375612259\n",
      "Episode: 2, Step: 226, Action: [-0.7239442  -0.54007006  0.01432531  0.10436286], Reward: -0.10834448039531708\n",
      "Episode: 2, Step: 227, Action: [ 0.4036879   0.0289733  -0.31644008 -0.45015442], Reward: -0.1077004224061966\n",
      "Episode: 2, Step: 228, Action: [-0.8770033   0.6419185  -0.72532326  0.67296857], Reward: -0.10606636106967926\n",
      "Episode: 2, Step: 229, Action: [ 0.5608819  -0.70710754  0.78367245  0.58697486], Reward: -0.10591711103916168\n",
      "Episode: 2, Step: 230, Action: [ 0.05357007  0.68798935 -0.29973975  0.2541377 ], Reward: -0.10520973056554794\n",
      "Episode: 2, Step: 231, Action: [ 0.25001767  0.48795417 -0.09684689 -0.30468717], Reward: -0.10408706963062286\n",
      "Episode: 2, Step: 232, Action: [-0.08177628 -0.49142805 -0.54157996 -0.5953737 ], Reward: -0.10340247303247452\n",
      "Episode: 2, Step: 233, Action: [-0.46003425  0.5833572  -0.7911496   0.8983392 ], Reward: -0.10216548293828964\n",
      "Episode: 2, Step: 234, Action: [-0.7459044   0.36082032 -0.3588325   0.94021106], Reward: -0.1007000282406807\n",
      "Episode: 2, Step: 235, Action: [ 0.75045574 -0.2662936   0.17504808  0.6180215 ], Reward: -0.10006044059991837\n",
      "Episode: 2, Step: 236, Action: [-0.76080805  0.4740516   0.12120908 -0.05001121], Reward: -0.09879565238952637\n",
      "Episode: 2, Step: 237, Action: [ 0.5134682  -0.20900694 -0.4094393   0.95978665], Reward: -0.09757232666015625\n",
      "Episode: 2, Step: 238, Action: [ 0.7811779  -0.21928087 -0.8890329   0.5458835 ], Reward: -0.09658545255661011\n",
      "Episode: 2, Step: 239, Action: [-0.18380038  0.39516595 -0.26638827 -0.05593961], Reward: -0.09577307105064392\n",
      "Episode: 2, Step: 240, Action: [-0.33511993 -0.6349697   0.84210443 -0.87371254], Reward: -0.09585068374872208\n",
      "Episode: 2, Step: 241, Action: [-0.03892456  0.2796757  -0.45586768  0.8171571 ], Reward: -0.09502407908439636\n",
      "Episode: 2, Step: 242, Action: [-0.66366035 -0.03375788 -0.05034485 -0.16394924], Reward: -0.09468808770179749\n",
      "Episode: 2, Step: 243, Action: [ 0.4623449  -0.72030073  0.22503218  0.31677473], Reward: -0.09526315331459045\n",
      "Episode: 2, Step: 244, Action: [-0.5700163  -0.03915389  0.6571368  -0.26521915], Reward: -0.09611594676971436\n",
      "Episode: 2, Step: 245, Action: [0.44616595 0.3546647  0.81986403 0.8308544 ], Reward: -0.0968777984380722\n",
      "Episode: 2, Step: 246, Action: [0.42486554 0.46702743 0.3872556  0.19266924], Reward: -0.09674104303121567\n",
      "Episode: 2, Step: 247, Action: [ 0.74173456 -0.53339016  0.44359645  0.10414458], Reward: -0.09717755764722824\n",
      "Episode: 2, Step: 248, Action: [-0.8394847   0.4474836   0.07606538 -0.23584488], Reward: -0.09652266651391983\n",
      "Episode: 2, Step: 249, Action: [-0.8789764   0.36167374  0.7230695  -0.07863235], Reward: -0.09592985361814499\n",
      "Episode: 2, Step: 250, Action: [-0.22931601  0.09856361 -0.10559319  0.10887364], Reward: -0.09530577808618546\n",
      "Episode: 2, Step: 251, Action: [ 0.5270098   0.56872565  0.35563567 -0.52141833], Reward: -0.09461012482643127\n",
      "Episode: 2, Step: 252, Action: [-0.08183379 -0.13890105  0.2625476  -0.22562952], Reward: -0.09432199597358704\n",
      "Episode: 2, Step: 253, Action: [-0.3239031 -0.6342604 -0.0047954  0.8154643], Reward: -0.09401139616966248\n",
      "Episode: 2, Step: 254, Action: [-0.6845703   0.11212557  0.37863144 -0.19584846], Reward: -0.09430834650993347\n",
      "Episode: 2, Step: 255, Action: [0.7171707  0.07384615 0.40011677 0.02019725], Reward: -0.09497419744729996\n",
      "Episode: 2, Step: 256, Action: [-0.21150647  0.64377844 -0.20972978 -0.02410954], Reward: -0.09454621374607086\n",
      "Episode: 2, Step: 257, Action: [-0.36857092  0.97984576 -0.26251742 -0.24296348], Reward: -0.09309138357639313\n",
      "Episode: 2, Step: 258, Action: [ 0.5987579   0.27468538 -0.7612268   0.8753644 ], Reward: -0.09103793650865555\n",
      "Episode: 2, Step: 259, Action: [-0.07697791 -0.04920543  0.11700733  0.71681607], Reward: -0.08994077891111374\n",
      "Episode: 2, Step: 260, Action: [ 0.57733506 -0.8793747  -0.33338118 -0.362324  ], Reward: -0.08924491703510284\n",
      "Episode: 2, Step: 261, Action: [ 0.44324982  0.8198698   0.35247216 -0.04826987], Reward: -0.08844917267560959\n",
      "Episode: 2, Step: 262, Action: [ 0.49500912 -0.17882407 -0.42238617  0.6965261 ], Reward: -0.08747479319572449\n",
      "Episode: 2, Step: 263, Action: [-0.3668282  -0.33488286 -0.23516493  0.5933937 ], Reward: -0.08735589683055878\n",
      "Episode: 2, Step: 264, Action: [ 0.4189255  -0.935183   -0.6898627   0.75918645], Reward: -0.08712489902973175\n",
      "Episode: 2, Step: 265, Action: [-0.3596906   0.28574327 -0.2982574  -0.36341214], Reward: -0.08693268895149231\n",
      "Episode: 2, Step: 266, Action: [ 0.65309125 -0.05079082  0.3050526  -0.796217  ], Reward: -0.08690796047449112\n",
      "Episode: 2, Step: 267, Action: [-0.5584424  -0.49987945  0.76193106 -0.2997605 ], Reward: -0.08772581815719604\n",
      "Episode: 2, Step: 268, Action: [ 0.7942584  -0.78826797  0.41100526 -0.09070628], Reward: -0.08941633999347687\n",
      "Episode: 2, Step: 269, Action: [ 0.41012588 -0.19053356  0.51088727 -0.38239   ], Reward: -0.0909593403339386\n",
      "Episode: 2, Step: 270, Action: [-0.6844     -0.5553356  -0.01605352 -0.5863496 ], Reward: -0.09248409420251846\n",
      "Episode: 2, Step: 271, Action: [ 0.16817419  0.09765299  0.18680887 -0.30119365], Reward: -0.09350240975618362\n",
      "Episode: 2, Step: 272, Action: [-0.08140238  0.10594494  0.89961576 -0.6828068 ], Reward: -0.09444399178028107\n",
      "Episode: 2, Step: 273, Action: [-0.80344576 -0.9520983   0.70942223  0.18256827], Reward: -0.09645046293735504\n",
      "Episode: 2, Step: 274, Action: [ 0.5522094   0.81497025  0.8896945  -0.7979507 ], Reward: -0.09855028241872787\n",
      "Episode: 2, Step: 275, Action: [ 0.4832099   0.4117733  -0.22462177  0.87346935], Reward: -0.09937187284231186\n",
      "Episode: 2, Step: 276, Action: [ 0.2279157  -0.19080561 -0.01397892  0.34869707], Reward: -0.10010652989149094\n",
      "Episode: 2, Step: 277, Action: [ 0.73462576  0.8619419   0.5158936  -0.12816732], Reward: -0.10080871731042862\n",
      "Episode: 2, Step: 278, Action: [ 0.5797642  0.5258277 -0.6107668 -0.4228932], Reward: -0.10049112886190414\n",
      "Episode: 2, Step: 279, Action: [ 0.25309053  0.21223634 -0.779816    0.24407269], Reward: -0.09939490258693695\n",
      "Episode: 2, Step: 280, Action: [ 0.09386715 -0.18223692 -0.12752236 -0.8894035 ], Reward: -0.098866768181324\n",
      "Episode: 2, Step: 281, Action: [-0.04269069  0.02882553  0.9294996  -0.90436137], Reward: -0.09893205761909485\n",
      "Episode: 2, Step: 282, Action: [-0.0206576   0.57603294  0.11518422  0.45056677], Reward: -0.0987236499786377\n",
      "Episode: 2, Step: 283, Action: [-0.9819446   0.2714522  -0.46190622  0.845223  ], Reward: -0.09727797657251358\n",
      "Episode: 2, Step: 284, Action: [ 0.09874651 -0.7121608   0.66462743  0.29600498], Reward: -0.09692617505788803\n",
      "Episode: 2, Step: 285, Action: [-0.19545123  0.7573846  -0.23941371  0.7780989 ], Reward: -0.09536705166101456\n",
      "Episode: 2, Step: 286, Action: [ 0.72811055  0.5169985  -0.39275008  0.02216884], Reward: -0.093056820333004\n",
      "Episode: 2, Step: 287, Action: [-0.54760486 -0.41376597  0.96858704  0.02393803], Reward: -0.0917535200715065\n",
      "Episode: 2, Step: 288, Action: [ 0.3187624  -0.8830177  -0.0629998  -0.26685074], Reward: -0.0910898819565773\n",
      "Episode: 2, Step: 289, Action: [-0.9174766  -0.6485258   0.8122187   0.40009037], Reward: -0.09149415045976639\n",
      "Episode: 2, Step: 290, Action: [ 0.7754997  -0.3288469   0.6245197   0.82878894], Reward: -0.09297284483909607\n",
      "Episode: 2, Step: 291, Action: [-0.75440913  0.28422114 -0.8201981  -0.63418865], Reward: -0.0931522399187088\n",
      "Episode: 2, Step: 292, Action: [-0.74465585 -0.26886106  0.45136535  0.58778656], Reward: -0.094338059425354\n",
      "Episode: 2, Step: 293, Action: [-0.8030927  -0.55333257 -0.99393094  0.16693063], Reward: -0.09525608271360397\n",
      "Episode: 2, Step: 294, Action: [-0.25695243  0.7935193  -0.33865148 -0.8023909 ], Reward: -0.09494319558143616\n",
      "Episode: 2, Step: 295, Action: [ 0.41202068 -0.79681605 -0.49493247  0.6546534 ], Reward: -0.09473729133605957\n",
      "Episode: 2, Step: 296, Action: [ 0.9147786   0.6117496   0.11010389 -0.53401273], Reward: -0.09463788568973541\n",
      "Episode: 2, Step: 297, Action: [ 0.32520327 -0.5022216   0.30786926  0.5484118 ], Reward: -0.09543494135141373\n",
      "Episode: 2, Step: 298, Action: [-0.9418554  -0.6185156  -0.8440602   0.27344635], Reward: -0.0960475280880928\n",
      "Episode: 2, Step: 299, Action: [ 0.44145197 -0.09240866 -0.9416465   0.92751485], Reward: -0.09555061906576157\n",
      "Episode: 2, Step: 300, Action: [-0.13581659  0.18270415 -0.94010955  0.10427926], Reward: -0.09421645849943161\n",
      "Episode: 2, Step: 301, Action: [ 0.8461989  -0.9718885   0.91545016  0.04008077], Reward: -0.0938435047864914\n",
      "Episode: 2, Step: 302, Action: [-0.7321228   0.43567395  0.8751226  -0.4601917 ], Reward: -0.09345659613609314\n",
      "Episode: 2, Step: 303, Action: [-0.98829216 -0.34468812  0.6789468  -0.04163486], Reward: -0.09408530592918396\n",
      "Episode: 2, Step: 304, Action: [-0.5797643  -0.6042386   0.22256456 -0.5985755 ], Reward: -0.09566918760538101\n",
      "Episode: 2, Step: 305, Action: [ 0.08309965  0.22410862 -0.6147662   0.46959266], Reward: -0.09618688374757767\n",
      "Episode: 2, Step: 306, Action: [ 0.19201891  0.15730458  0.11616401 -0.82439053], Reward: -0.09651511907577515\n",
      "Episode: 2, Step: 307, Action: [ 0.00461133 -0.76731175  0.40170938  0.8338533 ], Reward: -0.09775601327419281\n",
      "Episode: 2, Step: 308, Action: [-0.37911132 -0.19137605  0.19927512  0.24398854], Reward: -0.09882333874702454\n",
      "Episode: 2, Step: 309, Action: [-0.23218577 -0.0225794  -0.82829005 -0.34653485], Reward: -0.09898585081100464\n",
      "Episode: 2, Step: 310, Action: [ 0.67496765 -0.89375263 -0.6563861  -0.85424626], Reward: -0.09911574423313141\n",
      "Episode: 2, Step: 311, Action: [-0.8663744   0.39932215  0.8580855   0.8309248 ], Reward: -0.09910798817873001\n",
      "Episode: 2, Step: 312, Action: [ 0.8862795   0.18310384 -0.63793147  0.5640014 ], Reward: -0.09817639738321304\n",
      "Episode: 2, Step: 313, Action: [-0.9003792   0.53718144 -0.7002396  -0.42962626], Reward: -0.09752597659826279\n",
      "Episode: 2, Step: 314, Action: [-0.60769403  0.70420307 -0.60503745  0.24430904], Reward: -0.09643822908401489\n",
      "Episode: 2, Step: 315, Action: [ 0.543652    0.6797171  -0.99421406  0.2481833 ], Reward: -0.09476316720247269\n",
      "Episode: 2, Step: 316, Action: [ 0.45643085 -0.7246463   0.9447117   0.91169506], Reward: -0.09381728619337082\n",
      "Episode: 2, Step: 317, Action: [-0.52574813 -0.56608635 -0.8612414   0.35690588], Reward: -0.0931432694196701\n",
      "Episode: 2, Step: 318, Action: [-0.14191325  0.39415294 -0.27268764 -0.72754246], Reward: -0.09146637469530106\n",
      "Episode: 2, Step: 319, Action: [ 0.43051806 -0.7854428  -0.3639261   0.12769285], Reward: -0.09083504974842072\n",
      "Episode: 2, Step: 320, Action: [ 0.7296356   0.05505049  0.9783242  -0.9558701 ], Reward: -0.09089433401823044\n",
      "Episode: 2, Step: 321, Action: [ 0.8114445  -0.04562762 -0.49044797  0.6194691 ], Reward: -0.09083720296621323\n",
      "Episode: 2, Step: 322, Action: [-0.9039504  -0.13316257 -0.36347297 -0.39851904], Reward: -0.0907861590385437\n",
      "Episode: 2, Step: 323, Action: [ 0.5334627   0.8409134  -0.58240783 -0.09165946], Reward: -0.09073928743600845\n",
      "Episode: 2, Step: 324, Action: [ 0.15741542  0.06972607 -0.31113803 -0.72933006], Reward: -0.09044978022575378\n",
      "Episode: 2, Step: 325, Action: [ 0.62686205  0.73530465 -0.9137331   0.16880962], Reward: -0.0896393358707428\n",
      "Episode: 2, Step: 326, Action: [ 0.29721442  0.82019216  0.24864784 -0.31293187], Reward: -0.08847586065530777\n",
      "Episode: 2, Step: 327, Action: [-0.99662906  0.3611386   0.71629673 -0.45937392], Reward: -0.08781589567661285\n",
      "Episode: 2, Step: 328, Action: [-0.58304465 -0.9195646  -0.04323687  0.8292944 ], Reward: -0.08724714815616608\n",
      "Episode: 2, Step: 329, Action: [0.59214467 0.50965315 0.54023486 0.7377659 ], Reward: -0.08651445806026459\n",
      "Episode: 2, Step: 330, Action: [-0.268065   -0.43584713  0.23939943  0.98493123], Reward: -0.08603253960609436\n",
      "Episode: 2, Step: 331, Action: [-0.05463376 -0.70752263 -0.3543797   0.32300988], Reward: -0.08564906567335129\n",
      "Episode: 2, Step: 332, Action: [ 0.33915418  0.28583354  0.26781934 -0.27892464], Reward: -0.08505646139383316\n",
      "Episode: 2, Step: 333, Action: [-0.655519   -0.97962445  0.42213774  0.8746942 ], Reward: -0.08546753972768784\n",
      "Episode: 2, Step: 334, Action: [0.73688924 0.42275712 0.4330962  0.46647158], Reward: -0.08554071187973022\n",
      "Episode: 2, Step: 335, Action: [0.27803683 0.7559523  0.2418864  0.2800567 ], Reward: -0.08469630032777786\n",
      "Episode: 2, Step: 336, Action: [-0.8533258  -0.7207902   0.39437896 -0.61365145], Reward: -0.0846676230430603\n",
      "Episode: 2, Step: 337, Action: [ 0.1300541   0.19373672 -0.25190955 -0.68059397], Reward: -0.08416915684938431\n",
      "Episode: 2, Step: 338, Action: [ 0.14076902 -0.1466336  -0.8544718   0.19111203], Reward: -0.08342248946428299\n",
      "Episode: 2, Step: 339, Action: [ 0.7019682  -0.66842276  0.8737886   0.56475985], Reward: -0.08361959457397461\n",
      "Episode: 2, Step: 340, Action: [ 0.1716707  -0.50412834 -0.08931738  0.4605156 ], Reward: -0.08405221998691559\n",
      "Episode: 2, Step: 341, Action: [ 0.9665882   0.6223234  -0.20352186 -0.9602949 ], Reward: -0.08393369615077972\n",
      "Episode: 2, Step: 342, Action: [0.6474873  0.6904608  0.55995655 0.053496  ], Reward: -0.08370181173086166\n",
      "Episode: 2, Step: 343, Action: [ 0.6216221  -0.50261426 -0.6004118   0.52414227], Reward: -0.08335071802139282\n",
      "Episode: 2, Step: 344, Action: [-0.1265216   0.65758085 -0.3600437  -0.99794585], Reward: -0.08246723562479019\n",
      "Episode: 2, Step: 345, Action: [ 0.17940702 -0.33202547 -0.6113462   0.8779264 ], Reward: -0.08152623474597931\n",
      "Episode: 2, Step: 346, Action: [0.5068231  0.23025899 0.16324466 0.14042614], Reward: -0.08067287504673004\n",
      "Episode: 2, Step: 347, Action: [ 0.04043025  0.27609822  0.752189   -0.96755666], Reward: -0.07973414659500122\n",
      "Episode: 2, Step: 348, Action: [ 0.19583978  0.4533205  -0.88514274 -0.88634664], Reward: -0.07780464738607407\n",
      "Episode: 2, Step: 349, Action: [ 0.8971572  -0.41494432 -0.7557542   0.5329941 ], Reward: -0.07578035444021225\n",
      "Episode: 2, Step: 350, Action: [-0.47618613 -0.04080252  0.07606587  0.24679352], Reward: -0.07590685784816742\n",
      "Episode: 2, Step: 351, Action: [-0.24907324 -0.06070175 -0.8697081   0.42412624], Reward: -0.07626499980688095\n",
      "Episode: 2, Step: 352, Action: [ 0.75513536 -0.07396005  0.57309514  0.09166056], Reward: -0.07728507369756699\n",
      "Episode: 2, Step: 353, Action: [-0.39500144  0.06478003  0.54754174  0.5414215 ], Reward: -0.07809282839298248\n",
      "Episode: 2, Step: 354, Action: [ 0.8687867  -0.36380434  0.23418343 -0.8938804 ], Reward: -0.07893501967191696\n",
      "Episode: 2, Step: 355, Action: [ 0.33866918 -0.79850936 -0.01805247 -0.9553048 ], Reward: -0.07988828420639038\n",
      "Episode: 2, Step: 356, Action: [ 0.44564635 -0.01945575  0.72197396 -0.95687455], Reward: -0.08086796849966049\n",
      "Episode: 2, Step: 357, Action: [-0.5056992   0.06278601 -0.548853   -0.3258569 ], Reward: -0.0806821882724762\n",
      "Episode: 2, Step: 358, Action: [ 0.67134124 -0.9650748   0.00939678 -0.47232077], Reward: -0.08130866289138794\n",
      "Episode: 2, Step: 359, Action: [-0.23132598 -0.59631354 -0.368337   -0.32465026], Reward: -0.08181360363960266\n",
      "Episode: 2, Step: 360, Action: [-0.74388343 -0.79056495 -0.46413672 -0.7530944 ], Reward: -0.0824316218495369\n",
      "Episode: 2, Step: 361, Action: [-0.5562354 -0.0784305  0.292719  -0.8346386], Reward: -0.08289902657270432\n",
      "Episode: 2, Step: 362, Action: [-0.5098576  -0.57600987 -0.7687643   0.29101256], Reward: -0.0841541588306427\n",
      "Episode: 2, Step: 363, Action: [-0.39560577 -0.6247739   0.99039906  0.96211267], Reward: -0.08624181896448135\n",
      "Episode: 2, Step: 364, Action: [-0.6629538   0.24822041  0.6215486  -0.22138815], Reward: -0.08803779631853104\n",
      "Episode: 2, Step: 365, Action: [ 0.31550828 -0.6374593  -0.6629612  -0.4746881 ], Reward: -0.09003520011901855\n",
      "Episode: 2, Step: 366, Action: [ 0.4661666  -0.01589043 -0.38568607 -0.07325823], Reward: -0.09102392196655273\n",
      "Episode: 2, Step: 367, Action: [-0.37070408  0.07666655  0.9713712   0.59617853], Reward: -0.09187012910842896\n",
      "Episode: 2, Step: 368, Action: [ 0.0193301  -0.19128975  0.21356128  0.04720076], Reward: -0.0929272398352623\n",
      "Episode: 2, Step: 369, Action: [-0.43219373 -0.2040853   0.01524039 -0.30350313], Reward: -0.0935509204864502\n",
      "Episode: 2, Step: 370, Action: [ 0.4119602  -0.04225047 -0.10600144 -0.45577848], Reward: -0.0936436653137207\n",
      "Episode: 2, Step: 371, Action: [ 0.26839098 -0.23126511  0.9842036  -0.5862882 ], Reward: -0.09470637887716293\n",
      "Episode: 2, Step: 372, Action: [-0.65724444  0.34218687  0.74547726 -0.02924915], Reward: -0.09555933624505997\n",
      "Episode: 2, Step: 373, Action: [-0.27655178  0.570489   -0.5665405   0.2023536 ], Reward: -0.09524209797382355\n",
      "Episode: 2, Step: 374, Action: [ 0.10056674 -0.47662538 -0.4329119  -0.37316316], Reward: -0.09504874795675278\n",
      "Episode: 2, Step: 375, Action: [ 0.8574657  -0.3268052   0.49328116  0.51882535], Reward: -0.09574317932128906\n",
      "Episode: 2, Step: 376, Action: [ 0.09106433 -0.37205112  0.36808068 -0.7494452 ], Reward: -0.09739220887422562\n",
      "Episode: 2, Step: 377, Action: [-0.15407324 -0.8515547   0.6676482  -0.5684676 ], Reward: -0.09989307075738907\n",
      "Episode: 2, Step: 378, Action: [0.15154436 0.70734334 0.24267997 0.9646862 ], Reward: -0.10162442177534103\n",
      "Episode: 2, Step: 379, Action: [ 0.15932767 -0.10664252  0.8118109   0.6879573 ], Reward: -0.10331839323043823\n",
      "Episode: 2, Step: 380, Action: [ 0.5350813  -0.5178464   0.35584855  0.71537507], Reward: -0.10541229695081711\n",
      "Episode: 2, Step: 381, Action: [ 0.31978348 -0.35556257  0.76976806  0.02282814], Reward: -0.10805882513523102\n",
      "Episode: 2, Step: 382, Action: [ 0.06585148 -0.73999786 -0.5647933   0.22883023], Reward: -0.11047115176916122\n",
      "Episode: 2, Step: 383, Action: [-0.12996063  0.6418957  -0.08377455 -0.85060304], Reward: -0.11178182065486908\n",
      "Episode: 2, Step: 384, Action: [ 0.19528928  0.12586644 -0.4007631   0.8279123 ], Reward: -0.11210303008556366\n",
      "Episode: 2, Step: 385, Action: [-0.06676401 -0.01557378 -0.2418158   0.72563046], Reward: -0.11212924122810364\n",
      "Episode: 2, Step: 386, Action: [ 0.3959787   0.98789155 -0.8636485  -0.14726453], Reward: -0.11120478063821793\n",
      "Episode: 2, Step: 387, Action: [-0.09532353  0.00886788  0.98859775  0.16118892], Reward: -0.11068069189786911\n",
      "Episode: 2, Step: 388, Action: [-0.5128912  -0.62059766 -0.9989265   0.31998017], Reward: -0.11011508852243423\n",
      "Episode: 2, Step: 389, Action: [ 0.8342332  -0.51508605  0.8633023   0.59436274], Reward: -0.11061277985572815\n",
      "Episode: 2, Step: 390, Action: [ 0.7461505  -0.02884842 -0.47679877 -0.7153028 ], Reward: -0.1105901375412941\n",
      "Episode: 2, Step: 391, Action: [-0.9804718  0.6851729  0.7924176 -0.7598818], Reward: -0.11034189909696579\n",
      "Episode: 2, Step: 392, Action: [ 0.30985174  0.4953694  -0.98286235 -0.17792098], Reward: -0.10930318385362625\n",
      "Episode: 2, Step: 393, Action: [ 0.1736905  -0.0116503   0.45531762  0.1112316 ], Reward: -0.10950616747140884\n",
      "Episode: 2, Step: 394, Action: [0.19624768 0.18352386 0.92841506 0.4930671 ], Reward: -0.10952024161815643\n",
      "Episode: 2, Step: 395, Action: [ 0.7807901  0.2328714 -0.3096554 -0.6845719], Reward: -0.10888872295618057\n",
      "Episode: 2, Step: 396, Action: [ 0.6588592   0.14526884 -0.9003821   0.16099232], Reward: -0.10839572548866272\n",
      "Episode: 2, Step: 397, Action: [-0.21446401 -0.47415072 -0.10971554 -0.4699339 ], Reward: -0.10874597728252411\n",
      "Episode: 2, Step: 398, Action: [-0.18684499 -0.30277973 -0.46829203 -0.44586197], Reward: -0.10959037393331528\n",
      "Episode: 2, Step: 399, Action: [-0.7874751  -0.92085177  0.59951663  0.71509075], Reward: -0.11097576469182968\n",
      "Episode: 2, Step: 400, Action: [ 0.41219544 -0.9685853  -0.92401206  0.8399355 ], Reward: -0.11260610073804855\n",
      "Episode: 2, Step: 401, Action: [ 0.5584815  -0.3784276  -0.8057872   0.45521304], Reward: -0.11405442655086517\n",
      "Episode: 2, Step: 402, Action: [-0.02786559  0.43069166  0.4868299  -0.8991968 ], Reward: -0.11526976525783539\n",
      "Episode: 2, Step: 403, Action: [0.55145663 0.6865737  0.10313699 0.14500989], Reward: -0.11622022837400436\n",
      "Episode: 2, Step: 404, Action: [-0.33179134 -0.6433973   0.74148524  0.997579  ], Reward: -0.11781451851129532\n",
      "Episode: 2, Step: 405, Action: [-0.23343602 -0.82925755 -0.00947534  0.43318003], Reward: -0.11938150972127914\n",
      "Episode: 2, Step: 406, Action: [-0.9822238  -0.36348063 -0.70936     0.5744692 ], Reward: -0.12036819756031036\n",
      "Episode: 2, Step: 407, Action: [-0.86265683  0.22588927  0.6649861   0.70427513], Reward: -0.1211150586605072\n",
      "Episode: 2, Step: 408, Action: [-0.07186689 -0.9559322   0.84793067  0.7505373 ], Reward: -0.12268605828285217\n",
      "Episode: 2, Step: 409, Action: [ 0.5300963  -0.4493494   0.36116612  0.65150577], Reward: -0.12486499547958374\n",
      "Episode: 2, Step: 410, Action: [-0.5720399   0.09984665 -0.10844772 -0.29435122], Reward: -0.12601295113563538\n",
      "Episode: 2, Step: 411, Action: [-0.79619735  0.75629383 -0.92878276 -0.36086535], Reward: -0.1261361688375473\n",
      "Episode: 2, Step: 412, Action: [-0.6328882   0.96184146  0.18583345  0.34658536], Reward: -0.12588714063167572\n",
      "Episode: 2, Step: 413, Action: [ 0.60921156 -0.05767949  0.05110895 -0.5169929 ], Reward: -0.12601988017559052\n",
      "Episode: 2, Step: 414, Action: [0.15978006 0.3991626  0.276184   0.3816684 ], Reward: -0.1259961873292923\n",
      "Episode: 2, Step: 415, Action: [ 0.8537639  -0.9380521  -0.8100686   0.47629264], Reward: -0.12617868185043335\n",
      "Episode: 2, Step: 416, Action: [-0.28608897  0.43496913  0.57376575 -0.09029223], Reward: -0.12604881823062897\n",
      "Episode: 2, Step: 417, Action: [ 0.2352873   0.52150273 -0.98559767 -0.85686237], Reward: -0.1251077950000763\n",
      "Episode: 2, Step: 418, Action: [ 0.10896323 -0.40696803 -0.05949477 -0.27029297], Reward: -0.12491654604673386\n",
      "Episode: 2, Step: 419, Action: [-0.45196125 -0.16238005  0.26503918  0.43261573], Reward: -0.12530136108398438\n",
      "Episode: 2, Step: 420, Action: [0.98296666 0.7994586  0.20995556 0.4473524 ], Reward: -0.1254061758518219\n",
      "Episode: 2, Step: 421, Action: [-0.05467369  0.12630853 -0.17579985 -0.03560941], Reward: -0.12480244040489197\n",
      "Episode: 2, Step: 422, Action: [-0.06035432  0.2900514  -0.5973211   0.2940397 ], Reward: -0.12324780225753784\n",
      "Episode: 2, Step: 423, Action: [-0.8119759  -0.0348614   0.13612087  0.60804874], Reward: -0.12236279994249344\n",
      "Episode: 2, Step: 424, Action: [ 0.6407314  -0.38174662 -0.79074055  0.7169201 ], Reward: -0.12170454114675522\n",
      "Episode: 2, Step: 425, Action: [ 0.52134085 -0.6085622   0.6707119  -0.52189255], Reward: -0.12236723303794861\n",
      "Episode: 2, Step: 426, Action: [-0.30905625  0.22882819 -0.06873389  0.30399972], Reward: -0.1223636046051979\n",
      "Episode: 2, Step: 427, Action: [-0.88274324  0.7555252  -0.74812347 -0.12180574], Reward: -0.12173286080360413\n",
      "Episode: 2, Step: 428, Action: [-0.20771094 -0.03536216 -0.26424477  0.9802208 ], Reward: -0.12151192873716354\n",
      "Episode: 2, Step: 429, Action: [ 0.6557557  -0.26354125  0.6760913  -0.81264174], Reward: -0.12225932627916336\n",
      "Episode: 2, Step: 430, Action: [ 0.13823628  0.18196397 -0.4276953   0.15693454], Reward: -0.12226875871419907\n",
      "Episode: 2, Step: 431, Action: [-0.62647045 -0.64206064  0.02242158  0.85246944], Reward: -0.12265236675739288\n",
      "Episode: 2, Step: 432, Action: [ 0.13732328 -0.573307    0.89160556  0.01702579], Reward: -0.12409330159425735\n",
      "Episode: 2, Step: 433, Action: [ 0.24249242  0.24760012 -0.5187778  -0.24153672], Reward: -0.12469503283500671\n",
      "Episode: 2, Step: 434, Action: [0.8586243  0.08968145 0.51572096 0.27285218], Reward: -0.125157430768013\n",
      "Episode: 2, Step: 435, Action: [-0.74297285  0.14153545 -0.7027753   0.1318688 ], Reward: -0.12466590851545334\n",
      "Episode: 2, Step: 436, Action: [0.30790612 0.72142357 0.7745409  0.0180977 ], Reward: -0.12401975691318512\n",
      "Episode: 2, Step: 437, Action: [-0.9930457  -0.917098    0.8942112  -0.07166653], Reward: -0.12407977879047394\n",
      "Episode: 2, Step: 438, Action: [-0.06858482  0.2788078  -0.9658275   0.68028414], Reward: -0.12310680001974106\n",
      "Episode: 2, Step: 439, Action: [0.44230393 0.7452789  0.32151964 0.76935226], Reward: -0.12210290133953094\n",
      "Episode: 2, Step: 440, Action: [-0.39222917 -0.45396817  0.5794792   0.8744237 ], Reward: -0.12170808762311935\n",
      "Episode: 2, Step: 441, Action: [0.40508732 0.60193306 0.81603605 0.5961826 ], Reward: -0.12134233862161636\n",
      "Episode: 2, Step: 442, Action: [ 0.5295301  -0.63178796  0.27524775  0.69930565], Reward: -0.12126694619655609\n",
      "Episode: 2, Step: 443, Action: [ 0.575351   -0.34892246  0.33334562  0.9659977 ], Reward: -0.12169694155454636\n",
      "Episode: 2, Step: 444, Action: [ 0.79343647 -0.3511142   0.02896736 -0.27462554], Reward: -0.12248334288597107\n",
      "Episode: 2, Step: 445, Action: [-0.974871   -0.64703417  0.5066513   0.51940536], Reward: -0.12388318032026291\n",
      "Episode: 2, Step: 446, Action: [-0.43460998  0.7722599   0.18728723 -0.58700275], Reward: -0.12449590861797333\n",
      "Episode: 2, Step: 447, Action: [-0.56079334  0.98748857 -0.37090153  0.55967957], Reward: -0.12405551970005035\n",
      "Episode: 2, Step: 448, Action: [-0.24568275  0.19444717  0.15597218 -0.43892053], Reward: -0.12355829775333405\n",
      "Episode: 2, Step: 449, Action: [-0.13214412 -0.23158805  0.5725065   0.6480174 ], Reward: -0.12370001524686813\n",
      "Episode: 2, Step: 450, Action: [-0.689657    0.7401432  -0.3807689  -0.46607387], Reward: -0.12274309247732162\n",
      "Episode: 2, Step: 451, Action: [-0.24815077  0.00547734 -0.15275945 -0.6130985 ], Reward: -0.12190531939268112\n",
      "Episode: 2, Step: 452, Action: [0.01295641 0.08562446 0.58871245 0.9713735 ], Reward: -0.12156277894973755\n",
      "Episode: 2, Step: 453, Action: [-0.5653869  -0.6527952  -0.01121833  0.5899748 ], Reward: -0.12135867029428482\n",
      "Episode: 2, Step: 454, Action: [-0.42305112 -0.9782401   0.69833463 -0.8046015 ], Reward: -0.1218707412481308\n",
      "Episode: 2, Step: 455, Action: [0.23201795 0.3459956  0.28911853 0.14261484], Reward: -0.12218611687421799\n",
      "Episode: 2, Step: 456, Action: [-0.06957912  0.9472077  -0.94423676  0.44107464], Reward: -0.1217341497540474\n",
      "Episode: 2, Step: 457, Action: [-0.72368354  0.649795    0.96142703  0.57589495], Reward: -0.12096361070871353\n",
      "Episode: 2, Step: 458, Action: [-0.6254441  -0.5935701   0.5472245  -0.01319113], Reward: -0.12095515429973602\n",
      "Episode: 2, Step: 459, Action: [ 0.54722226 -0.8706465   0.0622065   0.60298514], Reward: -0.1210634633898735\n",
      "Episode: 2, Step: 460, Action: [0.31818703 0.41231325 0.6639163  0.00763511], Reward: -0.12131133675575256\n",
      "Episode: 2, Step: 461, Action: [ 0.69867605 -0.37167823  0.62524384 -0.8710895 ], Reward: -0.12255456298589706\n",
      "Episode: 2, Step: 462, Action: [ 0.9839873  -0.64319193  0.2802817  -0.6541922 ], Reward: -0.1238134354352951\n",
      "Episode: 2, Step: 463, Action: [-0.18480209 -0.768275   -0.59082913  0.47373614], Reward: -0.12480788677930832\n",
      "Episode: 2, Step: 464, Action: [ 0.81289756  0.06709548  0.5599965  -0.49383673], Reward: -0.12596262991428375\n",
      "Episode: 2, Step: 465, Action: [-0.91085017  0.13563038 -0.6071007   0.88650393], Reward: -0.1258714199066162\n",
      "Episode: 2, Step: 466, Action: [ 0.44170472 -0.6156237   0.33351147 -0.96819097], Reward: -0.12685921788215637\n",
      "Episode: 2, Step: 467, Action: [ 0.27358067 -0.5343073  -0.5028676  -0.8818424 ], Reward: -0.12775959074497223\n",
      "Episode: 2, Step: 468, Action: [ 0.5158008   0.48686236  0.81612647 -0.6255212 ], Reward: -0.1287996470928192\n",
      "Episode: 2, Step: 469, Action: [-0.4188794   0.4621217   0.82918197  0.60006773], Reward: -0.12969356775283813\n",
      "Episode: 2, Step: 470, Action: [ 0.37044352  0.09234115 -0.804682   -0.1669174 ], Reward: -0.1296476125717163\n",
      "Episode: 2, Step: 471, Action: [ 0.5811039  -0.57452226  0.699786    0.7326423 ], Reward: -0.1307155042886734\n",
      "Episode: 2, Step: 472, Action: [ 0.48718253 -0.95965165 -0.623042    0.8224221 ], Reward: -0.13164569437503815\n",
      "Episode: 2, Step: 473, Action: [ 0.50383186 -0.52394754  0.08970026  0.13783278], Reward: -0.13366708159446716\n",
      "Episode: 2, Step: 474, Action: [-0.18881325 -0.9976482  -0.19933908 -0.6252891 ], Reward: -0.13534478843212128\n",
      "Episode: 2, Step: 475, Action: [ 0.2696307   0.47295746 -0.9396829  -0.6949086 ], Reward: -0.13590297102928162\n",
      "Episode: 2, Step: 476, Action: [-0.9134684  -0.86836606 -0.82947046 -0.8014147 ], Reward: -0.13637946546077728\n",
      "Episode: 2, Step: 477, Action: [ 0.7878642   0.02250494 -0.20567147  0.07377932], Reward: -0.13695871829986572\n",
      "Episode: 2, Step: 478, Action: [ 0.11749088  0.78896123 -0.4635536  -0.13803358], Reward: -0.1372048258781433\n",
      "Episode: 2, Step: 479, Action: [-0.6664623  -0.6695194  -0.35090703  0.3738336 ], Reward: -0.1379120796918869\n",
      "Episode: 2, Step: 480, Action: [-0.77154046  0.74482673 -0.3564063  -0.13039687], Reward: -0.13802972435951233\n",
      "Episode: 2, Step: 481, Action: [ 0.5611919   0.31721613 -0.64894533 -0.499928  ], Reward: -0.1374383270740509\n",
      "Episode: 2, Step: 482, Action: [-0.65207857  0.3577983  -0.38262215 -0.624573  ], Reward: -0.13648822903633118\n",
      "Episode: 2, Step: 483, Action: [-0.7406635  0.5368714 -0.9812586 -0.2575416], Reward: -0.13452476263046265\n",
      "Episode: 2, Step: 484, Action: [-0.4786834   0.81018156 -0.05801542 -0.11243626], Reward: -0.13220545649528503\n",
      "Episode: 2, Step: 485, Action: [ 0.919084   -0.72165895 -0.9938073   0.9557631 ], Reward: -0.13028720021247864\n",
      "Episode: 2, Step: 486, Action: [-0.05454827 -0.36982286  0.8660096   0.33765328], Reward: -0.129845529794693\n",
      "Episode: 2, Step: 487, Action: [-0.30768526 -0.43420818 -0.6523404  -0.61062527], Reward: -0.1298116147518158\n",
      "Episode: 2, Step: 488, Action: [ 0.7655757   0.4882002   0.8538197  -0.70389044], Reward: -0.1296943873167038\n",
      "Episode: 2, Step: 489, Action: [ 0.8191551  -0.9141511  -0.89436066  0.9793885 ], Reward: -0.12990163266658783\n",
      "Episode: 2, Step: 490, Action: [-0.43637195 -0.1584244   0.06553318 -0.43349195], Reward: -0.13041363656520844\n",
      "Episode: 2, Step: 491, Action: [-0.93568325 -0.5812691  -0.47201276  0.890273  ], Reward: -0.13103152811527252\n",
      "Episode: 2, Step: 492, Action: [ 0.8519484  -0.632316    0.4798566  -0.68439287], Reward: -0.13256040215492249\n",
      "Episode: 2, Step: 493, Action: [-0.11901226  0.12304812  0.52252996  0.8263609 ], Reward: -0.13373500108718872\n",
      "Episode: 2, Step: 494, Action: [-0.7404412  -0.9367586  -0.21621998  0.57341564], Reward: -0.13500601053237915\n",
      "Episode: 2, Step: 495, Action: [-0.53911334 -0.1256486  -0.04403706 -0.05480421], Reward: -0.1356140673160553\n",
      "Episode: 2, Step: 496, Action: [-0.6967949  -0.97936237 -0.37527204 -0.43606362], Reward: -0.1363399177789688\n",
      "Episode: 2, Step: 497, Action: [ 0.5422936  -0.4815656  -0.6267993   0.52160186], Reward: -0.13786593079566956\n",
      "Episode: 2, Step: 498, Action: [ 0.08567678 -0.4681591  -0.5533671  -0.20762469], Reward: -0.13940925896167755\n",
      "Episode: 2, Step: 499, Action: [-0.66487396 -0.56051886  0.8381196  -0.9173553 ], Reward: -0.14154544472694397\n",
      "Episode: 2, Step: 500, Action: [-0.11371148  0.45210788  0.8644178  -0.82823575], Reward: -0.1435166746377945\n",
      "Episode: 2, Step: 501, Action: [-0.52886057 -0.49690303  0.5390594   0.4921216 ], Reward: -0.1456412822008133\n",
      "Episode: 2, Step: 502, Action: [ 0.67859066 -0.31361553 -0.693205   -0.0226822 ], Reward: -0.14705535769462585\n",
      "Episode: 2, Step: 503, Action: [-0.7264283  -0.8536873  -0.08857755  0.28136823], Reward: -0.14861932396888733\n",
      "Episode: 2, Step: 504, Action: [ 0.14524825 -0.80356026 -0.748728    0.84695   ], Reward: -0.15048550069332123\n",
      "Episode: 2, Step: 505, Action: [-0.35807246 -0.5953545  -0.7914253  -0.5468225 ], Reward: -0.1518842726945877\n",
      "Episode: 2, Step: 506, Action: [-0.11068229 -0.38709715 -0.7298589   0.880167  ], Reward: -0.15285830199718475\n",
      "Episode: 2, Step: 507, Action: [ 0.24988382 -0.29263914  0.23425798 -0.48557994], Reward: -0.15421536564826965\n",
      "Episode: 2, Step: 508, Action: [ 0.5468948   0.822852    0.81687826 -0.77572083], Reward: -0.15527456998825073\n",
      "Episode: 2, Step: 509, Action: [-0.85726607  0.4026411  -0.28159517 -0.91174716], Reward: -0.15551672875881195\n",
      "Episode: 2, Step: 510, Action: [-0.24410667  0.70334184  0.80085784  0.48470756], Reward: -0.15517522394657135\n",
      "Episode: 2, Step: 511, Action: [ 0.582849  -0.3043453 -0.1923967 -0.4947213], Reward: -0.1553363800048828\n",
      "Episode: 2, Step: 512, Action: [-0.9345521   0.11121351  0.5270874  -0.7820731 ], Reward: -0.1550770401954651\n",
      "Episode: 2, Step: 513, Action: [ 0.23233028 -0.9805802  -0.4448767   0.24681596], Reward: -0.15505774319171906\n",
      "Episode: 2, Step: 514, Action: [ 0.7178331  -0.35002032  0.7719951  -0.17922854], Reward: -0.15591591596603394\n",
      "Episode: 2, Step: 515, Action: [-0.3269624  -0.74958545  0.4530798   0.4285646 ], Reward: -0.15747681260108948\n",
      "Episode: 2, Step: 516, Action: [-0.5266169  -0.08190037 -0.61303145  0.5607913 ], Reward: -0.15812169015407562\n",
      "Episode: 2, Step: 517, Action: [-0.9808402  -0.3275861  -0.9431328   0.76172924], Reward: -0.15898965299129486\n",
      "Episode: 2, Step: 518, Action: [-0.30260658  0.48192552  0.5111661  -0.8105017 ], Reward: -0.15954218804836273\n",
      "Episode: 2, Step: 519, Action: [-0.11219432 -0.26766405 -0.00123342 -0.6752243 ], Reward: -0.16050894558429718\n",
      "Episode: 2, Step: 520, Action: [-0.09959822 -0.7133896  -0.81380993  0.6090405 ], Reward: -0.16184157133102417\n",
      "Episode: 2, Step: 521, Action: [-0.7880203  0.5345154 -0.5342481 -0.5262852], Reward: -0.1628285050392151\n",
      "Episode: 2, Step: 522, Action: [ 0.9013034  -0.3485243   0.5549679  -0.69451016], Reward: -0.16435079276561737\n",
      "Episode: 2, Step: 523, Action: [-0.5597059 -0.5478919 -0.9764015 -0.8566043], Reward: -0.16614176332950592\n",
      "Episode: 2, Step: 524, Action: [-0.02778948  0.64998776 -0.38033107  0.3272072 ], Reward: -0.1672687977552414\n",
      "Episode: 2, Step: 525, Action: [ 0.0016369  -0.05114055 -0.18121956 -0.48518783], Reward: -0.1681860387325287\n",
      "Episode: 2, Step: 526, Action: [ 0.38847464 -0.76927364  0.15342954  0.68828195], Reward: -0.16970805823802948\n",
      "Episode: 2, Step: 527, Action: [ 0.24846941 -0.06344045 -0.39268863  0.22303092], Reward: -0.17070752382278442\n",
      "Episode: 2, Step: 528, Action: [-0.24161431 -0.36837444 -0.53859264 -0.8631468 ], Reward: -0.17221303284168243\n",
      "Episode: 2, Step: 529, Action: [-0.84956485 -0.1133237  -0.55380166  0.83487016], Reward: -0.17311038076877594\n",
      "Episode: 2, Step: 530, Action: [ 0.54933184 -0.16486685  0.15436082 -0.01633033], Reward: -0.1739620864391327\n",
      "Episode: 2, Step: 531, Action: [-0.12306035 -0.02129613  0.04957262 -0.64093375], Reward: -0.17409846186637878\n",
      "Episode: 2, Step: 532, Action: [ 0.10457058 -0.55066824  0.98553044 -0.11200929], Reward: -0.17507214844226837\n",
      "Episode: 2, Step: 533, Action: [ 0.691522    0.30691364 -0.8869957  -0.15261997], Reward: -0.17521923780441284\n",
      "Episode: 2, Step: 534, Action: [ 0.6619961  -0.68006086 -0.81436545  0.1602744 ], Reward: -0.17579321563243866\n",
      "Episode: 2, Step: 535, Action: [-0.36417395 -0.5028526   0.23291214 -0.0150496 ], Reward: -0.17697960138320923\n",
      "Episode: 2, Step: 536, Action: [ 0.04737167 -0.045809    0.47550765 -0.31550065], Reward: -0.1778060495853424\n",
      "Episode: 2, Step: 537, Action: [ 0.7049039  -0.35338834 -0.39982146  0.3789964 ], Reward: -0.179022416472435\n",
      "Episode: 2, Step: 538, Action: [ 0.22090502 -0.94847226 -0.78699785 -0.97912484], Reward: -0.18091467022895813\n",
      "Episode: 2, Step: 539, Action: [-0.91028744  0.5916428  -0.02908926 -0.86643046], Reward: -0.1821698546409607\n",
      "Episode: 2, Step: 540, Action: [-0.6358622   0.25215614  0.5073232  -0.8937476 ], Reward: -0.1830524057149887\n",
      "Episode: 2, Step: 541, Action: [ 0.68964803  0.2056134  -0.11299542  0.7986207 ], Reward: -0.18316346406936646\n",
      "Episode: 2, Step: 542, Action: [-0.74687356  0.87862617  0.44671193  0.6243583 ], Reward: -0.18290436267852783\n",
      "Episode: 2, Step: 543, Action: [ 0.86795676  0.01729582  0.49008864 -0.00209828], Reward: -0.1831902414560318\n",
      "Episode: 2, Step: 544, Action: [-0.46128967  0.90709805  0.6637303   0.5082517 ], Reward: -0.18313895165920258\n",
      "Episode: 2, Step: 545, Action: [ 0.872634   -0.67272913 -0.3920621  -0.03737801], Reward: -0.1833924502134323\n",
      "Episode: 2, Step: 546, Action: [-0.59187895 -0.65216494 -0.8291816  -0.72403705], Reward: -0.18387514352798462\n",
      "Episode: 2, Step: 547, Action: [-0.00477272 -0.39135358 -0.46746835  0.4270785 ], Reward: -0.18456432223320007\n",
      "Episode: 2, Step: 548, Action: [ 0.5040042  -0.77989846 -0.9224809  -0.02404678], Reward: -0.1856476068496704\n",
      "Episode: 2, Step: 549, Action: [ 0.3262338   0.4889209  -0.378998    0.71083385], Reward: -0.18654470145702362\n",
      "Episode: 2, Step: 550, Action: [ 0.11767036  0.46100074  0.4968226  -0.6765291 ], Reward: -0.18697777390480042\n",
      "Episode: 2, Step: 551, Action: [ 0.81657565  0.83911926  0.15294427 -0.09773191], Reward: -0.18707053363323212\n",
      "Episode: 2, Step: 552, Action: [ 0.8587903   0.6964692   0.23275848 -0.1826493 ], Reward: -0.18689706921577454\n",
      "Episode: 2, Step: 553, Action: [ 0.03224473  0.50088245 -0.41644695 -0.24574767], Reward: -0.18582947552204132\n",
      "Episode: 2, Step: 554, Action: [-0.44586813 -0.19293238 -0.35196134 -0.47419024], Reward: -0.18496344983577728\n",
      "Episode: 2, Step: 555, Action: [ 0.02486504 -0.16278508 -0.55534756  0.21450573], Reward: -0.18498080968856812\n",
      "Episode: 2, Step: 556, Action: [-0.39041102  0.47921267  0.8339358  -0.12253711], Reward: -0.18443340063095093\n",
      "Episode: 2, Step: 557, Action: [-0.8015886  -0.37166405  0.9010555   0.07739837], Reward: -0.18464145064353943\n",
      "Episode: 2, Step: 558, Action: [ 0.44961905  0.9582175  -0.5366387  -0.213552  ], Reward: -0.18405328691005707\n",
      "Episode: 2, Step: 559, Action: [-0.5938514  -0.7775109   0.17597462 -0.7932611 ], Reward: -0.18406283855438232\n",
      "Episode: 2, Step: 560, Action: [ 0.9669066  -0.31534904 -0.75049335 -0.6721157 ], Reward: -0.1843605935573578\n",
      "Episode: 2, Step: 561, Action: [-0.72001964  0.51176775 -0.8423546   0.47997192], Reward: -0.18378618359565735\n",
      "Episode: 2, Step: 562, Action: [ 0.98994577  0.43279386 -0.33742753 -0.7443412 ], Reward: -0.18277999758720398\n",
      "Episode: 2, Step: 563, Action: [ 0.23972633 -0.6896521  -0.25403914  0.9705811 ], Reward: -0.1826147437095642\n",
      "Episode: 2, Step: 564, Action: [-0.34952444  0.696181   -0.334468   -0.5746349 ], Reward: -0.18189050257205963\n",
      "Episode: 2, Step: 565, Action: [ 0.762417    0.05499361  0.26179555 -0.84085333], Reward: -0.1819124072790146\n",
      "Episode: 2, Step: 566, Action: [-0.16533898  0.4977453   0.45950115 -0.20328082], Reward: -0.18145331740379333\n",
      "Episode: 2, Step: 567, Action: [-0.90561223  0.8511233  -0.08740866 -0.81942105], Reward: -0.18019241094589233\n",
      "Episode: 2, Step: 568, Action: [-0.7994209   0.32207838 -0.45105425 -0.60904145], Reward: -0.17850488424301147\n",
      "Episode: 2, Step: 569, Action: [-0.01089781  0.15844753 -0.96348894  0.08828564], Reward: -0.1773233264684677\n",
      "Episode: 2, Step: 570, Action: [ 0.8595812  -0.84048325  0.45061105 -0.7496533 ], Reward: -0.17678911983966827\n",
      "Episode: 2, Step: 571, Action: [-0.82429814  0.13793439  0.72143745  0.45302612], Reward: -0.17621150612831116\n",
      "Episode: 2, Step: 572, Action: [ 0.5133692  -0.21322833 -0.824407    0.8519339 ], Reward: -0.17609252035617828\n",
      "Episode: 2, Step: 573, Action: [ 0.6145342   0.99667466 -0.97909737  0.41213432], Reward: -0.1756378561258316\n",
      "Episode: 2, Step: 574, Action: [ 0.69919974  0.9623047  -0.8295109  -0.83627814], Reward: -0.17455728352069855\n",
      "Episode: 2, Step: 575, Action: [ 0.14955781 -0.8128042  -0.89178616  0.810257  ], Reward: -0.17418818175792694\n",
      "Episode: 2, Step: 576, Action: [-0.9583023  -0.2056918   0.8962452  -0.19824931], Reward: -0.1742977648973465\n",
      "Episode: 2, Step: 577, Action: [ 0.507832   -0.26221618  0.09157553 -0.6125497 ], Reward: -0.17504452168941498\n",
      "Episode: 2, Step: 578, Action: [ 0.09061314 -0.67605    -0.43283385  0.10236087], Reward: -0.17597685754299164\n",
      "Episode: 2, Step: 579, Action: [-0.87991244  0.51075673 -0.7650337  -0.6191474 ], Reward: -0.1760440617799759\n",
      "Episode: 2, Step: 580, Action: [-0.43200535 -0.7975617  -0.7227061  -0.9377006 ], Reward: -0.17711378633975983\n",
      "Episode: 2, Step: 581, Action: [-0.14942378  0.9050823  -0.01039403  0.21481965], Reward: -0.17766734957695007\n",
      "Episode: 2, Step: 582, Action: [-0.8107512   0.9231964   0.12506074 -0.2841259 ], Reward: -0.17760871350765228\n",
      "Episode: 2, Step: 583, Action: [-0.43341348 -0.32996383 -0.14178212 -0.72805244], Reward: -0.17794029414653778\n",
      "Episode: 2, Step: 584, Action: [ 0.04650708  0.6142747  -0.38072136  0.191965  ], Reward: -0.1778257191181183\n",
      "Episode: 2, Step: 585, Action: [-0.14449938 -0.8827192   0.95396596 -0.3493086 ], Reward: -0.17844943702220917\n",
      "Episode: 2, Step: 586, Action: [-0.41485715 -0.8056905  -0.98684347 -0.9054484 ], Reward: -0.17936338484287262\n",
      "Episode: 2, Step: 587, Action: [ 0.10141934 -0.9633808  -0.13434286 -0.25577345], Reward: -0.18085023760795593\n",
      "Episode: 2, Step: 588, Action: [-0.63658214 -0.1905717  -0.60750544 -0.13003357], Reward: -0.1818164438009262\n",
      "Episode: 2, Step: 589, Action: [-0.09488452 -0.18483104  0.7741198   0.63797444], Reward: -0.18262851238250732\n",
      "Episode: 2, Step: 590, Action: [-0.95765245  0.02429786  0.19214849  0.46075183], Reward: -0.18297390639781952\n",
      "Episode: 2, Step: 591, Action: [-0.908068   -0.91837835  0.7945351  -0.92210203], Reward: -0.18387745320796967\n",
      "Episode: 2, Step: 592, Action: [-0.91258633  0.40830404 -0.33279237 -0.5168012 ], Reward: -0.18403573334217072\n",
      "Episode: 2, Step: 593, Action: [ 0.9449786   0.57825917 -0.31197754  0.61532265], Reward: -0.18346214294433594\n",
      "Episode: 2, Step: 594, Action: [ 0.97632664  0.24574785  0.7502412  -0.88379234], Reward: -0.1825399547815323\n",
      "Episode: 2, Step: 595, Action: [-0.8468692  -0.47752252 -0.8587579   0.7067519 ], Reward: -0.18183960020542145\n",
      "Episode: 2, Step: 596, Action: [ 0.899683    0.42902225 -0.9891479  -0.67067   ], Reward: -0.18044254183769226\n",
      "Episode: 2, Step: 597, Action: [-0.69294214 -0.69010574  0.14714189 -0.646475  ], Reward: -0.18011343479156494\n",
      "Episode: 2, Step: 598, Action: [ 0.726553   -0.88817704 -0.4859998   0.7614325 ], Reward: -0.18029768764972687\n",
      "Episode: 2, Step: 599, Action: [-0.12953177 -0.5405427  -0.18940207  0.78087986], Reward: -0.18108853697776794\n",
      "Episode: 2, Step: 600, Action: [ 0.38232723  0.38631687 -0.9040697   0.7308196 ], Reward: -0.18129920959472656\n",
      "Episode: 2, Step: 601, Action: [ 0.95961803  0.47201163 -0.04163279  0.31705493], Reward: -0.18101060390472412\n",
      "Episode: 2, Step: 602, Action: [-0.64288   -0.5898411 -0.1268119  0.9841072], Reward: -0.18120504915714264\n",
      "Episode: 2, Step: 603, Action: [-0.05383661  0.9816173  -0.53589404 -0.2405046 ], Reward: -0.18082600831985474\n",
      "Episode: 2, Step: 604, Action: [-0.96846724 -0.74892026  0.67132014  0.9858396 ], Reward: -0.18119552731513977\n",
      "Episode: 2, Step: 605, Action: [ 0.28285235  0.06542447  0.13754891 -0.8093046 ], Reward: -0.18109095096588135\n",
      "Episode: 2, Step: 606, Action: [ 0.3754264   0.37254688  0.1135368  -0.82128185], Reward: -0.18030765652656555\n",
      "Episode: 2, Step: 607, Action: [ 0.6471771   0.72945917  0.83391654 -0.42366058], Reward: -0.17922788858413696\n",
      "Episode: 2, Step: 608, Action: [-0.36677337  0.26588085 -0.39528105 -0.8189038 ], Reward: -0.17819669842720032\n",
      "Episode: 2, Step: 609, Action: [ 0.39207867 -0.47084525 -0.04773153 -0.79386544], Reward: -0.17768289148807526\n",
      "Episode: 2, Step: 610, Action: [ 0.8897333  -0.9256088   0.9374934   0.06067039], Reward: -0.17786288261413574\n",
      "Episode: 2, Step: 611, Action: [-0.6766363   0.9544322   0.22371371 -0.9355668 ], Reward: -0.17750969529151917\n",
      "Episode: 2, Step: 612, Action: [ 0.13150245  0.64401174 -0.65228325 -0.31102902], Reward: -0.17637276649475098\n",
      "Episode: 2, Step: 613, Action: [ 0.91903627 -0.78810555  0.8857562   0.96800274], Reward: -0.17605718970298767\n",
      "Episode: 2, Step: 614, Action: [-0.79273087 -0.33219588  0.40780866 -0.7137506 ], Reward: -0.17641876637935638\n",
      "Episode: 2, Step: 615, Action: [-0.6177549   0.27200654 -0.0130565  -0.231992  ], Reward: -0.17588064074516296\n",
      "Episode: 2, Step: 616, Action: [ 0.3217466  -0.6561241  -0.5113111  -0.90642196], Reward: -0.17568539083003998\n",
      "Episode: 2, Step: 617, Action: [ 0.67324954 -0.9386713   0.5526497  -0.88647985], Reward: -0.17630210518836975\n",
      "Episode: 2, Step: 618, Action: [-0.8861557  -0.8056137  -0.05756922  0.99887735], Reward: -0.1773366630077362\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Not connected to physics server.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (terminated \u001b[38;5;129;01mor\u001b[39;00m truncated):  \u001b[38;5;66;03m# Correct condition for Gymnasium environments\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Take a random action from the environment's action space\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 19\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Action: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\stijn\\OneDrive\\Documenten\\GitHub\\2024-25b-fai2-adsai-StijnvanderPas232027\\Y2B-2023-OT2_Twin-main\\Y2B-2023-OT2_Twin-main\\ot2_env_wrapper.py:71\u001b[0m, in \u001b[0;36mOT2Env.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     68\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(action, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Execute the action in the simulation\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Extract pipette position\u001b[39;00m\n\u001b[0;32m     74\u001b[0m robot_id_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobotId_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mrobotIds[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\stijn\\OneDrive\\Documenten\\GitHub\\2024-25b-fai2-adsai-StijnvanderPas232027\\Y2B-2023-OT2_Twin-main\\Y2B-2023-OT2_Twin-main\\sim_class.py:253\u001b[0m, in \u001b[0;36mSimulation.run\u001b[1;34m(self, actions, num_steps)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender:\n\u001b[0;32m    251\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m240.\u001b[39m) \u001b[38;5;66;03m# slow down the simulation\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stijn\\OneDrive\\Documenten\\GitHub\\2024-25b-fai2-adsai-StijnvanderPas232027\\Y2B-2023-OT2_Twin-main\\Y2B-2023-OT2_Twin-main\\sim_class.py:304\u001b[0m, in \u001b[0;36mSimulation.get_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m states \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m robotId \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobotIds:\n\u001b[1;32m--> 304\u001b[0m     raw_joint_states \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetJointStates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrobotId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;66;03m# Convert joint states into a dictionary\u001b[39;00m\n\u001b[0;32m    307\u001b[0m     joint_states \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31merror\u001b[0m: Not connected to physics server."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from ot2_env_wrapper import OT2Env \n",
    "\n",
    "# Load your custom environment\n",
    "env = OT2Env(render=True, max_steps=1000)\n",
    "\n",
    "# Number of episodes\n",
    "num_episodes = 5\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "    step = 0\n",
    "\n",
    "    while not (terminated or truncated):  # Correct condition for Gymnasium environments\n",
    "        # Take a random action from the environment's action space\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        print(f\"Episode: {episode + 1}, Step: {step + 1}, Action: {action}, Reward: {reward}\")\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    print(f\"Episode finished after {step} steps. Info: {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Block_2B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
